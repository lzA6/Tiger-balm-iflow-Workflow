#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½MCPç®¡ç†å™¨ - è‡ªåŠ¨è¯†åˆ«å’Œè°ƒç”¨MCPå·¥å…·
Intelligent MCP Manager - Automatic Recognition and Invocation of MCP Tools

ä½œè€…: Quantum AI Team
ç‰ˆæœ¬: 5.2.0
æ—¥æœŸ: 2025-11-12
"""

import re
import json
import time
import logging
import asyncio
import subprocess
from typing import Dict, List, Any, Optional, Tuple, Callable
from dataclasses import dataclass, asdict
from pathlib import Path
from enum import Enum
import threading
from collections import defaultdict, deque

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TaskType(Enum):
    """ä»»åŠ¡ç±»å‹æšä¸¾"""
    CODE_GENERATION = "code_generation"
    ANALYSIS = "analysis"
    OPTIMIZATION = "optimization"
    DOCUMENTATION = "documentation"
    TESTING = "testing"
    DEBUGGING = "debugging"
    REFACTORING = "refactoring"
    DEPLOYMENT = "deployment"
    RESEARCH = "research"
    DESIGN = "design"
    VALIDATION = "validation"

@dataclass
class MCPTool:
    """MCPå·¥å…·å®šä¹‰"""
    name: str
    description: str
    capabilities: List[str]
    task_types: List[TaskType]
    priority: int  # 1-10
    command_pattern: str
    example_usage: str
    success_indicators: List[str]
    failure_indicators: List[str]
    auto_call_threshold: float  # 0.0-1.0
    performance_score: float = 0.0

@dataclass
class ContextAnalysis:
    """ä¸Šä¸‹æ–‡åˆ†æç»“æœ"""
    task_type: TaskType
    complexity: str  # simple, medium, complex, critical
    urgency: str  # low, normal, high, critical
    domain: str  # web, mobile, ai, data, system
    language: Optional[str]
    tools_needed: List[str]
    confidence: float
    keywords: List[str]
    user_intent: str

class IntelligentMCPManager:
    """æ™ºèƒ½MCPç®¡ç†å™¨"""
    
    def __init__(self, config_path: Optional[str] = None):
        """åˆå§‹åŒ–æ™ºèƒ½MCPç®¡ç†å™¨"""
        self.config_path = config_path or "mcp_tools_config.json"
        self.available_tools = {}
        self.tool_performance = defaultdict(list)
        self.context_history = deque(maxlen=100)
        self.auto_call_history = defaultdict(list)
        self.learning_enabled = True
        
        # åŠ è½½å·¥å…·é…ç½®
        self._load_tools_configuration()
        
        # åˆå§‹åŒ–é»˜è®¤å·¥å…·
        self._initialize_default_tools()
        
        # æ€§èƒ½ç›‘æ§çº¿ç¨‹
        self.performance_monitor_thread = threading.Thread(target=self._performance_monitor, daemon=True)
        self.performance_monitor_thread.start()
        
        logger.info("ğŸ¤– æ™ºèƒ½MCPç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_tools_configuration(self):
        """åŠ è½½å·¥å…·é…ç½®"""
        if Path(self.config_path).exists():
            try:
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    
                for tool_config in config.get('tools', []):
                    tool = MCPTool(
                        name=tool_config['name'],
                        description=tool_config['description'],
                        capabilities=tool_config['capabilities'],
                        task_types=[TaskType(t) for t in tool_config['task_types']],
                        priority=tool_config['priority'],
                        command_pattern=tool_config.get('command_pattern', ''),
                        example_usage=tool_config.get('example_usage', ''),
                        success_indicators=tool_config.get('success_indicators', []),
                        failure_indicators=tool_config.get('failure_indicators', []),
                        auto_call_threshold=tool_config.get('auto_call_threshold', 0.7),
                        performance_score=tool_config.get('performance_score', 0.5)
                    )
                    self.available_tools[tool.name] = tool
                    
                logger.info(f"ğŸ“„ åŠ è½½äº† {len(self.available_tools)} ä¸ªå·¥å…·é…ç½®")
                    
            except Exception as e:
                logger.error(f"âŒ åŠ è½½å·¥å…·é…ç½®å¤±è´¥: {e}")
    
    def _initialize_default_tools(self):
        """åˆå§‹åŒ–é»˜è®¤å·¥å…·"""
        default_tools = [
            {
                "name": "adaptive_quantum_annealing",
                "description": "è‡ªé€‚åº”é‡å­é€€ç«ä¼˜åŒ–ç®—æ³•",
                "capabilities": ["optimization", "quantum_computing", "parameter_tuning"],
                "task_types": ["optimization", "analysis"],
                "priority": 9,
                "command_pattern": "python tools/adaptive_quantum_annealing.py",
                "example_usage": "ä¼˜åŒ–é¡¹ç›®æ€§èƒ½æˆ–å¤æ‚é—®é¢˜",
                "success_indicators": ["æ”¶æ•›", "ä¼˜åŒ–å®Œæˆ", "æ‰¾åˆ°æœ€ä¼˜è§£"],
                "failure_indicators": ["é”™è¯¯", "ä¸æ”¶æ•›", "è¶…æ—¶"],
                "auto_call_threshold": 0.8,
                "performance_score": 0.9
            },
            {
                "name": "reinforcement_learning_agent",
                "description": "å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“å†³ç­–ç³»ç»Ÿ",
                "capabilities": ["machine_learning", "decision_making", "agent_coordination"],
                "task_types": ["analysis", "optimization", "coordination"],
                "priority": 8,
                "command_pattern": "python tools/reinforcement_learning_agent.py",
                "example_usage": "å¤šæ™ºèƒ½ä½“åä½œå†³ç­–æˆ–ç­–ç•¥ä¼˜åŒ–",
                "success_indicators": ["å­¦ä¹ å®Œæˆ", "ç­–ç•¥æ”¹è¿›", "å†³ç­–ä¼˜åŒ–"],
                "failure_indicators": ["å­¦ä¹ å¤±è´¥", "æ”¶æ•›æ…¢", "ç­–ç•¥é”™è¯¯"],
                "auto_call_threshold": 0.7,
                "performance_score": 0.8
            },
            {
                "name": "quantum_intelligent_router",
                "description": "é‡å­æ™ºèƒ½è·¯ç”±ç³»ç»Ÿ",
                "capabilities": ["routing", "model_selection", "load_balancing", "ide_detection"],
                "task_types": ["analysis", "coordination"],
                "priority": 9,
                "command_pattern": "python tools/quantum_intelligent_router.py",
                "example_usage": "æ™ºèƒ½è·¯ç”±ä»»åŠ¡åˆ°æœ€ä¼˜AIæ¨¡å‹",
                "success_indicators": ["è·¯ç”±å®Œæˆ", "æ¨¡å‹é€‰æ‹©", "è´Ÿè½½å‡è¡¡"],
                "failure_indicators": ["è·¯ç”±å¤±è´¥", "æ¨¡å‹ä¸å¯ç”¨", "è´Ÿè½½è¿‡é«˜"],
                "auto_call_threshold": 0.9,
                "performance_score": 0.9
            },
            {
                "name": "agent_memory_system",
                "description": "æ™ºèƒ½ä½“è®°å¿†å’Œå­¦ä¹ ç³»ç»Ÿ",
                "capabilities": ["memory", "learning", "knowledge_management", "experience_tracking"],
                "task_types": ["analysis", "documentation", "learning"],
                "priority": 7,
                "command_pattern": "python tools/agent_memory_system.py",
                "example_usage": "å­˜å‚¨å’Œæ£€ç´¢å¼€å‘ç»éªŒå’ŒçŸ¥è¯†",
                "success_indicators": ["è®°å¿†å­˜å‚¨", "çŸ¥è¯†æ£€ç´¢", "ç»éªŒå­¦ä¹ "],
                "failure_indicators": ["å­˜å‚¨å¤±è´¥", "æ£€ç´¢é”™è¯¯", "å­¦ä¹ é—®é¢˜"],
                "auto_call_threshold": 0.6,
                "performance_score": 0.7
            }
        ]
        
        for tool_config in default_tools:
            if tool_config['name'] not in self.available_tools:
                tool = MCPTool(
                    name=tool_config['name'],
                    description=tool_config['description'],
                    capabilities=tool_config['capabilities'],
                    task_types=[TaskType(t) for t in tool_config['task_types']],
                    priority=tool_config['priority'],
                    command_pattern=tool_config['command_pattern'],
                    example_usage=tool_config['example_usage'],
                    success_indicators=tool_config['success_indicators'],
                    failure_indicators=tool_config['failure_indicators'],
                    auto_call_threshold=tool_config['auto_call_threshold'],
                    performance_score=tool_config['performance_score']
                )
                self.available_tools[tool.name] = tool
        
        logger.info(f"ğŸ”§ åˆå§‹åŒ–äº† {len(self.available_tools)} ä¸ªé»˜è®¤å·¥å…·")
    
    def analyze_context(self, user_input: str, conversation_history: List[str] = None) -> ContextAnalysis:
        """åˆ†æç”¨æˆ·ä¸Šä¸‹æ–‡å’Œæ„å›¾"""
        logger.info(f"ğŸ” åˆ†æä¸Šä¸‹æ–‡: {user_input[:50]}...")
        
        # å…³é”®è¯æå–
        keywords = self._extract_keywords(user_input)
        
        # ä»»åŠ¡ç±»å‹è¯†åˆ«
        task_type = self._identify_task_type(user_input, keywords)
        
        # å¤æ‚åº¦è¯„ä¼°
        complexity = self._assess_complexity(user_input, keywords)
        
        # ç´§æ€¥ç¨‹åº¦è¯„ä¼°
        urgency = self._assess_urgency(user_input, keywords)
        
        # é¢†åŸŸè¯†åˆ«
        domain = self._identify_domain(user_input, keywords)
        
        # è¯­è¨€è¯†åˆ«
        language = self._identify_language(user_input, keywords)
        
        # å·¥å…·éœ€æ±‚åˆ†æ
        tools_needed = self._analyze_tool_needs(task_type, complexity, domain)
        
        # ç½®ä¿¡åº¦è®¡ç®—
        confidence = self._calculate_confidence(keywords, task_type, complexity)
        
        # ç”¨æˆ·æ„å›¾æå–
        user_intent = self._extract_user_intent(user_input, keywords)
        
        analysis = ContextAnalysis(
            task_type=task_type,
            complexity=complexity,
            urgency=urgency,
            domain=domain,
            language=language,
            tools_needed=tools_needed,
            confidence=confidence,
            keywords=keywords,
            user_intent=user_intent
        )
        
        # å­˜å‚¨åˆ†æå†å²
        self.context_history.append(analysis)
        
        logger.info(f"ğŸ“Š ä¸Šä¸‹æ–‡åˆ†æå®Œæˆ: {task_type.value} - ç½®ä¿¡åº¦: {confidence:.2f}")
        return analysis
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # æŠ€æœ¯å…³é”®è¯
        tech_keywords = [
            'ä¼˜åŒ–', 'ç®—æ³•', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ', 'ç¥ç»ç½‘ç»œ', 'é‡å­è®¡ç®—',
            'è·¯ç”±', 'è°ƒåº¦', 'è´Ÿè½½å‡è¡¡', 'ç¼“å­˜', 'æ€§èƒ½', 'æ•ˆç‡',
            'è®°å¿†', 'å­¦ä¹ ', 'ç»éªŒ', 'çŸ¥è¯†', 'æ¨ç†', 'å†³ç­–',
            'ä»£ç ', 'ç¼–ç¨‹', 'å¼€å‘', 'æµ‹è¯•', 'è°ƒè¯•', 'é‡æ„', 'éƒ¨ç½²',
            'åˆ†æ', 'è®¾è®¡', 'æ¶æ„', 'ç³»ç»Ÿ', 'é¡¹ç›®', 'å·¥ä½œæµ',
            'python', 'java', 'javascript', 'typescript', 'react', 'vue', 'angular',
            'æ•°æ®åº“', 'api', 'å‰ç«¯', 'åç«¯', 'å…¨æ ˆ', 'å¾®æœåŠ¡'
        ]
        
        # æƒ…æ„Ÿå…³é”®è¯
        sentiment_keywords = [
            'ç´§æ€¥', 'é‡è¦', 'å…³é”®', 'ä¼˜å…ˆ', 'å¿«é€Ÿ', 'ç«‹å³', 'é©¬ä¸Š',
            'å¤æ‚', 'å›°éš¾', 'æŒ‘æˆ˜', 'é—®é¢˜', 'é”™è¯¯', 'æ•…éšœ', 'å¼‚å¸¸',
            'ç®€å•', 'å®¹æ˜“', 'åŸºç¡€', 'åŸºæœ¬', 'å…¥é—¨', 'ç¤ºä¾‹', 'æ¼”ç¤º'
        ]
        
        # é¢†åŸŸå…³é”®è¯
        domain_keywords = [
            'web', 'ç½‘ç«™', 'å‰ç«¯', 'åç«¯', 'ç§»åŠ¨', 'æ¡Œé¢', 'æ¸¸æˆ',
            'ai', 'äººå·¥æ™ºèƒ½', 'æ•°æ®ç§‘å­¦', 'å¤§æ•°æ®', 'äº‘è®¡ç®—',
            'åŒºå—é“¾', 'å®‰å…¨', 'ç½‘ç»œ', 'ç³»ç»Ÿ', 'è¿ç»´', 'DevOps'
        ]
        
        found_keywords = []
        text_lower = text.lower()
        
        for keyword_list in [tech_keywords, sentiment_keywords, domain_keywords]:
            for keyword in keyword_list:
                if keyword in text_lower:
                    found_keywords.append(keyword)
        
        return list(set(found_keywords))
    
    def _identify_task_type(self, text: str, keywords: List[str]) -> TaskType:
        """è¯†åˆ«ä»»åŠ¡ç±»å‹"""
        task_patterns = {
            TaskType.CODE_GENERATION: ['ä»£ç ', 'ç¼–ç¨‹', 'å®ç°', 'å¼€å‘', 'ç¼–å†™', 'ç”Ÿæˆ'],
            TaskType.ANALYSIS: ['åˆ†æ', 'è¯„ä¼°', 'æ£€æŸ¥', 'å®¡æŸ¥', 'è¯Šæ–­'],
            TaskType.OPTIMIZATION: ['ä¼˜åŒ–', 'æ”¹è¿›', 'æå‡', 'åŠ é€Ÿ', 'è°ƒä¼˜'],
            TaskType.DOCUMENTATION: ['æ–‡æ¡£', 'è¯´æ˜', 'æŒ‡å—', 'æ•™ç¨‹', 'æ‰‹å†Œ'],
            TaskType.TESTING: ['æµ‹è¯•', 'éªŒè¯', 'æ£€æŸ¥', 'è´¨é‡ä¿è¯'],
            TaskType.DEBUGGING: ['è°ƒè¯•', 'æ’é”™', 'æ•…éšœ', 'é—®é¢˜', 'é”™è¯¯'],
            TaskType.REFACTORING: ['é‡æ„', 'æ”¹è¿›', 'æ•´ç†', 'ä¼˜åŒ–ä»£ç '],
            TaskType.DEPLOYMENT: ['éƒ¨ç½²', 'å‘å¸ƒ', 'ä¸Šçº¿', 'è¿ç»´'],
            TaskType.RESEARCH: ['ç ”ç©¶', 'è°ƒç ”', 'æ¢ç´¢', 'æŸ¥æ‰¾'],
            TaskType.DESIGN: ['è®¾è®¡', 'æ¶æ„', 'è§„åˆ’', 'æ–¹æ¡ˆ']
        }
        
        text_lower = text.lower()
        
        for task_type, patterns in task_patterns.items():
            for pattern in patterns:
                if pattern in text_lower:
                    return task_type
        
        return TaskType.ANALYSIS  # é»˜è®¤åˆ†æç±»å‹
    
    def _assess_complexity(self, text: str, keywords: List[str]) -> str:
        """è¯„ä¼°å¤æ‚åº¦"""
        complexity_indicators = {
            'simple': ['ç®€å•', 'å®¹æ˜“', 'åŸºç¡€', 'åŸºæœ¬', 'ç¤ºä¾‹', 'æ¼”ç¤º'],
            'medium': ['ä¸­ç­‰', 'ä¸€èˆ¬', 'å¸¸è§„', 'æ ‡å‡†'],
            'complex': ['å¤æ‚', 'å›°éš¾', 'æŒ‘æˆ˜', 'é«˜çº§', 'æ·±åº¦'],
            'critical': ['å…³é”®', 'é‡è¦', 'ç´§æ€¥', 'ä¸¥é‡', 'æ ¸å¿ƒ']
        }
        
        text_lower = text.lower()
        
        for level, indicators in complexity_indicators.items():
            for indicator in indicators:
                if indicator in text_lower:
                    return level
        
        # åŸºäºé•¿åº¦å’Œå…³é”®è¯æ•°é‡è¯„ä¼°
        if len(text) > 500 or len(keywords) > 10:
            return 'complex'
        elif len(text) > 200 or len(keywords) > 5:
            return 'medium'
        else:
            return 'simple'
    
    def _assess_urgency(self, text: str, keywords: List[str]) -> str:
        """è¯„ä¼°ç´§æ€¥ç¨‹åº¦"""
        urgency_indicators = {
            'critical': ['ç´§æ€¥', 'ç«‹å³', 'é©¬ä¸Š', 'ä¸¥é‡', 'å…³é”®', 'é‡è¦'],
            'high': ['é«˜', 'ä¼˜å…ˆ', 'å°½å¿«', 'éœ€è¦', 'å¿…é¡»'],
            'normal': ['æ­£å¸¸', 'æ ‡å‡†', 'å¸¸è§„', 'ä¸€èˆ¬'],
            'low': ['ä½', 'å¯ä»¥', 'å»ºè®®', 'å¯é€‰', 'ç¨å']
        }
        
        text_lower = text.lower()
        
        for level, indicators in urgency_indicators.items():
            for indicator in indicators:
                if indicator in text_lower:
                    return level
        
        return 'normal'
    
    def _identify_domain(self, text: str, keywords: List[str]) -> str:
        """è¯†åˆ«é¢†åŸŸ"""
        domain_patterns = {
            'web': ['web', 'ç½‘ç«™', 'å‰ç«¯', 'åç«¯', 'ç½‘é¡µ', 'æµè§ˆå™¨'],
            'mobile': ['ç§»åŠ¨', 'æ‰‹æœº', 'app', 'åº”ç”¨', 'ios', 'android'],
            'ai': ['ai', 'äººå·¥æ™ºèƒ½', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ', 'ç¥ç»ç½‘ç»œ'],
            'data': ['æ•°æ®', 'æ•°æ®åº“', 'å¤§æ•°æ®', 'åˆ†æ', 'å¤„ç†'],
            'system': ['ç³»ç»Ÿ', 'æ¶æ„', 'è®¾è®¡', 'åŸºç¡€è®¾æ–½', 'è¿ç»´']
        }
        
        text_lower = text.lower()
        
        for domain, patterns in domain_patterns.items():
            for pattern in patterns:
                if pattern in text_lower:
                    return domain
        
        return 'general'
    
    def _identify_language(self, text: str, keywords: List[str]) -> Optional[str]:
        """è¯†åˆ«ç¼–ç¨‹è¯­è¨€"""
        language_patterns = {
            'python': ['python', 'py', '.py'],
            'javascript': ['javascript', 'js', '.js', 'node', 'nodejs'],
            'typescript': ['typescript', 'ts', '.ts'],
            'java': ['java', '.java'],
            'go': ['go', '.go'],
            'rust': ['rust', '.rs'],
            'cpp': ['cpp', 'c++', '.cpp'],
            'c': ['c', '.c'],
            'html': ['html', '.html', 'web'],
            'css': ['css', '.css', 'æ ·å¼'],
            'sql': ['sql', 'database', 'æ•°æ®åº“']
        }
        
        text_lower = text.lower()
        
        for language, patterns in language_patterns.items():
            for pattern in patterns:
                if pattern in text_lower:
                    return language
        
        return None
    
    def _analyze_tool_needs(self, task_type: TaskType, complexity: str, domain: str) -> List[str]:
        """åˆ†æå·¥å…·éœ€æ±‚"""
        tool_needs = []
        
        # åŸºäºä»»åŠ¡ç±»å‹çš„å·¥å…·éœ€æ±‚
        task_tool_mapping = {
            TaskType.OPTIMIZATION: ['adaptive_quantum_annealing', 'reinforcement_learning_agent'],
            TaskType.CODE_GENERATION: ['quantum_intelligent_router', 'agent_memory_system'],
            TaskType.ANALYSIS: ['quantum_intelligent_router', 'agent_memory_system'],
            TaskType.DOCUMENTATION: ['agent_memory_system'],
            TaskType.TESTING: ['agent_memory_system'],
            TaskType.DEBUGGING: ['agent_memory_system', 'quantum_intelligent_router'],
            TaskType.REFACTORING: ['reinforcement_learning_agent', 'agent_memory_system'],
            TaskType.DEPLOYMENT: ['quantum_intelligent_router']
        }
        
        # åŸºäºå¤æ‚åº¦çš„å·¥å…·é€‰æ‹©
        if complexity in ['complex', 'critical']:
            # é«˜å¤æ‚åº¦éœ€è¦å¤šä¸ªå·¥å…·åä½œ
            base_tools = task_tool_mapping.get(task_type, [])
            if base_tools:
                tool_needs.extend(base_tools)
            
            # æ·»åŠ é€šç”¨å·¥å…·
            tool_needs.extend(['agent_memory_system', 'quantum_intelligent_router'])
        else:
            # ç®€å•ä»»åŠ¡ä½¿ç”¨å•ä¸ªå·¥å…·
            tool_needs = task_tool_mapping.get(task_type, ['quantum_intelligent_router'])
        
        # åŸºäºé¢†åŸŸçš„å·¥å…·è°ƒæ•´
        if domain == 'ai':
            if 'reinforcement_learning_agent' not in tool_needs:
                tool_needs.append('reinforcement_learning_agent')
        elif domain == 'system':
            if 'adaptive_quantum_annealing' not in tool_needs:
                tool_needs.append('adaptive_quantum_annealing')
        
        return list(set(tool_needs))
    
    def _calculate_confidence(self, keywords: List[str], task_type: TaskType, complexity: str) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦"""
        base_confidence = 0.5
        
        # åŸºäºå…³é”®è¯åŒ¹é…åº¦
        keyword_score = min(1.0, len(keywords) / 10.0)
        
        # åŸºäºä»»åŠ¡ç±»å‹æ˜ç¡®åº¦
        type_confidence = 0.8 if task_type != TaskType.ANALYSIS else 0.6
        
        # åŸºäºå¤æ‚åº¦åŒ¹é…
        complexity_scores = {'simple': 0.9, 'medium': 0.7, 'complex': 0.5, 'critical': 0.3}
        complexity_score = complexity_scores.get(complexity, 0.5)
        
        confidence = (base_confidence + keyword_score + type_confidence + complexity_score) / 4.0
        return min(1.0, confidence)
    
    def _extract_user_intent(self, text: str, keywords: List[str]) -> str:
        """æå–ç”¨æˆ·æ„å›¾"""
        # ç®€åŒ–çš„æ„å›¾æå–
        if any(word in text.lower() for word in ['ä¼˜åŒ–', 'æ”¹è¿›', 'æå‡']):
            return "ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½"
        elif any(word in text.lower() for word in ['åˆ†æ', 'æ£€æŸ¥', 'è¯„ä¼°']):
            return "åˆ†æç°çŠ¶é—®é¢˜"
        elif any(word in text.lower() for word in ['å­¦ä¹ ', 'ç»éªŒ', 'æ•™è®­']):
            return "ä»ç»éªŒä¸­å­¦ä¹ "
        elif any(word in text.lower() for word in ['å®ç°', 'å¼€å‘', 'åˆ›å»º']):
            return "å¼€å‘æ–°åŠŸèƒ½"
        elif any(word in text.lower() for word in ['ä¿®å¤', 'è§£å†³', 'å¤„ç†']):
            return "è§£å†³é—®é¢˜"
        else:
            return "ä¸€èˆ¬å’¨è¯¢"
    
    def should_auto_call_tool(self, tool_name: str, context: ContextAnalysis) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è‡ªåŠ¨è°ƒç”¨å·¥å…·"""
        if tool_name not in self.available_tools:
            return False
        
        tool = self.available_tools[tool_name]
        
        # åŸºäºé˜ˆå€¼åˆ¤æ–­
        if context.confidence < tool.auto_call_threshold:
            return False
        
        # åŸºäºç´§æ€¥ç¨‹åº¦åˆ¤æ–­
        if context.urgency in ['critical', 'high'] and tool.priority >= 7:
            return True
        
        # åŸºäºä»»åŠ¡ç±»å‹åŒ¹é…
        if context.task_type in tool.task_types and tool.priority >= 8:
            return True
        
        # åŸºäºæ€§èƒ½åˆ†æ•°åˆ¤æ–­
        if tool.performance_score >= 0.8:
            return True
        
        return False
    
    def select_optimal_tools(self, context: ContextAnalysis) -> List[MCPTool]:
        """é€‰æ‹©æœ€ä¼˜å·¥å…·ç»„åˆ"""
        candidate_tools = []
        
        for tool_name in context.tools_needed:
            if tool_name in self.available_tools:
                tool = self.available_tools[tool_name]
                
                # è®¡ç®—å·¥å…·åŒ¹é…åˆ†æ•°
                match_score = 0.0
                
                # ä»»åŠ¡ç±»å‹åŒ¹é…
                if context.task_type in tool.task_types:
                    match_score += 0.4
                
                # ä¼˜å…ˆçº§æƒé‡
                match_score += tool.priority / 10.0 * 0.3
                
                # æ€§èƒ½æƒé‡
                match_score += tool.performance_score * 0.2
                
                # å¤æ‚åº¦é€‚é…
                complexity_scores = {'simple': 0.3, 'medium': 0.2, 'complex': 0.1, 'critical': 0.05}
                match_score += complexity_scores.get(context.complexity, 0.2)
                
                candidate_tools.append((match_score, tool))
        
        # æ’åºå¹¶è¿”å›
        candidate_tools.sort(key=lambda x: x[0], reverse=True)
        return [tool for score, tool in candidate_tools]
    
    async def auto_call_tools(self, context: ContextAnalysis) -> Dict[str, Any]:
        """è‡ªåŠ¨è°ƒç”¨å·¥å…·"""
        logger.info("ğŸ¤– è‡ªåŠ¨è°ƒç”¨MCPå·¥å…·...")
        
        results = {}
        
        # é€‰æ‹©æœ€ä¼˜å·¥å…·
        optimal_tools = self.select_optimal_tools(context)
        
        for tool in optimal_tools:
            if self.should_auto_call_tool(tool.name, context):
                try:
                    logger.info(f"ğŸ”§ è‡ªåŠ¨è°ƒç”¨å·¥å…·: {tool.name}")
                    
                    # æ‰§è¡Œå·¥å…·è°ƒç”¨
                    result = await self._execute_tool(tool, context)
                    results[tool.name] = result
                    
                    # æ›´æ–°æ€§èƒ½å†å²
                    self.tool_performance[tool.name].append({
                        'timestamp': time.time(),
                        'success': result.get('success', False),
                        'execution_time': result.get('execution_time', 0),
                        'context': context.user_intent
                    })
                    
                    # å­¦ä¹ å’Œä¼˜åŒ–
                    if self.learning_enabled:
                        self._update_tool_performance(tool.name, result)
                    
                except Exception as e:
                    logger.error(f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥ {tool.name}: {e}")
                    results[tool.name] = {
                        'success': False,
                        'error': str(e),
                        'execution_time': 0
                    }
        
        return results
    
    async def _execute_tool(self, tool: MCPTool, context: ContextAnalysis) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
        start_time = time.time()
        
        try:
            # æ„å»ºå‘½ä»¤
            command = tool.command_pattern
            
            # æ·»åŠ ä¸Šä¸‹æ–‡å‚æ•°
            if context.domain:
                command += f" --domain {context.domain}"
            if context.language:
                command += f" --language {context.language}"
            if context.complexity:
                command += f" --complexity {context.complexity}"
            
            # æ‰§è¡Œå‘½ä»¤
            process = await asyncio.create_subprocess_shell(
                command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=Path.cwd()
            )
            
            stdout, stderr = await process.communicate()
            
            execution_time = time.time() - start_time
            
            # åˆ†ææ‰§è¡Œç»“æœ
            success = self._analyze_execution_result(
                stdout, stderr, tool.success_indicators, tool.failure_indicators
            )
            
            return {
                'success': success,
                'stdout': stdout,
                'stderr': stderr,
                'execution_time': execution_time,
                'command': command
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'execution_time': time.time() - start_time
            }
    
    def _analyze_execution_result(self, stdout: str, stderr: str, 
                                 success_indicators: List[str], 
                                 failure_indicators: List[str]) -> bool:
        """åˆ†ææ‰§è¡Œç»“æœ"""
        stdout_lower = stdout.lower() if stdout else ""
        stderr_lower = stderr.lower() if stderr else ""
        
        # æ£€æŸ¥æˆåŠŸæŒ‡æ ‡
        for indicator in success_indicators:
            if indicator.lower() in stdout_lower:
                return True
        
        # æ£€æŸ¥å¤±è´¥æŒ‡æ ‡
        for indicator in failure_indicators:
            if indicator.lower() in stderr_lower or indicator.lower() in stdout_lower:
                return False
        
        # é»˜è®¤è®¤ä¸ºæˆåŠŸï¼ˆå¦‚æœæ²¡æœ‰æ˜ç¡®çš„å¤±è´¥æŒ‡æ ‡ï¼‰
        return True
    
    def _update_tool_performance(self, tool_name: str, result: Dict[str, Any]):
        """æ›´æ–°å·¥å…·æ€§èƒ½åˆ†æ•°"""
        if tool_name not in self.available_tools:
            return
        
        tool = self.available_tools[tool_name]
        
        # åŸºäºæ‰§è¡Œç»“æœæ›´æ–°æ€§èƒ½åˆ†æ•°
        current_score = tool.performance_score
        success = result.get('success', False)
        execution_time = result.get('execution_time', 0)
        
        if success:
            # æˆåŠŸæ‰§è¡Œæå‡æ€§èƒ½åˆ†æ•°
            improvement = min(0.1, 1.0 - current_score)
            tool.performance_score = min(1.0, current_score + improvement)
        else:
            # å¤±è´¥æ‰§è¡Œé™ä½æ€§èƒ½åˆ†æ•°
            degradation = min(0.2, current_score)
            tool.performance_score = max(0.1, current_score - degradation)
        
        # è®°å½•è‡ªåŠ¨è°ƒç”¨å†å²
        self.auto_call_history[tool_name].append({
            'timestamp': time.time(),
            'success': success,
            'execution_time': execution_time
        })
        
        # é™åˆ¶å†å²è®°å½•æ•°é‡
        if len(self.auto_call_history[tool_name]) > 100:
            self.auto_call_history[tool_name].pop(0)
        
        logger.debug(f"ğŸ“Š æ›´æ–°å·¥å…·æ€§èƒ½: {tool_name} - æ–°åˆ†æ•°: {tool.performance_score:.2f}")
    
    def _performance_monitor(self):
        """æ€§èƒ½ç›‘æ§çº¿ç¨‹"""
        while True:
            try:
                time.sleep(30)  # 30ç§’é—´éš”
                
                # åˆ†æå·¥å…·æ€§èƒ½è¶‹åŠ¿
                for tool_name, history in self.tool_performance.items():
                    if len(history) >= 5:
                        recent_performance = history[-5:]
                        success_rate = sum(1 for record in recent_performance if record['success']) / len(recent_performance)
                        avg_time = sum(record['execution_time'] for record in recent_performance) / len(recent_performance)
                        
                        # æ›´æ–°å·¥å…·æ€§èƒ½åˆ†æ•°
                        if tool_name in self.available_tools:
                            tool = self.available_tools[tool_name]
                            if success_rate > 0.8 and avg_time < 10:
                                tool.performance_score = min(1.0, tool.performance_score + 0.05)
                            elif success_rate < 0.5 or avg_time > 30:
                                tool.performance_score = max(0.1, tool.performance_score - 0.1)
                        
                        logger.debug(f"ğŸ“ˆ æ€§èƒ½ç›‘æ§: {tool_name} - æˆåŠŸç‡: {success_rate:.2f}, å¹³å‡æ—¶é—´: {avg_time:.2f}s")
                
            except Exception as e:
                logger.error(f"âŒ æ€§èƒ½ç›‘æ§é”™è¯¯: {e}")
    
    def get_tool_recommendations(self, context: ContextAnalysis) -> List[MCPTool]:
        """è·å–å·¥å…·æ¨è"""
        recommendations = []
        
        # åŸºäºä¸Šä¸‹æ–‡æ¨èå·¥å…·
        all_tools = list(self.available_tools.values())
        
        for tool in all_tools:
            # è®¡ç®—æ¨èåˆ†æ•°
            recommendation_score = 0.0
            
            # ä»»åŠ¡ç±»å‹åŒ¹é…åº¦
            if context.task_type in tool.task_types:
                recommendation_score += 0.4
            
            # é¢†åŸŸåŒ¹é…åº¦
            domain_tools = {
                'ai': ['reinforcement_learning_agent', 'adaptive_quantum_annealing'],
                'system': ['adaptive_quantum_annealing', 'quantum_intelligent_router'],
                'web': ['quantum_intelligent_router', 'agent_memory_system'],
                'data': ['agent_memory_system', 'quantum_intelligent_router']
            }
            
            if context.domain in domain_tools:
                for recommended_tool in domain_tools[context.domain]:
                    if recommended_tool in self.available_tools:
                        tool = self.available_tools[recommended_tool]
                        recommendation_score += 0.3
            
            # æ€§èƒ½åˆ†æ•°æƒé‡
            recommendation_score += tool.performance_score * 0.3
            
            # åŸºäºå¤æ‚åº¦çš„å·¥å…·é€‚é…
            if context.complexity == 'simple':
                simple_tools = ['quantum_intelligent_router', 'agent_memory_system']
                if tool.name in simple_tools:
                    recommendation_score += 0.2
            elif context.complexity in ['complex', 'critical']:
                complex_tools = ['adaptive_quantum_annealing', 'reinforcement_learning_agent']
                if tool.name in complex_tools:
                    recommendation_score += 0.2
            
            recommendations.append((recommendation_score, tool))
        
        # æ’åºå¹¶è¿”å›
        recommendations.sort(key=lambda x: x[0], reverse=True)
        return [tool for score, tool in recommendations]
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total_tools = len(self.available_tools)
        auto_call_count = sum(len(history) for history in self.auto_call_history.values())
        avg_performance = sum(tool.performance_score for tool in self.available_tools.values()) / len(self.available_tools) if self.available_tools else 0
        
        return {
            'total_tools': total_tools,
            'auto_call_count': auto_call_count,
            'average_performance': avg_performance,
            'context_analysis_count': len(self.context_history),
            'performance_monitoring_active': self.performance_monitor_thread.is_alive(),
            'learning_enabled': self.learning_enabled,
            'tool_details': {
                tool.name: {
                    'name': tool.name,
                    'performance_score': tool.performance_score,
                    'auto_call_count': len(self.auto_call_history.get(tool.name, [])),
                    'success_rate': self._calculate_success_rate(tool.name)
                } for tool in self.available_tools.values()
            }
        }
    
    def _calculate_success_rate(self, tool_name: str) -> float:
        """è®¡ç®—å·¥å…·æˆåŠŸç‡"""
        history = self.auto_call_history.get(tool_name, [])
        if not history:
            return 0.0
        
        successful_calls = sum(1 for record in history if record['success'])
        return successful_calls / len(history)
    
    def save_configuration(self, filepath: str = None):
        """ä¿å­˜é…ç½®"""
        if filepath is None:
            filepath = self.config_path
        
        config = {
            'tools': [asdict(tool) for tool in self.available_tools.values()],
            'learning_enabled': self.learning_enabled,
            'auto_call_history': dict(self.auto_call_history),
            'performance_history': dict(self.tool_performance)
        }
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ’¾ é…ç½®å·²ä¿å­˜åˆ°: {filepath}")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜é…ç½®å¤±è´¥: {e}")
    
    def load_configuration(self, filepath: str = None):
        """åŠ è½½é…ç½®"""
        if filepath is None:
            filepath = self.config_path
        
        if not Path(filepath).exists():
            logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
            return
        
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # é‡æ–°åŠ è½½å·¥å…·é…ç½®
            self.available_tools.clear()
            for tool_config in config.get('tools', []):
                tool = MCPTool(
                    name=tool_config['name'],
                    description=tool_config['description'],
                    capabilities=tool_config['capabilities'],
                    task_types=[TaskType(t) for t in tool_config['task_types']],
                    priority=tool_config['priority'],
                    command_pattern=tool_config.get('command_pattern', ''),
                    example_usage=tool_config.get('example_usage', ''),
                    success_indicators=tool_config.get('success_indicators', []),
                    failure_indicators=tool_config.get('failure_indicators', []),
                    auto_call_threshold=tool_config.get('auto_call_threshold', 0.7),
                    performance_score=tool_config.get('performance_score', 0.5)
                )
                self.available_tools[tool.name] = tool
            
            self.learning_enabled = config.get('learning_enabled', True)
            self.auto_call_history = defaultdict(list, config.get('auto_call_history', {}))
            self.tool_performance = defaultdict(list, config.get('performance_history', {}))
            
            logger.info(f"ğŸ“‚ é…ç½®å·²ä» {filepath} åŠ è½½")
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½é…ç½®å¤±è´¥: {e}")

# ç¤ºä¾‹ä½¿ç”¨
async def example_intelligent_mcp_usage():
    """ç¤ºä¾‹æ™ºèƒ½MCPä½¿ç”¨"""
    manager = IntelligentMCPManager()
    
    # æ¨¡æ‹Ÿç”¨æˆ·è¾“å…¥
    user_inputs = [
        "æˆ‘éœ€è¦ä¼˜åŒ–è¿™ä¸ªPythoné¡¹ç›®çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯ç®—æ³•éƒ¨åˆ†",
        "å¸®æˆ‘åˆ†æè¿™ä¸ªå¤æ‚çš„ç³»ç»Ÿæ¶æ„é—®é¢˜",
        "åˆ›å»ºä¸€ä¸ªç”¨æˆ·è®¤è¯ç³»ç»Ÿçš„ä»£ç ç¤ºä¾‹",
        "è°ƒè¯•è¿™ä¸ªå†…å­˜æ³„æ¼é—®é¢˜",
        "ä»ä¹‹å‰çš„é”™è¯¯ä¸­å­¦ä¹ ç»éªŒ"
    ]
    
    for user_input in user_inputs:
        print(f"\nğŸ“ ç”¨æˆ·è¾“å…¥: {user_input}")
        
        # åˆ†æä¸Šä¸‹æ–‡
        context = manager.analyze_context(user_input)
        
        print(f"ğŸ” åˆ†æç»“æœ: {context.task_type.value} - å¤æ‚åº¦: {context.complexity} - ç½®ä¿¡åº¦: {context.confidence:.2f}")
        print(f"ğŸ¯ ç”¨æˆ·æ„å›¾: {context.user_intent}")
        print(f"ğŸ”§ æ¨èå·¥å…·: {[tool.name for tool in manager.select_optimal_tools(context)]}")
        
        # è‡ªåŠ¨è°ƒç”¨å·¥å…·ï¼ˆå¦‚æœæ»¡è¶³æ¡ä»¶ï¼‰
        if context.confidence > 0.7:
            results = await manager.auto_call_tools(context)
            print(f"ğŸ¤– è‡ªåŠ¨è°ƒç”¨ç»“æœ: {list(results.keys())}")
            
            for tool_name, result in results.items():
                if result['success']:
                    print(f"âœ… {tool_name}: æ‰§è¡ŒæˆåŠŸ ({result['execution_time']:.2f}s)")
                else:
                    print(f"âŒ {tool_name}: æ‰§è¡Œå¤±è´¥ - {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        print("-" * 50)

if __name__ == "__main__":
    asyncio.run(example_intelligent_mcp_usage())
