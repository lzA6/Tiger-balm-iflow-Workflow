#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½é¡¹ç›®åˆ†æå’Œæ¶æ„è®¾è®¡ç³»ç»Ÿ
Intelligent Project Analysis and Architecture Design System

ä½œè€…: Quantum AI Team
ç‰ˆæœ¬: 5.2.0
æ—¥æœŸ: 2025-11-12
"""

import os
import re
import ast
import json
import time
import asyncio
import logging
import subprocess
from typing import Dict, List, Any, Optional, Union, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
from enum import Enum
from collections import defaultdict, Counter
import hashlib
import mimetypes
import sys

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ProjectType(Enum):
    """é¡¹ç›®ç±»å‹"""
    WEB_APP = "web_application"
    MOBILE_APP = "mobile_application"
    DESKTOP_APP = "desktop_application"
    API_SERVICE = "api_service"
    MICROSERVICE = "microservice"
    LIBRARY = "library"
    CLI_TOOL = "cli_tool"
    DATA_PIPELINE = "data_pipeline"
    MACHINE_LEARNING = "machine_learning"
    GAME = "game"
    EMBEDDED = "embedded"
    UNKNOWN = "unknown"

class ArchitecturePattern(Enum):
    """æ¶æ„æ¨¡å¼"""
    MONOLITH = "monolith"
    MICROSERVICES = "microservices"
    EVENT_DRIVEN = "event_driven"
    CQRS = "cqrs"
    HEXAGONAL = "hexagonal"
    LAYERED = "layered"
    MVC = "mvc"
    MVP = "mvp"
    MVVM = "mvvm"
    CLEAN_ARCHITECTURE = "clean_architecture"
    SERVERLESS = "serverless"
    UNKNOWN = "unknown"

class TechnologyStack(Enum):
    """æŠ€æœ¯æ ˆ"""
    PYTHON_DJANGO = "python_django"
    PYTHON_FASTAPI = "python_fastapi"
    PYTHON_FLASK = "python_flask"
    NODE_EXPRESS = "node_express"
    REACT = "react"
    VUE = "vue"
    ANGULAR = "angular"
    JAVA_SPRING = "java_spring"
    DOTNET_CORE = "dotnet_core"
    GO = "go"
    RUST = "rust"
    UNKNOWN = "unknown"

@dataclass
class ProjectMetrics:
    """é¡¹ç›®æŒ‡æ ‡"""
    total_files: int
    total_lines: int
    code_lines: int
    comment_lines: int
    blank_lines: int
    file_types: Dict[str, int]
    dependencies: Dict[str, List[str]]
    complexity_score: float
    maintainability_index: float
    test_coverage: float

@dataclass
class ArchitectureComponent:
    """æ¶æ„ç»„ä»¶"""
    component_id: str
    name: str
    type: str  # service, controller, model, etc.
    file_path: str
    dependencies: List[str]
    complexity: float
    responsibilities: List[str]
    interfaces: List[str]

@dataclass
class ArchitectureAnalysis:
    """æ¶æ„åˆ†æç»“æœ"""
    project_type: ProjectType
    architecture_pattern: ArchitecturePattern
    technology_stack: TechnologyStack
    components: List[ArchitectureComponent]
    metrics: ProjectMetrics
    recommendations: List[str]
    issues: List[str]
    strengths: List[str]

class ProjectAnalyzer:
    """é¡¹ç›®åˆ†æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–é¡¹ç›®åˆ†æå™¨"""
        self.file_analyzers = {
            '.py': self._analyze_python_file,
            '.js': self._analyze_javascript_file,
            '.ts': self._analyze_typescript_file,
            '.java': self._analyze_java_file,
            '.cs': self._analyze_csharp_file,
            '.go': self._analyze_go_file,
            '.rs': self._analyze_rust_file,
            '.cpp': self._analyze_cpp_file,
            '.c': self._analyze_cpp_file,
            '.h': self._analyze_cpp_file,
            '.hpp': self._analyze_cpp_file,
            '.json': self._analyze_json_file,
            '.yaml': self._analyze_yaml_file,
            '.yml': self._analyze_yaml_file,
            '.md': self._analyze_markdown_file,
            '.txt': self._analyze_text_file
        }
        
        self.project_indicators = {
            ProjectType.WEB_APP: [
                'package.json', 'requirements.txt', 'pipfile', 'poetry.lock',
                'index.html', 'app.js', 'main.js', 'server.js', 'app.py',
                'templates', 'static', 'public', 'src', 'components'
            ],
            ProjectType.MOBILE_APP: [
                'android', 'ios', 'mobile', 'react-native', 'flutter',
                'cordova', 'ionic', 'xamarin', 'native', 'app.json'
            ],
            ProjectType.DESKTOP_APP: [
                'electron', 'qt', 'gtk', 'wxwidgets', 'winforms', 'wpf',
                'desktop', 'gui', 'ui', 'mainwindow', 'application'
            ],
            ProjectType.API_SERVICE: [
                'api', 'rest', 'graphql', 'grpc', 'endpoint', 'service',
                'controller', 'handler', 'route', 'middleware'
            ],
            ProjectType.MICROSERVICE: [
                'microservice', 'service', 'docker', 'kubernetes', 'k8s',
                'consul', 'eureka', 'zuul', 'gateway', 'discovery'
            ],
            ProjectType.LIBRARY: [
                'lib', 'library', 'package', 'module', 'setup.py',
                'pom.xml', 'build.gradle', 'cargo.toml', 'go.mod'
            ],
            ProjectType.CLI_TOOL: [
                'cli', 'command', 'terminal', 'console', 'argparse',
                'click', 'commander', 'yargs', 'main.py', 'index.js'
            ],
            ProjectType.DATA_PIPELINE: [
                'pipeline', 'etl', 'spark', 'hadoop', 'airflow',
                'kafka', 'data', 'analytics', 'batch', 'stream'
            ],
            ProjectType.MACHINE_LEARNING: [
                'ml', 'machine_learning', 'ai', 'model', 'training',
                'tensorflow', 'pytorch', 'scikit', 'jupyter', 'notebook'
            ],
            ProjectType.GAME: [
                'game', 'unity', 'unreal', 'godot', 'pygame',
                'sprite', 'engine', 'physics', 'rendering', 'player'
            ]
        }
        
        self.technology_indicators = {
            TechnologyStack.PYTHON_DJANGO: [
                'django', 'wsgi.py', 'settings.py', 'urls.py', 'views.py',
                'models.py', 'forms.py', 'admin.py', 'manage.py'
            ],
            TechnologyStack.PYTHON_FASTAPI: [
                'fastapi', 'pydantic', 'uvicorn', 'main.py', 'api',
                'endpoint', 'async', 'dependency injection'
            ],
            TechnologyStack.PYTHON_FLASK: [
                'flask', 'app.py', 'route', 'template', 'jinja2',
                'werkzeug', 'request', 'response'
            ],
            TechnologyStack.NODE_EXPRESS: [
                'express', 'node.js', 'npm', 'package.json', 'app.js',
                'server.js', 'middleware', 'router', 'req', 'res'
            ],
            TechnologyStack.REACT: [
                'react', 'jsx', 'component', 'hooks', 'state',
                'props', 'render', 'useEffect', 'useState'
            ],
            TechnologyStack.VUE: [
                'vue', 'vue.js', 'component', 'template', 'script',
                'data', 'methods', 'computed', 'watch'
            ],
            TechnologyStack.ANGULAR: [
                'angular', 'typescript', 'component', 'service',
                'module', 'directive', 'pipe', 'injectable'
            ],
            TechnologyStack.JAVA_SPRING: [
                'spring', 'springboot', '@controller', '@service',
                '@repository', '@entity', 'application.properties',
                'pom.xml', 'maven'
            ],
            TechnologyStack.DOTNET_CORE: [
                '.net', 'csharp', 'asp.net', 'controller', 'model',
                'view', 'startup.cs', 'program.cs', 'project.json'
            ],
            TechnologyStack.GO: [
                'go', 'golang', 'package main', 'func main',
                'gorilla', 'gin', 'echo', 'handler', 'middleware'
            ],
            TechnologyStack.RUST: [
                'rust', 'cargo.toml', 'fn main', 'impl', 'struct',
                'trait', 'mod', 'use', 'std', 'tokio'
            ]
        }
    
    async def analyze_project(self, project_path: str) -> ArchitectureAnalysis:
        """åˆ†æé¡¹ç›®"""
        logger.info(f"ğŸ” å¼€å§‹åˆ†æé¡¹ç›®: {project_path}")
        
        project_path = Path(project_path)
        if not project_path.exists():
            raise ValueError(f"é¡¹ç›®è·¯å¾„ä¸å­˜åœ¨: {project_path}")
        
        # æ‰«æé¡¹ç›®æ–‡ä»¶
        files = await self._scan_project_files(project_path)
        
        # åˆ†æé¡¹ç›®æŒ‡æ ‡
        metrics = await self._analyze_project_metrics(files, project_path)
        
        # æ£€æµ‹é¡¹ç›®ç±»å‹
        project_type = self._detect_project_type(files, project_path)
        
        # æ£€æµ‹æŠ€æœ¯æ ˆ
        technology_stack = self._detect_technology_stack(files, project_path)
        
        # åˆ†ææ¶æ„ç»„ä»¶
        components = await self._analyze_architecture_components(files, project_path, technology_stack)
        
        # æ£€æµ‹æ¶æ„æ¨¡å¼
        architecture_pattern = self._detect_architecture_pattern(components, project_type, technology_stack)
        
        # ç”Ÿæˆå»ºè®®å’Œé—®é¢˜
        recommendations, issues, strengths = await self._generate_recommendations(
            project_type, architecture_pattern, technology_stack, components, metrics
        )
        
        analysis = ArchitectureAnalysis(
            project_type=project_type,
            architecture_pattern=architecture_pattern,
            technology_stack=technology_stack,
            components=components,
            metrics=metrics,
            recommendations=recommendations,
            issues=issues,
            strengths=strengths
        )
        
        logger.info(f"âœ… é¡¹ç›®åˆ†æå®Œæˆ: {project_type.value} - {technology_stack.value}")
        return analysis
    
    async def _scan_project_files(self, project_path: Path) -> List[Path]:
        """æ‰«æé¡¹ç›®æ–‡ä»¶"""
        files = []
        
        # æ’é™¤çš„ç›®å½•
        exclude_dirs = {
            '.git', '.svn', '__pycache__', 'node_modules', '.vscode',
            '.idea', 'build', 'dist', 'target', 'bin', 'obj', 'out',
            '.pytest_cache', '.coverage', 'htmlcov', '.tox', 'venv', 'env'
        }
        
        # æ’é™¤çš„æ–‡ä»¶æ‰©å±•å
        exclude_extensions = {
            '.pyc', '.pyo', '.pyd', '.dll', '.exe', '.so', '.dylib',
            '.log', '.tmp', '.cache', '.bak', '.swp', '.swo'
        }
        
        for file_path in project_path.rglob('*'):
            if file_path.is_file():
                # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤ç›®å½•ä¸­
                if any(exclude_dir in file_path.parts for exclude_dir in exclude_dirs):
                    continue
                
                # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
                if file_path.suffix.lower() in exclude_extensions:
                    continue
                
                files.append(file_path)
        
        logger.info(f"ğŸ“ æ‰«æåˆ° {len(files)} ä¸ªæ–‡ä»¶")
        return files
    
    async def _analyze_project_metrics(self, files: List[Path], project_path: Path) -> ProjectMetrics:
        """åˆ†æé¡¹ç›®æŒ‡æ ‡"""
        total_files = len(files)
        total_lines = 0
        code_lines = 0
        comment_lines = 0
        blank_lines = 0
        file_types = Counter()
        dependencies = defaultdict(list)
        
        # åˆ†ææ¯ä¸ªæ–‡ä»¶
        for file_path in files:
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                lines = content.split('\n')
                file_total_lines = len(lines)
                file_code_lines = 0
                file_comment_lines = 0
                file_blank_lines = 0
                
                for line in lines:
                    stripped = line.strip()
                    if not stripped:
                        file_blank_lines += 1
                    elif stripped.startswith('#') or stripped.startswith('//') or stripped.startswith('/*'):
                        file_comment_lines += 1
                    else:
                        file_code_lines += 1
                
                total_lines += file_total_lines
                code_lines += file_code_lines
                comment_lines += file_comment_lines
                blank_lines += file_blank_lines
                
                # ç»Ÿè®¡æ–‡ä»¶ç±»å‹
                file_types[file_path.suffix.lower()] += 1
                
                # æå–ä¾èµ–
                file_deps = self._extract_dependencies(content, file_path.suffix.lower())
                for dep in file_deps:
                    dependencies[file_path.suffix.lower()].append(dep)
                
            except Exception as e:
                logger.debug(f"åˆ†ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        # è®¡ç®—å¤æ‚åº¦å’Œå¯ç»´æŠ¤æ€§æŒ‡æ•°
        complexity_score = self._calculate_complexity_score(code_lines, comment_lines, total_files)
        maintainability_index = self._calculate_maintainability_index(code_lines, comment_lines, complexity_score)
        
        # ä¼°ç®—æµ‹è¯•è¦†ç›–ç‡
        test_coverage = self._estimate_test_coverage(files, project_path)
        
        return ProjectMetrics(
            total_files=total_files,
            total_lines=total_lines,
            code_lines=code_lines,
            comment_lines=comment_lines,
            blank_lines=blank_lines,
            file_types=dict(file_types),
            dependencies=dict(dependencies),
            complexity_score=complexity_score,
            maintainability_index=maintainability_index,
            test_coverage=test_coverage
        )
    
    def _extract_dependencies(self, content: str, file_extension: str) -> List[str]:
        """æå–ä¾èµ–"""
        dependencies = []
        
        if file_extension == '.py':
            # Python imports
            import_patterns = [
                r'^import\s+([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)*)',
                r'^from\s+([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)*)\s+import',
                r'^from\s+\.([a-zA-Z_][a-zA-Z0-9_]*)\s+import'
            ]
            
            for pattern in import_patterns:
                matches = re.findall(pattern, content, re.MULTILINE)
                dependencies.extend(matches)
        
        elif file_extension in ['.js', '.ts']:
            # JavaScript/TypeScript imports
            import_patterns = [
                r'^import\s+.*\s+from\s+[\'"]([^\'"]+)[\'"]',
                r'^const\s+.*=\s+require\([\'"]([^\'"]+)[\'"]',
                r'^import\s+[\'"]([^\'"]+)[\'"]'
            ]
            
            for pattern in import_patterns:
                matches = re.findall(pattern, content, re.MULTILINE)
                dependencies.extend(matches)
        
        elif file_extension == '.java':
            # Java imports
            import_pattern = r'^import\s+([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)*)'
            matches = re.findall(import_pattern, content, re.MULTILINE)
            dependencies.extend(matches)
        
        elif file_extension == '.cs':
            # C# using statements
            using_pattern = r'^using\s+([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)*)'
            matches = re.findall(using_pattern, content, re.MULTILINE)
            dependencies.extend(matches)
        
        elif file_extension == '.go':
            # Go imports
            import_pattern = r'^import\s+[\'"]([^\'"]+)[\'"]'
            matches = re.findall(import_pattern, content, re.MULTILINE)
            dependencies.extend(matches)
        
        elif file_extension == '.rs':
            # Rust imports
            import_patterns = [
                r'^use\s+([a-zA-Z_][a-zA-Z0-9_]*(?::[a-zA-Z_][a-zA-Z0-9_]*)*)',
                r'^extern\s+crate\s+([a-zA-Z_][a-zA-Z0-9_]*)'
            ]
            
            for pattern in import_patterns:
                matches = re.findall(pattern, content, re.MULTILINE)
                dependencies.extend(matches)
        
        return list(set(dependencies))  # å»é‡
    
    def _calculate_complexity_score(self, code_lines: int, comment_lines: int, file_count: int) -> float:
        """è®¡ç®—å¤æ‚åº¦åˆ†æ•°"""
        if code_lines == 0:
            return 0.0
        
        # åŸºç¡€å¤æ‚åº¦åŸºäºä»£ç è¡Œæ•°
        base_complexity = min(1.0, code_lines / 10000.0)
        
        # æ³¨é‡Šæ¯”ä¾‹å½±å“
        comment_ratio = comment_lines / (code_lines + comment_lines) if (code_lines + comment_lines) > 0 else 0
        comment_factor = 1.0 - comment_ratio  # æ³¨é‡Šè¶Šå¤šï¼Œå¤æ‚åº¦è¶Šä½
        
        # æ–‡ä»¶æ•°é‡å½±å“
        file_factor = min(1.0, file_count / 100.0)
        
        complexity_score = (base_complexity * 0.5 + comment_factor * 0.3 + file_factor * 0.2)
        
        return min(1.0, complexity_score)
    
    def _calculate_maintainability_index(self, code_lines: int, comment_lines: int, complexity_score: float) -> float:
        """è®¡ç®—å¯ç»´æŠ¤æ€§æŒ‡æ•°"""
        if code_lines == 0:
            return 100.0
        
        # ç®€åŒ–çš„å¯ç»´æŠ¤æ€§æŒ‡æ•°è®¡ç®—
        comment_ratio = comment_lines / (code_lines + comment_lines) if (code_lines + comment_lines) > 0 else 0
        
        # åŸºç¡€åˆ†æ•°
        base_score = 100.0
        
        # å¤æ‚åº¦å½±å“
        complexity_penalty = complexity_score * 30.0
        
        # æ³¨é‡Šå¥–åŠ±
        comment_bonus = comment_ratio * 20.0
        
        maintainability_index = base_score - complexity_penalty + comment_bonus
        
        return max(0.0, min(100.0, maintainability_index))
    
    def _estimate_test_coverage(self, files: List[Path], project_path: Path) -> float:
        """ä¼°ç®—æµ‹è¯•è¦†ç›–ç‡"""
        test_files = 0
        source_files = 0
        
        for file_path in files:
            file_name = file_path.name.lower()
            file_dir = file_path.parent.name.lower()
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæµ‹è¯•æ–‡ä»¶
            is_test_file = (
                'test' in file_name or
                'spec' in file_name or
                file_name.startswith('test_') or
                file_name.endswith('_test') or
                file_name.endswith('_spec') or
                'tests' in file_dir or
                'test' in file_dir
            )
            
            if is_test_file:
                test_files += 1
            elif file_path.suffix in ['.py', '.js', '.ts', '.java', '.cs', '.go', '.rs']:
                source_files += 1
        
        if source_files == 0:
            return 0.0
        
        coverage = (test_files / (source_files + test_files)) * 100
        return min(100.0, coverage)
    
    def _detect_project_type(self, files: List[Path], project_path: Path) -> ProjectType:
        """æ£€æµ‹é¡¹ç›®ç±»å‹"""
        type_scores = {}
        
        # æ£€æŸ¥æ¯ä¸ªé¡¹ç›®ç±»å‹çš„æŒ‡ç¤ºå™¨
        for project_type, indicators in self.project_indicators.items():
            score = 0
            
            # æ£€æŸ¥æ–‡ä»¶å
            for file_path in files:
                file_name = file_path.name.lower()
                file_path_str = str(file_path).lower()
                
                for indicator in indicators:
                    if indicator in file_name or indicator in file_path_str:
                        score += 1
            
            # æ£€æŸ¥ç›®å½•å
            for dir_path in project_path.rglob('*'):
                if dir_path.is_dir():
                    dir_name = dir_path.name.lower()
                    for indicator in indicators:
                        if indicator in dir_name:
                            score += 2  # ç›®å½•åæƒé‡æ›´é«˜
            
            type_scores[project_type] = score
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„é¡¹ç›®ç±»å‹
        if type_scores:
            best_type = max(type_scores, key=type_scores.get)
            if type_scores[best_type] > 0:
                return best_type
        
        return ProjectType.UNKNOWN
    
    def _detect_technology_stack(self, files: List[Path], project_path: Path) -> TechnologyStack:
        """æ£€æµ‹æŠ€æœ¯æ ˆ"""
        stack_scores = {}
        
        # æ£€æŸ¥æ¯ä¸ªæŠ€æœ¯æ ˆçš„æŒ‡ç¤ºå™¨
        for tech_stack, indicators in self.technology_indicators.items():
            score = 0
            
            # æ£€æŸ¥æ–‡ä»¶å†…å®¹
            for file_path in files[:20]:  # é™åˆ¶æ£€æŸ¥çš„æ–‡ä»¶æ•°é‡
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read().lower()
                    
                    for indicator in indicators:
                        score += content.count(indicator)
                        
                except Exception:
                    continue
            
            # æ£€æŸ¥æ–‡ä»¶å
            for file_path in files:
                file_name = file_path.name.lower()
                file_path_str = str(file_path).lower()
                
                for indicator in indicators:
                    if indicator in file_name or indicator in file_path_str:
                        score += 5  # æ–‡ä»¶åæƒé‡æ›´é«˜
            
            stack_scores[tech_stack] = score
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„æŠ€æœ¯æ ˆ
        if stack_scores:
            best_stack = max(stack_scores, key=stack_scores.get)
            if stack_scores[best_stack] > 0:
                return best_stack
        
        return TechnologyStack.UNKNOWN
    
    async def _analyze_architecture_components(self, files: List[Path], project_path: Path, technology_stack: TechnologyStack) -> List[ArchitectureComponent]:
        """åˆ†ææ¶æ„ç»„ä»¶"""
        components = []
        
        # æ ¹æ®æŠ€æœ¯æ ˆé€‰æ‹©åˆé€‚çš„åˆ†æå™¨
        if technology_stack in [TechnologyStack.PYTHON_DJANGO, TechnologyStack.PYTHON_FASTAPI, TechnologyStack.PYTHON_FLASK]:
            components.extend(await self._analyze_python_components(files))
        elif technology_stack == TechnologyStack.NODE_EXPRESS:
            components.extend(await self._analyze_nodejs_components(files))
        elif technology_stack == TechnologyStack.JAVA_SPRING:
            components.extend(await self._analyze_java_components(files))
        elif technology_stack == TechnologyStack.DOTNET_CORE:
            components.extend(await self._analyze_csharp_components(files))
        elif technology_stack == TechnologyStack.GO:
            components.extend(await self._analyze_go_components(files))
        elif technology_stack == TechnologyStack.RUST:
            components.extend(await self._analyze_rust_components(files))
        else:
            # é€šç”¨åˆ†æ
            components.extend(await self._analyze_generic_components(files))
        
        return components
    
    async def _analyze_python_components(self, files: List[Path]) -> List[ArchitectureComponent]:
        """åˆ†æPythonç»„ä»¶"""
        components = []
        
        for file_path in files:
            if file_path.suffix != '.py':
                continue
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # è§£æAST
                try:
                    tree = ast.parse(content)
                except SyntaxError:
                    continue
                
                # åˆ†æç±»å’Œå‡½æ•°
                for node in ast.walk(tree):
                    if isinstance(node, ast.ClassDef):
                        component = ArchitectureComponent(
                            component_id=f"class_{node.name}_{file_path.name}",
                            name=node.name,
                            type="class",
                            file_path=str(file_path),
                            dependencies=self._extract_python_dependencies(node),
                            complexity=self._calculate_python_complexity(node),
                            responsibilities=self._extract_python_responsibilities(node),
                            interfaces=self._extract_python_interfaces(node)
                        )
                        components.append(component)
                    
                    elif isinstance(node, ast.FunctionDef):
                        # æ£€æŸ¥æ˜¯å¦ä¸ºè§†å›¾å‡½æ•°ã€æ§åˆ¶å™¨ç­‰
                        func_type = self._classify_python_function(node, content)
                        
                        component = ArchitectureComponent(
                            component_id=f"function_{node.name}_{file_path.name}",
                            name=node.name,
                            type=func_type,
                            file_path=str(file_path),
                            dependencies=self._extract_python_dependencies(node),
                            complexity=self._calculate_python_complexity(node),
                            responsibilities=[f"å®ç°{node.name}åŠŸèƒ½"],
                            interfaces=[]
                        )
                        components.append(component)
                
            except Exception as e:
                logger.debug(f"åˆ†æPythonæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        return components
    
    def _extract_python_dependencies(self, node) -> List[str]:
        """æå–Pythonä¾èµ–"""
        dependencies = []
        
        for child in ast.walk(node):
            if isinstance(child, ast.Call):
                if isinstance(child.func, ast.Name):
                    dependencies.append(child.func.id)
                elif isinstance(child.func, ast.Attribute):
                    dependencies.append(child.func.attr)
        
        return list(set(dependencies))
    
    def _calculate_python_complexity(self, node) -> float:
        """è®¡ç®—Pythonå¤æ‚åº¦"""
        complexity = 1.0
        
        # è®¡ç®—åœˆå¤æ‚åº¦
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                complexity += 1
            elif isinstance(child, ast.ExceptHandler):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
        
        return min(10.0, complexity)
    
    def _extract_python_responsibilities(self, node) -> List[str]:
        """æå–PythonèŒè´£"""
        responsibilities = []
        
        # ä»æ–‡æ¡£å­—ç¬¦ä¸²æå–èŒè´£
        if (hasattr(node, 'body') and node.body and 
            isinstance(node.body[0], ast.Expr) and 
            isinstance(node.body[0].value, ast.Str)):
            docstring = node.body[0].value.s
            responsibilities.append(docstring)
        
        # ä»æ–¹æ³•åæ¨æ–­èŒè´£
        if hasattr(node, 'name'):
            name = node.name.lower()
            if 'get' in name:
                responsibilities.append("æ•°æ®è·å–")
            elif 'set' in name:
                responsibilities.append("æ•°æ®è®¾ç½®")
            elif 'process' in name:
                responsibilities.append("æ•°æ®å¤„ç†")
            elif 'validate' in name:
                responsibilities.append("æ•°æ®éªŒè¯")
        
        return responsibilities
    
    def _extract_python_interfaces(self, node) -> List[str]:
        """æå–Pythonæ¥å£"""
        interfaces = []
        
        # ä»åŸºç±»æå–æ¥å£
        if hasattr(node, 'bases'):
            for base in node.bases:
                if isinstance(base, ast.Name):
                    interfaces.append(base.id)
        
        return interfaces
    
    def _classify_python_function(self, node, content: str) -> str:
        """åˆ†ç±»Pythonå‡½æ•°"""
        name = node.name.lower()
        
        # Djangoè§†å›¾å‡½æ•°
        if 'request' in content or 'HttpResponse' in content:
            return "view"
        
        # APIå‡½æ•°
        if 'api' in name or 'endpoint' in name:
            return "api"
        
        # æ§åˆ¶å™¨å‡½æ•°
        if 'controller' in name or 'handler' in name:
            return "controller"
        
        # æœåŠ¡å‡½æ•°
        if 'service' in name or 'business' in name:
            return "service"
        
        # æ¨¡å‹å‡½æ•°
        if 'model' in name or 'entity' in name:
            return "model"
        
        # å·¥å…·å‡½æ•°
        if 'util' in name or 'helper' in name:
            return "utility"
        
        return "function"
    
    async def _analyze_nodejs_components(self, files: List[Path]) -> List[ArchitectureComponent]:
        """åˆ†æNode.jsç»„ä»¶"""
        components = []
        
        for file_path in files:
            if file_path.suffix not in ['.js', '.ts']:
                continue
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†æ
                # å‡½æ•°å®šä¹‰
                func_pattern = r'(?:function\s+(\w+)|const\s+(\w+)\s*=\s*(?:function|\([^)]*\)\s*=>))'
                func_matches = re.findall(func_pattern, content)
                
                for match in func_matches:
                    func_name = match[0] or match[1]
                    
                    component = ArchitectureComponent(
                        component_id=f"function_{func_name}_{file_path.name}",
                        name=func_name,
                        type=self._classify_js_function(func_name, content),
                        file_path=str(file_path),
                        dependencies=self._extract_js_dependencies(content),
                        complexity=self._calculate_js_complexity(content),
                        responsibilities=[f"å®ç°{func_name}åŠŸèƒ½"],
                        interfaces=[]
                    )
                    components.append(component)
                
                # ç±»å®šä¹‰ï¼ˆTypeScriptï¼‰
                if file_path.suffix == '.ts':
                    class_pattern = r'class\s+(\w+)'
                    class_matches = re.findall(class_pattern, content)
                    
                    for class_name in class_matches:
                        component = ArchitectureComponent(
                            component_id=f"class_{class_name}_{file_path.name}",
                            name=class_name,
                            type="class",
                            file_path=str(file_path),
                            dependencies=self._extract_js_dependencies(content),
                            complexity=self._calculate_js_complexity(content),
                            responsibilities=[f"{class_name}ç±»"],
                            interfaces=[]
                        )
                        components.append(component)
                
            except Exception as e:
                logger.debug(f"åˆ†æNode.jsæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        return components
    
    def _extract_js_dependencies(self, content: str) -> List[str]:
        """æå–JavaScriptä¾èµ–"""
        dependencies = []
        
        # å‡½æ•°è°ƒç”¨
        call_pattern = r'(\w+)\s*\('
        matches = re.findall(call_pattern, content)
        dependencies.extend(matches)
        
        return list(set(dependencies))
    
    def _calculate_js_complexity(self, content: str) -> float:
        """è®¡ç®—JavaScriptå¤æ‚åº¦"""
        complexity = 1.0
        
        # è®¡ç®—åœˆå¤æ‚åº¦
        complexity_keywords = ['if', 'else if', 'for', 'while', 'switch', 'case', 'catch']
        for keyword in complexity_keywords:
            complexity += content.count(keyword)
        
        return min(10.0, complexity)
    
    def _classify_js_function(self, name: str, content: str) -> str:
        """åˆ†ç±»JavaScriptå‡½æ•°"""
        name_lower = name.lower()
        
        if 'controller' in name_lower or 'handler' in name_lower:
            return "controller"
        elif 'service' in name_lower or 'business' in name_lower:
            return "service"
        elif 'model' in name_lower or 'entity' in name_lower:
            return "model"
        elif 'util' in name_lower or 'helper' in name_lower:
            return "utility"
        elif 'middleware' in name_lower:
            return "middleware"
        elif 'route' in name_lower:
            return "route"
        else:
            return "function"
    
    async def _analyze_java_components(self, files: List[Path]) -> List[ArchitectureComponent]:
        """åˆ†æJavaç»„ä»¶"""
        components = []
        
        for file_path in files:
            if file_path.suffix != '.java':
                continue
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ç±»å®šä¹‰
                class_pattern = r'(?:public\s+|private\s+|protected\s+)?(?:abstract\s+|final\s+)?class\s+(\w+)'
                class_matches = re.findall(class_pattern, content)
                
                for class_name in class_matches:
                    component = ArchitectureComponent(
                        component_id=f"class_{class_name}_{file_path.name}",
                        name=class_name,
                        type=self._classify_java_class(class_name, content),
                        file_path=str(file_path),
                        dependencies=self._extract_java_dependencies(content),
                        complexity=self._calculate_java_complexity(content),
                        responsibilities=[f"{class_name}ç±»"],
                        interfaces=self._extract_java_interfaces(content)
                    )
                    components.append(component)
                
                # æ¥å£å®šä¹‰
                interface_pattern = r'(?:public\s+|private\s+|protected\s+)?interface\s+(\w+)'
                interface_matches = re.findall(interface_pattern, content)
                
                for interface_name in interface_matches:
                    component = ArchitectureComponent(
                        component_id=f"interface_{interface_name}_{file_path.name}",
                        name=interface_name,
                        type="interface",
                        file_path=str(file_path),
                        dependencies=self._extract_java_dependencies(content),
                        complexity=self._calculate_java_complexity(content),
                        responsibilities=[f"{interface_name}æ¥å£"],
                        interfaces=[]
                    )
                    components.append(component)
                
            except Exception as e:
                logger.debug(f"åˆ†æJavaæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        return components
    
    def _extract_java_dependencies(self, content: str) -> List[str]:
        """æå–Javaä¾èµ–"""
        dependencies = []
        
        # æ–¹æ³•è°ƒç”¨
        method_pattern = r'(\w+)\s*\('
        matches = re.findall(method_pattern, content)
        dependencies.extend(matches)
        
        return list(set(dependencies))
    
    def _calculate_java_complexity(self, content: str) -> float:
        """è®¡ç®—Javaå¤æ‚åº¦"""
        complexity = 1.0
        
        # è®¡ç®—åœˆå¤æ‚åº¦
        complexity_keywords = ['if', 'else if', 'for', 'while', 'switch', 'case', 'catch']
        for keyword in complexity_keywords:
            complexity += content.count(keyword)
        
        return min(10.0, complexity)
    
    def _extract_java_interfaces(self, content: str) -> List[str]:
        """æå–Javaæ¥å£"""
        interfaces = []
        
        # å®ç°çš„æ¥å£
        implements_pattern = r'implements\s+([^\{]+)'
        match = re.search(implements_pattern, content)
        if match:
            interfaces.extend([i.strip() for i in match.group(1).split(',')])
        
        return interfaces
    
    def _classify_java_class(self, name: str, content: str) -> str:
        """åˆ†ç±»Javaç±»"""
        name_lower = name.lower()
        
        if 'controller' in name_lower or '@Controller' in content:
            return "controller"
        elif 'service' in name_lower or '@Service' in content:
            return "service"
        elif 'repository' in name_lower or '@Repository' in content:
            return "repository"
        elif 'entity' in name_lower or '@Entity' in content:
            return "entity"
        elif 'model' in name_lower:
            return "model"
        elif 'config' in name_lower or '@Configuration' in content:
            return "configuration"
        else:
            return "class"
    
    async def _analyze_csharp_components(self, files: List[Path]) -> List[ArchitectureComponent]:
        """åˆ†æC#ç»„ä»¶"""
        # ç±»ä¼¼Javaçš„åˆ†æé€»è¾‘
        return await self._analyze_java_components(files)
    
    async def _analyze_go_components(self, files: List[Path]) -> List[ArchitectureComponent]:
        """åˆ†æGoç»„ä»¶"""
        components = []
        
        for file_path in files:
            if file_path.suffix != '.go':
                continue
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ç»“æ„ä½“å®šä¹‰
                struct_pattern = r'type\s+(\w+)\s+struct'
                struct_matches = re.findall(struct_pattern, content)
                
                for struct_name in struct_matches:
                    component = ArchitectureComponent(
                        component_id=f"struct_{struct_name}_{file_path.name}",
                        name=struct_name,
                        type="struct",
                        file_path=str(file_path),
                        dependencies=self._extract_go_dependencies(content),
                        complexity=self._calculate_go_complexity(content),
                        responsibilities=[f"{struct_name}ç»“æ„ä½“"],
                        interfaces=[]
                    )
                    components.append(component)
                
                # æ¥å£å®šä¹‰
                interface_pattern = r'type\s+(\w+)\s+interface'
                interface_matches = re.findall(interface_pattern, content)
                
                for interface_name in interface_matches:
                    component = ArchitectureComponent(
                        component_id=f"interface_{interface_name}_{file_path.name}",
                        name=interface_name,
                        type="interface",
                        file_path=str(file_path),
                        dependencies=self._extract_go_dependencies(content),
                        complexity=self._calculate_go_complexity(content),
                        responsibilities=[f"{interface_name}æ¥å£"],
                        interfaces=[]
                    )
                    components.append(component)
                
                # å‡½æ•°å®šä¹‰
                func_pattern = r'func\s+(?:\([^)]*\)\s*)?(\w+)'
                func_matches = re.findall(func_pattern, content)
                
                for func_name in func_matches:
                    component = ArchitectureComponent(
                        component_id=f"function_{func_name}_{file_path.name}",
                        name=func_name,
                        type=self._classify_go_function(func_name, content),
                        file_path=str(file_path),
                        dependencies=self._extract_go_dependencies(content),
                        complexity=self._calculate_go_complexity(content),
                        responsibilities=[f"å®ç°{func_name}åŠŸèƒ½"],
                        interfaces=[]
                    )
                    components.append(component)
                
            except Exception as e:
                logger.debug(f"åˆ†æGoæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        return components
    
    def _extract_go_dependencies(self, content: str) -> List[str]:
        """æå–Goä¾èµ–"""
        dependencies = []
        
        # å‡½æ•°è°ƒç”¨
        call_pattern = r'(\w+)\s*\('
        matches = re.findall(call_pattern, content)
        dependencies.extend(matches)
        
        return list(set(dependencies))
    
    def _calculate_go_complexity(self, content: str) -> float:
        """è®¡ç®—Goå¤æ‚åº¦"""
        complexity = 1.0
        
        # è®¡ç®—åœˆå¤æ‚åº¦
        complexity_keywords = ['if', 'else if', 'for', 'switch', 'case', 'select']
        for keyword in complexity_keywords:
            complexity += content.count(keyword)
        
        return min(10.0, complexity)
    
    def _classify_go_function(self, name: str, content: str) -> str:
        """åˆ†ç±»Goå‡½æ•°"""
        name_lower = name.lower()
        
        if 'handler' in name_lower:
            return "handler"
        elif 'service' in name_lower:
            return "service"
        elif 'process' in name_lower:
            return "processor"
        elif 'validate' in name_lower:
            return "validator"
        else:
            return "function"
    
    async def _analyze_rust_components(self, files: List[Path]) -> List[ArchitectureComponent]:
        """åˆ†æRustç»„ä»¶"""
        components = []
        
        for file_path in files:
            if file_path.suffix != '.rs':
                continue
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ç»“æ„ä½“å®šä¹‰
                struct_pattern = r'struct\s+(\w+)'
                struct_matches = re.findall(struct_pattern, content)
                
                for struct_name in struct_matches:
                    component = ArchitectureComponent(
                        component_id=f"struct_{struct_name}_{file_path.name}",
                        name=struct_name,
                        type="struct",
                        file_path=str(file_path),
                        dependencies=self._extract_rust_dependencies(content),
                        complexity=self._calculate_rust_complexity(content),
                        responsibilities=[f"{struct_name}ç»“æ„ä½“"],
                        interfaces=self._extract_rust_traits(content)
                    )
                    components.append(component)
                
                # ç‰¹å¾å®šä¹‰
                trait_pattern = r'trait\s+(\w+)'
                trait_matches = re.findall(trait_pattern, content)
                
                for trait_name in trait_matches:
                    component = ArchitectureComponent(
                        component_id=f"trait_{trait_name}_{file_path.name}",
                        name=trait_name,
                        type="trait",
                        file_path=str(file_path),
                        dependencies=self._extract_rust_dependencies(content),
                        complexity=self._calculate_rust_complexity(content),
                        responsibilities=[f"{trait_name}ç‰¹å¾"],
                        interfaces=[]
                    )
                    components.append(component)
                
                # å‡½æ•°å®šä¹‰
                func_pattern = r'fn\s+(\w+)'
                func_matches = re.findall(func_pattern, content)
                
                for func_name in func_matches:
                    component = ArchitectureComponent(
                        component_id=f"function_{func_name}_{file_path.name}",
                        name=func_name,
                        type=self._classify_rust_function(func_name, content),
                        file_path=str(file_path),
                        dependencies=self._extract_rust_dependencies(content),
                        complexity=self._calculate_rust_complexity(content),
                        responsibilities=[f"å®ç°{func_name}åŠŸèƒ½"],
                        interfaces=[]
                    )
                    components.append(component)
                
            except Exception as e:
                logger.debug(f"åˆ†æRustæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        return components
    
    def _extract_rust_dependencies(self, content: str) -> List[str]:
        """æå–Rustä¾èµ–"""
        dependencies = []
        
        # å‡½æ•°è°ƒç”¨
        call_pattern = r'(\w+)::'
        matches = re.findall(call_pattern, content)
        dependencies.extend(matches)
        
        return list(set(dependencies))
    
    def _calculate_rust_complexity(self, content: str) -> float:
        """è®¡ç®—Rustå¤æ‚åº¦"""
        complexity = 1.0
        
        # è®¡ç®—åœˆå¤æ‚åº¦
        complexity_keywords = ['if', 'else if', 'for', 'while', 'match', 'loop']
        for keyword in complexity_keywords:
            complexity += content.count(keyword)
        
        return min(10.0, complexity)
    
    def _extract_rust_traits(self, content: str) -> List[str]:
        """æå–Rustç‰¹å¾"""
        traits = []
        
        # å®ç°çš„ç‰¹å¾
        impl_pattern = r'impl\s+(\w+)\s+for\s+\w+'
        matches = re.findall(impl_pattern, content)
        traits.extend(matches)
        
        return traits
    
    def _classify_rust_function(self, name: str, content: str) -> str:
        """åˆ†ç±»Rustå‡½æ•°"""
        name_lower = name.lower()
        
        if 'main' in name_lower:
            return "main"
        elif 'new' in name_lower:
            return "constructor"
        elif 'process' in name_lower:
            return "processor"
        elif 'validate' in name_lower:
            return "validator"
        else:
            return "function"
    
    async def _analyze_generic_components(self, files: List[Path]) -> List[ArchitectureComponent]:
        """é€šç”¨ç»„ä»¶åˆ†æ"""
        components = []
        
        for file_path in files:
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                # ç®€å•çš„ç»„ä»¶åˆ†æ
                component = ArchitectureComponent(
                    component_id=f"file_{file_path.name}",
                    name=file_path.stem,
                    type="file",
                    file_path=str(file_path),
                    dependencies=[],
                    complexity=1.0,
                    responsibilities=[f"{file_path.name}æ–‡ä»¶"],
                    interfaces=[]
                )
                components.append(component)
                
            except Exception as e:
                logger.debug(f"åˆ†ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        return components
    
    def _detect_architecture_pattern(self, components: List[ArchitectureComponent], project_type: ProjectType, technology_stack: TechnologyStack) -> ArchitecturePattern:
        """æ£€æµ‹æ¶æ„æ¨¡å¼"""
        pattern_scores = {}
        
        # å•ä½“æ¶æ„
        monolith_indicators = [
            len(components) < 20,
            not any(c.type == "microservice" for c in components),
            project_type in [ProjectType.WEB_APP, ProjectType.DESKTOP_APP]
        ]
        pattern_scores[ArchitecturePattern.MONOLITH] = sum(monolith_indicators)
        
        # å¾®æœåŠ¡æ¶æ„
        microservice_indicators = [
            len(components) >= 20,
            any("service" in c.name.lower() or "microservice" in c.name.lower() for c in components),
            any("docker" in c.file_path.lower() for c in components),
            project_type in [ProjectType.API_SERVICE, ProjectType.MICROSERVICE]
        ]
        pattern_scores[ArchitecturePattern.MICROSERVICES] = sum(microservice_indicators)
        
        # äº‹ä»¶é©±åŠ¨æ¶æ„
        event_driven_indicators = [
            any("event" in c.name.lower() or "message" in c.name.lower() for c in components),
            any("queue" in c.file_path.lower() or "kafka" in c.file_path.lower() for c in components),
            any("publisher" in c.name.lower() or "subscriber" in c.name.lower() for c in components)
        ]
        pattern_scores[ArchitecturePattern.EVENT_DRIVEN] = sum(event_driven_indicators)
        
        # åˆ†å±‚æ¶æ„
        layered_indicators = [
            any("controller" in c.type for c in components),
            any("service" in c.type for c in components),
            any("repository" in c.type for c in components),
            any("model" in c.type for c in components)
        ]
        pattern_scores[ArchitecturePattern.LAYERED] = sum(layered_indicators)
        
        # MVCæ¶æ„
        mvc_indicators = [
            any("controller" in c.type for c in components),
            any("model" in c.type for c in components),
            any("view" in c.type or "template" in c.type for c in components),
            technology_stack in [TechnologyStack.PYTHON_DJANGO, TechnologyStack.NODE_EXPRESS]
        ]
        pattern_scores[ArchitecturePattern.MVC] = sum(mvc_indicators)
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„æ¶æ„æ¨¡å¼
        if pattern_scores:
            best_pattern = max(pattern_scores, key=pattern_scores.get)
            if pattern_scores[best_pattern] > 0:
                return best_pattern
        
        return ArchitecturePattern.UNKNOWN
    
    async def _generate_recommendations(self, project_type: ProjectType, architecture_pattern: ArchitecturePattern, 
                                       technology_stack: TechnologyStack, components: List[ArchitectureComponent], 
                                       metrics: ProjectMetrics) -> Tuple[List[str], List[str], List[str]]:
        """ç”Ÿæˆå»ºè®®ã€é—®é¢˜å’Œä¼˜åŠ¿"""
        recommendations = []
        issues = []
        strengths = []
        
        # åŸºäºæŒ‡æ ‡çš„å»ºè®®
        if metrics.complexity_score > 0.7:
            recommendations.append("è€ƒè™‘é‡æ„é«˜å¤æ‚åº¦çš„ä»£ç ï¼Œæé«˜å¯ç»´æŠ¤æ€§")
            issues.append(f"ä»£ç å¤æ‚åº¦è¿‡é«˜ ({metrics.complexity_score:.2f})")
        
        if metrics.maintainability_index < 60:
            recommendations.append("å¢åŠ ä»£ç æ³¨é‡Šå’Œæ–‡æ¡£ï¼Œæé«˜å¯ç»´æŠ¤æ€§")
            issues.append(f"å¯ç»´æŠ¤æ€§æŒ‡æ•°è¾ƒä½ ({metrics.maintainability_index:.2f})")
        
        if metrics.test_coverage < 30:
            recommendations.append("å¢åŠ å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•ï¼Œæé«˜æµ‹è¯•è¦†ç›–ç‡")
            issues.append(f"æµ‹è¯•è¦†ç›–ç‡è¿‡ä½ ({metrics.test_coverage:.1f}%)")
        
        # åŸºäºæ¶æ„çš„å»ºè®®
        if architecture_pattern == ArchitecturePattern.UNKNOWN:
            recommendations.append("æ˜ç¡®æ¶æ„æ¨¡å¼ï¼Œæé«˜ä»£ç ç»„ç»‡æ€§")
            issues.append("æ¶æ„æ¨¡å¼ä¸æ˜ç¡®")
        
        # åŸºäºç»„ä»¶çš„å»ºè®®
        if len(components) > 50:
            recommendations.append("è€ƒè™‘æ‹†åˆ†å¤§å‹é¡¹ç›®ï¼Œé‡‡ç”¨å¾®æœåŠ¡æ¶æ„")
        
        high_complexity_components = [c for c in components if c.complexity > 7]
        if high_complexity_components:
            recommendations.append(f"é‡æ„ {len(high_complexity_components)} ä¸ªé«˜å¤æ‚åº¦ç»„ä»¶")
        
        # ä¼˜åŠ¿
        if metrics.maintainability_index > 80:
            strengths.append("ä»£ç å¯ç»´æŠ¤æ€§è‰¯å¥½")
        
        if metrics.test_coverage > 70:
            strengths.append("æµ‹è¯•è¦†ç›–ç‡è¾ƒé«˜")
        
        if architecture_pattern != ArchitecturePattern.UNKNOWN:
            strengths.append(f"é‡‡ç”¨æ¸…æ™°çš„ {architecture_pattern.value} æ¶æ„æ¨¡å¼")
        
        if technology_stack != TechnologyStack.UNKNOWN:
            strengths.append(f"ä½¿ç”¨æˆç†Ÿçš„ {technology_stack.value} æŠ€æœ¯æ ˆ")
        
        return recommendations, issues, strengths
    
    def _analyze_python_file(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æPythonæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            analysis = {
                'classes': [],
                'functions': [],
                'imports': [],
                'complexity': 0
            }
            
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    analysis['classes'].append(node.name)
                elif isinstance(node, ast.FunctionDef):
                    analysis['functions'].append(node.name)
                elif isinstance(node, ast.Import):
                    for alias in node.names:
                        analysis['imports'].append(alias.name)
                elif isinstance(node, ast.ImportFrom):
                    module = node.module or ''
                    for alias in node.names:
                        analysis['imports'].append(f"{module}.{alias.name}")
            
            return analysis
            
        except Exception as e:
            logger.debug(f"åˆ†æPythonæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return {}
    
    def _analyze_javascript_file(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æJavaScriptæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            analysis = {
                'functions': [],
                'classes': [],
                'imports': [],
                'complexity': 0
            }
            
            # å‡½æ•°å®šä¹‰
            func_pattern = r'(?:function\s+(\w+)|const\s+(\w+)\s*=\s*(?:function|\([^)]*\)\s*=>))'
            func_matches = re.findall(func_pattern, content)
            for match in func_matches:
                func_name = match[0] or match[1]
                analysis['functions'].append(func_name)
            
            # ç±»å®šä¹‰ï¼ˆES6+ï¼‰
            class_pattern = r'class\s+(\w+)'
            class_matches = re.findall(class_pattern, content)
            analysis['classes'].extend(class_matches)
            
            # å¯¼å…¥
            import_pattern = r'(?:import\s+.*\s+from\s+[\'"]([^\'"]+)[\'"]|const\s+.*=\s+require\([\'"]([^\'"]+)[\'"])'
            import_matches = re.findall(import_pattern, content)
            for match in import_matches:
                module = match[0] or match[1]
                analysis['imports'].append(module)
            
            return analysis
            
        except Exception as e:
            logger.debug(f"åˆ†æJavaScriptæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return {}
    
    def _analyze_typescript_file(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æTypeScriptæ–‡ä»¶"""
        # ç±»ä¼¼JavaScriptçš„åˆ†æï¼ŒåŠ ä¸ŠTypeScriptç‰¹æœ‰çš„åˆ†æ
        return self._analyze_javascript_file(file_path)
    
    def _analyze_java_file(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æJavaæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            analysis = {
                'classes': [],
                'interfaces': [],
                'methods': [],
                'imports': [],
                'complexity': 0
            }
            
            # ç±»å®šä¹‰
            class_pattern = r'(?:public\s+|private\s+|protected\s+)?(?:abstract\s+|final\s+)?class\s+(\w+)'
            class_matches = re.findall(class_pattern, content)
            analysis['classes'].extend(class_matches)
            
            # æ¥å£å®šä¹‰
            interface_pattern = r'(?:public\s+|private\s+|protected\s+)?interface\s+(\w+)'
            interface_matches = re.findall(interface_pattern, content)
            analysis['interfaces'].extend(interface_matches)
            
            # æ–¹æ³•å®šä¹‰
            method_pattern = r'(?:public\s+|private\s+|protected\s+)?(?:static\s+)?(?:final\s+)?(?:abstract\s+)?(?:\w+\s+)?(\w+)\s*\([^)]*\)'
            method_matches = re.findall(method_pattern, content)
            analysis['methods'].extend(method_matches)
            
            # å¯¼å…¥
            import_pattern = r'import\s+([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)*)'
            import_matches = re.findall(import_pattern, content)
            analysis['imports'].extend(import_matches)
            
            return analysis
            
        except Exception as e:
            logger.debug(f"åˆ†æJavaæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return {}
    
    def _analyze_csharp_file(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æC#æ–‡ä»¶"""
        # ç±»ä¼¼Javaçš„åˆ†æ
        return self._analyze_java_file(file_path)
    
    def _analyze_go_file(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æGoæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            analysis = {
                'structs': [],
                'interfaces': [],
                'functions': [],
                'imports': [],
                'complexity': 0
            }
            
            # ç»“æ„ä½“å®šä¹‰
            struct_pattern = r'type\s+(\w+)\s+struct'
            struct_matches = re.findall(struct_pattern, content)
            analysis['structs'].extend(struct_matches)
            
            # æ¥å£å®šä¹‰
            interface_pattern = r'type\s+(\w+)\s+interface'
            interface_matches = re.findall(interface_pattern, content)
            analysis['interfaces'].extend(interface_matches)
            
            # å‡½æ•°å®šä¹‰
            func_pattern = r'func\s+(?:\([^)]*\)\s*)?(\w+)'
            func_matches = re.findall(func_pattern, content)
            analysis['functions'].extend(func_matches)
            
            # å¯¼å…¥
            import_pattern = r'import\s+[\'"]([^\'"]+)[\'"]'
            import_matches = re.findall(import_pattern, content)
            analysis['imports'].extend(import_matches)
            
            return analysis
            
        except Exception as e:
            logger.debug(f"åˆ†æGoæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return {}
    
    def _analyze_rust_file(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æRustæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            analysis = {
                'structs': [],
                'traits': [],
                'functions': [],
                'imports': [],
                'complexity': 0
            }
            
            # ç»“æ„ä½“å®šä¹‰
            struct_pattern = r'struct\s+(\w+)'
            struct_matches = re.findall(struct_pattern, content)
            analysis['structs'].extend(struct_matches)
            
            # ç‰¹å¾å®šä¹‰
            trait_pattern = r'trait\s+(\w+)'
            trait_matches = re.findall(trait_pattern, content)
            analysis['traits'].extend(trait_matches)
            
            # å‡½æ•°å®šä¹‰
            func_pattern = r'fn\s+(\w+)'
            func_matches = re.findall(func_pattern, content)
            analysis['functions'].extend(func_matches)
            
            # å¯¼å…¥
            import_pattern = r'use\s+([a-zA-Z_][a-zA-Z0-9_]*(?::[a-zA-Z_][a-zA-Z0-9_]*)*)'
            import_matches = re.findall(import_pattern, content)
            analysis['imports'].extend(import_matches)
            
            return analysis
            
        except Exception as e:
            logger.debug(f"åˆ†æRustæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return {}
    
    def _analyze_cpp_file(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æC++æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            analysis = {
                'classes': [],
                'functions': [],
                'includes': [],
                'complexity': 0
            }
            
            # ç±»å®šä¹‰
            class_pattern = r'class\s+(\w+)'
            class_matches = re.findall(class_pattern, content)
            analysis['classes'].extend(class_matches)
            
            # å‡½æ•°å®šä¹‰
            func_pattern = r'(?:\w+\s+)?(\w+)\s*\([^)]*\)\s*(?:const\s*)?{'
            func_matches = re.findall(func_pattern, content)
            analysis['functions'].extend(func_matches)
            
            # åŒ…å«æ–‡ä»¶
            include_pattern = r'#include\s*[<"]([^>"]+)[>"]'
            include_matches = re.findall(include_pattern, content)
            analysis['includes'].extend(include_matches)
            
            return analysis
            
        except Exception as e:
            logger.debug(f"åˆ†æC++æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return {}
    
    def _analyze_json_file(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æJSONæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            data = json.loads(content)
            
            analysis = {
                'type': 'json',
                'keys': list(data.keys()) if isinstance(data, dict) else [],
                'size': len(content),
                'structure': type(data).__name__
            }
            
            return analysis
            
        except Exception as e:
            logger.debug(f"åˆ†æJSONæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return {}
    
    def _analyze_yaml_file(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æYAMLæ–‡ä»¶"""
        try:
            import yaml
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            data = yaml.safe_load(content)
            
            analysis = {
                'type': 'yaml',
                'keys': list(data.keys()) if isinstance(data, dict) else [],
                'size': len(content),
                'structure': type(data).__name__
            }
            
            return analysis
            
        except Exception as e:
            logger.debug(f"åˆ†æYAMLæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return {}
    
    def _analyze_markdown_file(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æMarkdownæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.split('\n')
            
            analysis = {
                'type': 'markdown',
                'headings': [],
                'links': [],
                'size': len(content),
                'lines': len(lines)
            }
            
            # æå–æ ‡é¢˜
            for line in lines:
                if line.startswith('#'):
                    level = len(line) - len(line.lstrip('#'))
                    title = line.lstrip('# ').strip()
                    analysis['headings'].append({'level': level, 'title': title})
            
            # æå–é“¾æ¥
            link_pattern = r'\[([^\]]+)\]\(([^)]+)\)'
            link_matches = re.findall(link_pattern, content)
            analysis['links'].extend(link_matches)
            
            return analysis
            
        except Exception as e:
            logger.debug(f"åˆ†æMarkdownæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return {}
    
    def _analyze_text_file(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†ææ–‡æœ¬æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.split('\n')
            
            analysis = {
                'type': 'text',
                'size': len(content),
                'lines': len(lines),
                'words': len(content.split())
            }
            
            return analysis
            
        except Exception as e:
            logger.debug(f"åˆ†ææ–‡æœ¬æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return {}

# å…¨å±€é¡¹ç›®åˆ†æå™¨å®ä¾‹
project_analyzer = ProjectAnalyzer()

# ä¾¿æ·å‡½æ•°
async def analyze_project(project_path: str) -> ArchitectureAnalysis:
    """ä¾¿æ·çš„é¡¹ç›®åˆ†æå‡½æ•°"""
    return await project_analyzer.analyze_project(project_path)

# ç¤ºä¾‹ä½¿ç”¨
async def example_usage():
    """ç¤ºä¾‹ä½¿ç”¨"""
    print("ğŸ” é¡¹ç›®åˆ†æå™¨ç¤ºä¾‹")
    
    # åˆ†æå½“å‰é¡¹ç›®
    current_path = Path.cwd()
    print(f"\n1. åˆ†æå½“å‰é¡¹ç›®: {current_path}")
    
    try:
        analysis = await analyze_project(str(current_path))
        
        print(f"é¡¹ç›®ç±»å‹: {analysis.project_type.value}")
        print(f"æ¶æ„æ¨¡å¼: {analysis.architecture_pattern.value}")
        print(f"æŠ€æœ¯æ ˆ: {analysis.technology_stack.value}")
        print(f"ç»„ä»¶æ•°é‡: {len(analysis.components)}")
        
        print(f"\né¡¹ç›®æŒ‡æ ‡:")
        print(f"  æ€»æ–‡ä»¶æ•°: {analysis.metrics.total_files}")
        print(f"  æ€»ä»£ç è¡Œæ•°: {analysis.metrics.code_lines}")
        print(f"  å¤æ‚åº¦åˆ†æ•°: {analysis.metrics.complexity_score:.2f}")
        print(f"  å¯ç»´æŠ¤æ€§æŒ‡æ•°: {analysis.metrics.maintainability_index:.2f}")
        print(f"  æµ‹è¯•è¦†ç›–ç‡: {analysis.metrics.test_coverage:.1f}%")
        
        print(f"\nå»ºè®®:")
        for rec in analysis.recommendations[:5]:
            print(f"  â€¢ {rec}")
        
        print(f"\né—®é¢˜:")
        for issue in analysis.issues[:5]:
            print(f"  â€¢ {issue}")
        
        print(f"\nä¼˜åŠ¿:")
        for strength in analysis.strengths[:5]:
            print(f"  â€¢ {strength}")
        
    except Exception as e:
        print(f"âŒ é¡¹ç›®åˆ†æå¤±è´¥: {e}")
    
    print("\nâœ… é¡¹ç›®åˆ†æå™¨ç¤ºä¾‹å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(example_usage())