#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ§  æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ vÎ© - Intelligent Cache System
Intelligent Cache System vÎ© - åŸºäºæœºå™¨å­¦ä¹ çš„æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ

å®ç°é¢„æµ‹æ€§ç¼“å­˜ã€åˆ†å±‚ç¼“å­˜ã€æ™ºèƒ½å¤±æ•ˆç­‰é«˜çº§ç¼“å­˜åŠŸèƒ½ï¼Œ
å¤§å¹…æå‡æ¨¡å‹é€‚é…å™¨çš„å“åº”é€Ÿåº¦å’Œæ€§èƒ½ã€‚
"""

import asyncio
import json
import time
import hashlib
import logging
from typing import Dict, List, Any, Optional, Tuple, Set
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from enum import Enum
from collections import OrderedDict, defaultdict
import numpy as np
from abc import ABC, abstractmethod

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class CacheLevel(Enum):
    """ç¼“å­˜å±‚çº§æšä¸¾"""
    L1_HOT = "l1_hot"      # çƒ­ç‚¹æ•°æ®
    L2_WARM = "l2_warm"    # å¸¸ç”¨æ•°æ®
    L3_COLD = "l3_cold"    # å†·æ•°æ®

class CacheStrategy(Enum):
    """ç¼“å­˜ç­–ç•¥æšä¸¾"""
    LRU = "lru"
    LFU = "lfu"
    FIFO = "fifo"
    PREDICTIVE = "predictive"

@dataclass
class CacheEntry:
    """ç¼“å­˜æ¡ç›®"""
    key: str
    value: Any
    created_at: datetime
    last_accessed: datetime
    access_count: int = 0
    ttl: Optional[float] = None
    size: int = 0
    level: CacheLevel = CacheLevel.L3_COLD
    prediction_score: float = 0.0
    dependencies: Set[str] = field(default_factory=set)

@dataclass
class CacheStats:
    """ç¼“å­˜ç»Ÿè®¡"""
    hits: int = 0
    misses: int = 0
    evictions: int = 0
    total_requests: int = 0
    hit_rate: float = 0.0
    avg_access_time: float = 0.0
    memory_usage: int = 0

class CacheEvictionPolicy(ABC):
    """ç¼“å­˜æ·˜æ±°ç­–ç•¥æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    async def select_victim(self, cache: 'IntelligentCache') -> Optional[str]:
        """é€‰æ‹©è¦æ·˜æ±°çš„ç¼“å­˜é¡¹"""
        pass

class LRUEvictionPolicy(CacheEvictionPolicy):
    """LRUæ·˜æ±°ç­–ç•¥"""
    
    async def select_victim(self, cache: 'IntelligentCache') -> Optional[str]:
        """é€‰æ‹©æœ€è¿‘æœ€å°‘ä½¿ç”¨çš„é¡¹"""
        oldest_access = None
        victim_key = None
        
        for key, entry in cache.cache_data.items():
            if oldest_access is None or entry.last_accessed < oldest_access:
                oldest_access = entry.last_accessed
                victim_key = key
        
        return victim_key

class PredictiveEvictionPolicy(CacheEvictionPolicy):
    """é¢„æµ‹æ€§æ·˜æ±°ç­–ç•¥"""
    
    async def select_victim(self, cache: 'IntelligentCache') -> Optional[str]:
        """åŸºäºé¢„æµ‹é€‰æ‹©æ·˜æ±°é¡¹"""
        min_prediction = float('inf')
        victim_key = None
        
        for key, entry in cache.cache_data.items():
            # ç»¼åˆè€ƒè™‘é¢„æµ‹åˆ†æ•°å’Œè®¿é—®æ—¶é—´
            time_factor = (datetime.now() - entry.last_accessed).total_seconds() / 3600  # å°æ—¶
            combined_score = entry.prediction_score - time_factor * 0.1
            
            if combined_score < min_prediction:
                min_prediction = combined_score
                victim_key = key
        
        return victim_key

class UsagePatternAnalyzer:
    """ä½¿ç”¨æ¨¡å¼åˆ†æå™¨"""
    
    def __init__(self):
        self.access_patterns = defaultdict(list)
        self.pattern_weights = defaultdict(float)
        self.last_analysis = datetime.now()
    
    def record_access(self, key: str, context: Dict[str, Any] = None):
        """è®°å½•è®¿é—®æ¨¡å¼"""
        timestamp = datetime.now()
        self.access_patterns[key].append({
            "timestamp": timestamp,
            "context": context or {}
        })
        
        # ä¿æŒæœ€è¿‘100æ¬¡è®¿é—®è®°å½•
        if len(self.access_patterns[key]) > 100:
            self.access_patterns[key] = self.access_patterns[key][-100:]
    
    def predict_next_access(self, key: str) -> float:
        """é¢„æµ‹ä¸‹æ¬¡è®¿é—®æ¦‚ç‡"""
        if key not in self.access_patterns or len(self.access_patterns[key]) < 2:
            return 0.1  # é»˜è®¤ä½æ¦‚ç‡
        
        pattern = self.access_patterns[key]
        
        # è®¡ç®—è®¿é—®é¢‘ç‡
        recent_accesses = [p for p in pattern if 
                          (datetime.now() - p["timestamp"]).total_seconds() < 3600]
        
        if not recent_accesses:
            return 0.05
        
        # åŸºäºæœ€è¿‘è®¿é—®é¢‘ç‡é¢„æµ‹
        frequency = len(recent_accesses) / 3600  # æ¯ç§’è®¿é—®æ¬¡æ•°
        
        # è®¡ç®—è®¿é—®é—´éš”è§„å¾‹æ€§
        if len(recent_accesses) > 1:
            intervals = []
            for i in range(1, len(recent_accesses)):
                interval = (recent_accesses[i]["timestamp"] - recent_accesses[i-1]["timestamp"]).total_seconds()
                intervals.append(interval)
            
            # é—´éš”è¶Šè§„å¾‹ï¼Œé¢„æµ‹åˆ†æ•°è¶Šé«˜
            if intervals:
                interval_std = np.std(intervals)
                interval_mean = np.mean(intervals)
                regularity = max(0, 1 - interval_std / interval_mean) if interval_mean > 0 else 0
            else:
                regularity = 0
        else:
            regularity = 0
        
        # ç»¼åˆé¢„æµ‹åˆ†æ•°
        prediction_score = min(1.0, frequency * 100 + regularity * 0.5)
        
        return prediction_score
    
    def analyze_patterns(self):
        """åˆ†æè®¿é—®æ¨¡å¼"""
        for key in self.access_patterns:
            prediction_score = self.predict_next_access(key)
            self.pattern_weights[key] = prediction_score
        
        self.last_analysis = datetime.now()

class IntelligentCache:
    """æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.cache_data: Dict[str, CacheEntry] = {}
        self.level_limits = {
            CacheLevel.L1_HOT: config.get("tiered_cache", {}).get("l1_size", 100),
            CacheLevel.L2_WARM: config.get("tiered_cache", {}).get("l2_size", 500),
            CacheLevel.L3_COLD: config.get("tiered_cache", {}).get("l3_size", 1000)
        }
        self.total_limit = sum(self.level_limits.values())
        self.current_size = 0
        self.stats = CacheStats()
        self.pattern_analyzer = UsagePatternAnalyzer()
        self.eviction_policy = self._create_eviction_policy()
        self.cleanup_task = None
        
    def _create_eviction_policy(self) -> CacheEvictionPolicy:
        """åˆ›å»ºæ·˜æ±°ç­–ç•¥"""
        strategy = self.config.get("strategy", "predictive")
        
        if strategy == CacheStrategy.PREDICTIVE.value:
            return PredictiveEvictionPolicy()
        elif strategy == CacheStrategy.LRU.value:
            return LRUEvictionPolicy()
        else:
            return LRUEvictionPolicy()
    
    async def initialize(self):
        """åˆå§‹åŒ–ç¼“å­˜ç³»ç»Ÿ"""
        # å¯åŠ¨åå°æ¸…ç†ä»»åŠ¡
        self.cleanup_task = asyncio.create_task(self._cleanup_loop())
        logger.info("Intelligent cache initialized")
    
    async def get(self, key: str, context: Dict[str, Any] = None) -> Optional[Any]:
        """è·å–ç¼“å­˜å€¼"""
        start_time = time.time()
        
        # è®°å½•è®¿é—®æ¨¡å¼
        self.pattern_analyzer.record_access(key, context)
        
        if key not in self.cache_data:
            self.stats.misses += 1
            self.stats.total_requests += 1
            self._update_hit_rate()
            return None
        
        entry = self.cache_data[key]
        
        # æ£€æŸ¥TTL
        if entry.ttl and (datetime.now() - entry.created_at).total_seconds() > entry.ttl:
            await self._remove_entry(key)
            self.stats.misses += 1
            self.stats.total_requests += 1
            self._update_hit_rate()
            return None
        
        # æ›´æ–°è®¿é—®ä¿¡æ¯
        entry.last_accessed = datetime.now()
        entry.access_count += 1
        
        # æ›´æ–°ç¼“å­˜å±‚çº§
        await self._promote_entry(key)
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats.hits += 1
        self.stats.total_requests += 1
        self._update_hit_rate()
        
        # æ›´æ–°å¹³å‡è®¿é—®æ—¶é—´
        access_time = time.time() - start_time
        self.stats.avg_access_time = (
            (self.stats.avg_access_time * (self.stats.total_requests - 1) + access_time) /
            self.stats.total_requests
        )
        
        logger.debug(f"Cache hit for key: {key}")
        return entry.value
    
    async def put(self, key: str, value: Any, ttl: Optional[float] = None, 
                  context: Dict[str, Any] = None) -> bool:
        """å­˜å‚¨ç¼“å­˜å€¼"""
        # è®¡ç®—å€¼çš„å¤§å°ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
        value_size = len(str(value).encode('utf-8'))
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·˜æ±°
        await self._ensure_capacity(value_size)
        
        # åˆ›å»ºç¼“å­˜æ¡ç›®
        now = datetime.now()
        entry = CacheEntry(
            key=key,
            value=value,
            created_at=now,
            last_accessed=now,
            ttl=ttl,
            size=value_size,
            prediction_score=self.pattern_analyzer.predict_next_access(key)
        )
        
        # å¦‚æœé”®å·²å­˜åœ¨ï¼Œæ›´æ–°å¤§å°
        if key in self.cache_data:
            old_entry = self.cache_data[key]
            self.current_size -= old_entry.size
        
        # å­˜å‚¨æ¡ç›®
        self.cache_data[key] = entry
        self.current_size += value_size
        
        # è®¾ç½®åˆå§‹å±‚çº§
        await self._promote_entry(key)
        
        # è®°å½•è®¿é—®æ¨¡å¼
        self.pattern_analyzer.record_access(key, context)
        
        logger.debug(f"Cache stored for key: {key}")
        return True
    
    async def remove(self, key: str) -> bool:
        """åˆ é™¤ç¼“å­˜é¡¹"""
        if key not in self.cache_data:
            return False
        
        await self._remove_entry(key)
        logger.debug(f"Cache removed for key: {key}")
        return True
    
    async def _remove_entry(self, key: str):
        """åˆ é™¤ç¼“å­˜æ¡ç›®"""
        if key in self.cache_data:
            entry = self.cache_data[key]
            del self.cache_data[key]
            self.current_size -= entry.size
    
    async def _promote_entry(self, key: str):
        """æå‡ç¼“å­˜æ¡ç›®å±‚çº§"""
        if key not in self.cache_data:
            return
        
        entry = self.cache_data[key]
        
        # åŸºäºè®¿é—®é¢‘ç‡å’Œé¢„æµ‹åˆ†æ•°å†³å®šå±‚çº§
        access_frequency = entry.access_count / max(1, (datetime.now() - entry.created_at).total_seconds() / 3600)
        
        if access_frequency > 10 or entry.prediction_score > 0.8:
            new_level = CacheLevel.L1_HOT
        elif access_frequency > 1 or entry.prediction_score > 0.5:
            new_level = CacheLevel.L2_WARM
        else:
            new_level = CacheLevel.L3_COLD
        
        # å¦‚æœå±‚çº§æå‡ï¼Œæ£€æŸ¥å®¹é‡é™åˆ¶
        if new_level.value < entry.level.value:
            await self._ensure_level_capacity(new_level)
        
        entry.level = new_level
    
    async def _ensure_capacity(self, new_entry_size: int):
        """ç¡®ä¿æœ‰è¶³å¤Ÿå®¹é‡"""
        while self.current_size + new_entry_size > self.total_limit:
            victim_key = await self.eviction_policy.select_victim(self)
            if victim_key:
                await self._remove_entry(victim_key)
                self.stats.evictions += 1
            else:
                break
    
    async def _ensure_level_capacity(self, level: CacheLevel):
        """ç¡®ä¿å±‚çº§å®¹é‡é™åˆ¶"""
        level_count = sum(1 for entry in self.cache_data.values() if entry.level == level)
        level_limit = self.level_limits[level]
        
        while level_count >= level_limit:
            # æ‰¾åˆ°è¯¥å±‚çº§ä¸­é¢„æµ‹åˆ†æ•°æœ€ä½çš„é¡¹
            candidates = [(key, entry) for key, entry in self.cache_data.items() 
                         if entry.level == level]
            
            if not candidates:
                break
            
            # æŒ‰é¢„æµ‹åˆ†æ•°æ’åº
            candidates.sort(key=lambda x: x[1].prediction_score)
            
            # é™çº§æˆ–æ·˜æ±°æœ€ä½åˆ†æ•°çš„é¡¹
            victim_key, victim_entry = candidates[0]
            
            if level == CacheLevel.L1_HOT:
                victim_entry.level = CacheLevel.L2_WARM
            elif level == CacheLevel.L2_WARM:
                victim_entry.level = CacheLevel.L3_COLD
            else:
                await self._remove_entry(victim_key)
                self.stats.evictions += 1
                break
            
            level_count -= 1
    
    async def _cleanup_loop(self):
        """åå°æ¸…ç†å¾ªç¯"""
        while True:
            try:
                await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡
                await self._cleanup_expired()
                await self._analyze_patterns()
            except Exception as e:
                logger.error(f"Cleanup loop error: {e}")
    
    async def _cleanup_expired(self):
        """æ¸…ç†è¿‡æœŸæ¡ç›®"""
        now = datetime.now()
        expired_keys = []
        
        for key, entry in self.cache_data.items():
            if entry.ttl and (now - entry.created_at).total_seconds() > entry.ttl:
                expired_keys.append(key)
        
        for key in expired_keys:
            await self._remove_entry(key)
        
        if expired_keys:
            logger.debug(f"Cleaned up {len(expired_keys)} expired entries")
    
    async def _analyze_patterns(self):
        """åˆ†æè®¿é—®æ¨¡å¼"""
        self.pattern_analyzer.analyze_patterns()
        
        # æ›´æ–°æ‰€æœ‰æ¡ç›®çš„é¢„æµ‹åˆ†æ•°
        for key, entry in self.cache_data.items():
            entry.prediction_score = self.pattern_analyzer.predict_next_access(key)
    
    def _update_hit_rate(self):
        """æ›´æ–°å‘½ä¸­ç‡"""
        if self.stats.total_requests > 0:
            self.stats.hit_rate = self.stats.hits / self.stats.total_requests
    
    async def prefetch(self, keys: List[str], fetch_func: callable):
        """é¢„å–ç¼“å­˜"""
        for key in keys:
            if key not in self.cache_data:
                try:
                    # å¼‚æ­¥è·å–æ•°æ®
                    value = await fetch_func(key)
                    if value is not None:
                        await self.put(key, value)
                        logger.debug(f"Prefetched key: {key}")
                except Exception as e:
                    logger.warning(f"Prefetch failed for key {key}: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        self.stats.memory_usage = self.current_size
        
        # æŒ‰å±‚çº§ç»Ÿè®¡
        level_stats = defaultdict(int)
        for entry in self.cache_data.values():
            level_stats[entry.level.value] += 1
        
        return {
            "hits": self.stats.hits,
            "misses": self.stats.misses,
            "evictions": self.stats.evictions,
            "total_requests": self.stats.total_requests,
            "hit_rate": self.stats.hit_rate,
            "avg_access_time": self.stats.avg_access_time,
            "memory_usage": self.stats.memory_usage,
            "total_entries": len(self.cache_data),
            "level_distribution": dict(level_stats)
        }
    
    async def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache_data.clear()
        self.current_size = 0
        self.stats = CacheStats()
        logger.info("Cache cleared")
    
    async def destroy(self):
        """é”€æ¯ç¼“å­˜ç³»ç»Ÿ"""
        if self.cleanup_task:
            self.cleanup_task.cancel()
            try:
                await self.cleanup_task
            except asyncio.CancelledError:
                pass
        
        await self.clear()
        logger.info("Intelligent cache destroyed")

class PredictiveCacheManager:
    """é¢„æµ‹æ€§ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache: IntelligentCache):
        self.cache = cache
        self.prediction_model = None
        self.feature_history = []
        
    async def initialize(self):
        """åˆå§‹åŒ–é¢„æµ‹æ¨¡å‹"""
        # è¿™é‡Œå¯ä»¥åŠ è½½æœºå™¨å­¦ä¹ æ¨¡å‹
        # ç®€åŒ–å®ç°ï¼Œä½¿ç”¨åŸºäºè§„åˆ™çš„é¢„æµ‹
        logger.info("Predictive cache manager initialized")
    
    async def predict_and_prefetch(self, current_key: str, related_keys: List[str], 
                                  fetch_func: callable):
        """é¢„æµ‹å¹¶é¢„å–ç›¸å…³é”®"""
        # åˆ†æå½“å‰è®¿é—®æ¨¡å¼
        current_pattern = self.cache.pattern_analyzer.access_patterns.get(current_key, [])
        
        if len(current_pattern) < 3:
            return  # å†å²æ•°æ®ä¸è¶³
        
        # é¢„æµ‹æ¥ä¸‹æ¥å¯èƒ½è®¿é—®çš„é”®
        predictions = []
        for related_key in related_keys:
            if related_key not in self.cache.cache_data:
                # è®¡ç®—é¢„æµ‹åˆ†æ•°
                score = await self._calculate_prediction_score(current_key, related_key)
                predictions.append((related_key, score))
        
        # æŒ‰é¢„æµ‹åˆ†æ•°æ’åº
        predictions.sort(key=lambda x: x[1], reverse=True)
        
        # é¢„å–é«˜åˆ†é¡¹
        prefetch_threshold = 0.3
        for key, score in predictions:
            if score > prefetch_threshold:
                await self.cache.prefetch([key], fetch_func)
                logger.debug(f"Prefetched predicted key: {key} (score: {score:.3f})")
    
    async def _calculate_prediction_score(self, current_key: str, predicted_key: str) -> float:
        """è®¡ç®—é¢„æµ‹åˆ†æ•°"""
        # ç®€åŒ–çš„é¢„æµ‹é€»è¾‘
        current_pattern = self.cache.pattern_analyzer.access_patterns.get(current_key, [])
        predicted_pattern = self.cache.pattern_analyzer.access_patterns.get(predicted_key, [])
        
        # æ—¶é—´ç›¸å…³æ€§
        if current_pattern and predicted_pattern:
            current_times = [p["timestamp"] for p in current_pattern[-10:]]
            predicted_times = [p["timestamp"] for p in predicted_pattern[-10:]]
            
            # è®¡ç®—æ—¶é—´ç›¸å…³æ€§
            correlation = self._calculate_temporal_correlation(current_times, predicted_times)
        else:
            correlation = 0.0
        
        # é”®çš„ç›¸ä¼¼æ€§
        key_similarity = self._calculate_key_similarity(current_key, predicted_key)
        
        # ç»¼åˆé¢„æµ‹åˆ†æ•°
        prediction_score = 0.6 * correlation + 0.4 * key_similarity
        
        return prediction_score
    
    def _calculate_temporal_correlation(self, times1: List[datetime], times2: List[datetime]) -> float:
        """è®¡ç®—æ—¶é—´ç›¸å…³æ€§"""
        if not times1 or not times2:
            return 0.0
        
        # ç®€åŒ–çš„ç›¸å…³æ€§è®¡ç®—
        # æ£€æŸ¥ä¸¤ä¸ªæ—¶é—´åºåˆ—æ˜¯å¦æœ‰ç›¸ä¼¼çš„æ¨¡å¼
        recent1 = times1[-5:] if len(times1) >= 5 else times1
        recent2 = times2[-5:] if len(times2) >= 5 else times2
        
        if len(recent1) != len(recent2):
            return 0.0
        
        # è®¡ç®—æ—¶é—´é—´éš”çš„ç›¸ä¼¼åº¦
        intervals1 = [(recent1[i] - recent1[i-1]).total_seconds() for i in range(1, len(recent1))]
        intervals2 = [(recent2[i] - recent2[i-1]).total_seconds() for i in range(1, len(recent2))]
        
        if not intervals1 or not intervals2:
            return 0.0
        
        # ç®€å•çš„ç›¸å…³æ€§è®¡ç®—
        correlation = 1.0 - min(1.0, np.std(intervals1) / (np.mean(intervals1) + 0.001))
        
        return correlation
    
    def _calculate_key_similarity(self, key1: str, key2: str) -> float:
        """è®¡ç®—é”®çš„ç›¸ä¼¼æ€§"""
        # ç®€å•çš„å­—ç¬¦ä¸²ç›¸ä¼¼æ€§
        common_chars = set(key1.lower()) & set(key2.lower())
        total_chars = set(key1.lower()) | set(key2.lower())
        
        if not total_chars:
            return 0.0
        
        similarity = len(common_chars) / len(total_chars)
        return similarity

# å…¨å±€ç¼“å­˜å®ä¾‹
_intelligent_cache = None
_predictive_manager = None

async def get_intelligent_cache(config: Dict[str, Any]) -> IntelligentCache:
    """è·å–æ™ºèƒ½ç¼“å­˜å®ä¾‹"""
    global _intelligent_cache
    if _intelligent_cache is None:
        _intelligent_cache = IntelligentCache(config)
        await _intelligent_cache.initialize()
    return _intelligent_cache

async def get_predictive_manager(cache: IntelligentCache) -> PredictiveCacheManager:
    """è·å–é¢„æµ‹æ€§ç¼“å­˜ç®¡ç†å™¨"""
    global _predictive_manager
    if _predictive_manager is None:
        _predictive_manager = PredictiveCacheManager(cache)
        await _predictive_manager.initialize()
    return _predictive_manager

if __name__ == "__main__":
    async def test_intelligent_cache():
        """æµ‹è¯•æ™ºèƒ½ç¼“å­˜"""
        config = {
            "strategy": "predictive",
            "tiered_cache": {
                "l1_size": 10,
                "l2_size": 50,
                "l3_size": 100
            }
        }
        
        cache = await get_intelligent_cache(config)
        
        # æµ‹è¯•åŸºæœ¬æ“ä½œ
        await cache.put("key1", "value1")
        value = await cache.get("key1")
        print(f"Got value: {value}")
        
        # æµ‹è¯•ç»Ÿè®¡
        stats = cache.get_stats()
        print(f"Cache stats: {stats}")
        
        # æ¸…ç†
        await cache.destroy()
    
    asyncio.run(test_intelligent_cache())