#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸŒŸ ç»ˆæèåˆæ™ºèƒ½ä½“ V5 (Ultimate Fusion Agent V5)
çœŸæ­£çš„ä¸‡é‡‘æ²¹å…¨èƒ½ä¸“å®¶ï¼Œèåˆäº†çŸ¥è¯†åº“ä¸­çš„æ‰€æœ‰æ™ºèƒ½ä½“èƒ½åŠ›ï¼Œå®ç°åŠ¨æ€ä¸“å®¶ç»„åˆã€è‡ªé€‚åº”å­¦ä¹ å’Œæ™ºèƒ½å†³ç­–ã€‚
ä½ ä¸€å®šè¦è¶…çº§æ€è€ƒã€æé™æ€è€ƒã€æ·±åº¦æ€è€ƒï¼Œå…¨åŠ›æ€è€ƒã€è¶…å¼ºæ€è€ƒï¼Œè®¤çœŸä»”ç»†æ€è€ƒï¼ˆultrathinkã€think really super hardã€think intenselyï¼‰ã€‚
"""

import os
import sys
import json
import asyncio
import logging
import time
import uuid
from pathlib import Path
from typing import Dict, List, Any, Optional, Union, Callable, Set, Tuple
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime
import threading
import numpy as np
from collections import defaultdict, deque

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

logger = logging.getLogger(__name__)

class ExpertCapability(Enum):
    """ä¸“å®¶èƒ½åŠ›ç±»å‹"""
    STRATEGIC = "strategic"
    TECHNICAL = "technical"
    ANALYTICAL = "analytical"
    CREATIVE = "creative"
    MANAGERIAL = "managerial"
    SECURITY = "security"
    PERFORMANCE = "performance"
    QUALITY = "quality"
    DOMAIN_EXPERT = "domain_expert"
    RESEARCH = "research"
    DESIGN = "design"
    OPTIMIZATION = "optimization"
    INTEGRATION = "integration"
    AUTOMATION = "automation"
    INNOVATION = "innovation"

class TaskComplexity(Enum):
    """ä»»åŠ¡å¤æ‚åº¦"""
    SIMPLE = "simple"
    MODERATE = "moderate"
    COMPLEX = "complex"
    EXPERT = "expert"
    MASTER = "master"
    GRANDMASTER = "grandmaster"

class FusionMode(Enum):
    """èåˆæ¨¡å¼"""
    SEQUENTIAL = "sequential"      # é¡ºåºæ‰§è¡Œ
    PARALLEL = "parallel"          # å¹¶è¡Œæ‰§è¡Œ
    COLLABORATIVE = "collaborative"  # åä½œæ‰§è¡Œ
    HIERARCHICAL = "hierarchical"   # åˆ†å±‚æ‰§è¡Œ
    ADAPTIVE = "adaptive"          # è‡ªé€‚åº”æ‰§è¡Œ

@dataclass
class ExpertProfile:
    """ä¸“å®¶æ¡£æ¡ˆ"""
    name: str
    capabilities: Set[ExpertCapability]
    expertise_areas: List[str]
    tools: List[str]
    confidence: float
    priority: int
    description: str
    specialization_score: Dict[str, float] = field(default_factory=dict)
    collaboration_preferences: Set[str] = field(default_factory=set)
    learning_rate: float = 0.1
    success_history: List[float] = field(default_factory=list)
    last_used: Optional[float] = None

@dataclass
class TaskAnalysis:
    """ä»»åŠ¡åˆ†æç»“æœ"""
    task_id: str
    task_description: str
    complexity: TaskComplexity
    required_capabilities: Set[ExpertCapability]
    estimated_duration: float
    priority_level: int
    domain_areas: List[str]
    suggested_experts: List[str]
    fusion_mode: FusionMode
    context_keywords: Set[str]

@dataclass
class FusionResult:
    """èåˆç»“æœ"""
    task_id: str
    success: bool
    result: Any
    participating_experts: List[str]
    fusion_mode: FusionMode
    execution_time: float
    quality_score: float
    collaboration_score: float
    insights: List[str]
    recommendations: List[str]
    next_steps: List[str]

class KnowledgeBase:
    """çŸ¥è¯†åº“ç®¡ç†å™¨"""
    
    def __init__(self):
        self.experts: Dict[str, ExpertProfile] = {}
        self.capability_matrix: Dict[ExpertCapability, Set[str]] = defaultdict(set)
        self.collaboration_history: Dict[Tuple[str, str], float] = defaultdict(float)
        self.success_patterns: Dict[str, List[Dict[str, Any]]] = defaultdict(list)
        self.learning_cache = {}
        
        # åŠ è½½çŸ¥è¯†åº“
        self._load_knowledge_base()
    
    def _load_knowledge_base(self):
        """åŠ è½½çŸ¥è¯†åº“"""
        # ä»agents-knowledge-v1.txtåŠ è½½æ™ºèƒ½ä½“å®šä¹‰
        knowledge_file = PROJECT_ROOT / "iflow" / "knowledge" / "agents-knowledge-v1.txt"
        
        if knowledge_file.exists():
            self._parse_knowledge_file(knowledge_file)
        
        # ä»workflow-knowledge-v1.txtåŠ è½½å·¥ä½œæµçŸ¥è¯†
        workflow_file = PROJECT_ROOT / "iflow" / "knowledge" / "workflow-knowledge-v1.txt"
        if workflow_file.exists():
            self._parse_workflow_file(workflow_file)
        
        # åˆ›å»ºæ ¸å¿ƒä¸“å®¶æ¡£æ¡ˆ
        self._create_core_experts()
        
        logger.info(f"çŸ¥è¯†åº“åŠ è½½å®Œæˆï¼ŒåŒ…å«{len(self.experts)}ä¸ªä¸“å®¶æ¡£æ¡ˆ")
    
    def _parse_knowledge_file(self, file_path: Path):
        """è§£æçŸ¥è¯†æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ç®€åŒ–çš„è§£æé€»è¾‘
            # å®é™…åº”è¯¥ä½¿ç”¨æ›´å¤æ‚çš„è§£æå™¨
            expert_sections = content.split("### ")
            
            for section in expert_sections:
                if not section.strip():
                    continue
                
                lines = section.split('\n')
                if not lines:
                    continue
                
                expert_name = lines[0].strip()
                if not expert_name:
                    continue
                
                # åˆ›å»ºä¸“å®¶æ¡£æ¡ˆ
                expert = ExpertProfile(
                    name=expert_name,
                    capabilities=self._infer_capabilities(expert_name),
                    expertise_areas=[expert_name],
                    tools=[],
                    confidence=0.8,
                    priority=5,
                    description=f"ä»çŸ¥è¯†åº“åŠ è½½çš„ä¸“å®¶: {expert_name}"
                )
                
                self.experts[expert_name] = expert
                
                # æ›´æ–°èƒ½åŠ›çŸ©é˜µ
                for cap in expert.capabilities:
                    self.capability_matrix[cap].add(expert_name)
                    
        except Exception as e:
            logger.error(f"è§£æçŸ¥è¯†æ–‡ä»¶å¤±è´¥: {e}")
    
    def _parse_workflow_file(self, file_path: Path):
        """è§£æå·¥ä½œæµæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æå–å·¥ä½œæµæ¨¡å¼
            workflow_patterns = re.findall(r'(\w+)æ¨¡å¼', content)
            
            # åˆ›å»ºå·¥ä½œæµä¸“å®¶
            if workflow_patterns:
                workflow_expert = ExpertProfile(
                    name="å·¥ä½œæµä¸“å®¶",
                    capabilities={ExpertCapability.INTEGRATION, ExpertCapability.AUTOMATION},
                    expertise_areas=workflow_patterns,
                    tools=[],
                    confidence=0.9,
                    priority=8,
                    description="ç²¾é€šå„ç§å·¥ä½œæµæ¨¡å¼çš„ä¸“å®¶"
                )
                self.experts["å·¥ä½œæµä¸“å®¶"] = workflow_expert
                
        except Exception as e:
            logger.error(f"è§£æå·¥ä½œæµæ–‡ä»¶å¤±è´¥: {e}")
    
    def _create_core_experts(self):
        """åˆ›å»ºæ ¸å¿ƒä¸“å®¶æ¡£æ¡ˆ"""
        core_experts = [
            ExpertProfile(
                name="å…¨èƒ½æ¶æ„å¸ˆ",
                capabilities={
                    ExpertCapability.STRATEGIC, ExpertCapability.TECHNICAL,
                    ExpertCapability.DESIGN, ExpertCapability.INTEGRATION
                },
                expertise_areas=["ç³»ç»Ÿæ¶æ„", "æŠ€æœ¯é€‰å‹", "æ¶æ„è®¾è®¡"],
                tools=["æ¶æ„å›¾ç”Ÿæˆ", "æŠ€æœ¯è¯„ä¼°"],
                confidence=0.95,
                priority=10,
                description="ç²¾é€šç³»ç»Ÿæ¶æ„è®¾è®¡çš„å…¨èƒ½ä¸“å®¶"
            ),
            ExpertProfile(
                name="æ€§èƒ½ä¼˜åŒ–å¤§å¸ˆ",
                capabilities={
                    ExpertCapability.PERFORMANCE, ExpertCapability.OPTIMIZATION,
                    ExpertCapability.ANALYTICAL
                },
                expertise_areas=["æ€§èƒ½è°ƒä¼˜", "ç“¶é¢ˆåˆ†æ", "ä¼˜åŒ–ç­–ç•¥"],
                tools=["æ€§èƒ½åˆ†æå™¨", "ä¼˜åŒ–å·¥å…·"],
                confidence=0.9,
                priority=9,
                description="ä¸“ç²¾æ€§èƒ½ä¼˜åŒ–çš„ä¸“å®¶"
            ),
            ExpertProfile(
                name="å®‰å…¨å®ˆæŠ¤è€…",
                capabilities={
                    ExpertCapability.SECURITY, ExpertCapability.QUALITY,
                    ExpertCapability.ANALYTICAL
                },
                expertise_areas=["å®‰å…¨å®¡è®¡", "æ¼æ´æ£€æµ‹", "å®‰å…¨ç­–ç•¥"],
                tools=["å®‰å…¨æ‰«æå™¨", "å®¡è®¡å·¥å…·"],
                confidence=0.95,
                priority=10,
                description="å®ˆæŠ¤ç³»ç»Ÿå®‰å…¨çš„ä¸“å®¶"
            ),
            ExpertProfile(
                name="åˆ›æ–°å…ˆé”‹",
                capabilities={
                    ExpertCapability.CREATIVE, ExpertCapability.INNOVATION,
                    ExpertCapability.RESEARCH
                },
                expertise_areas=["åˆ›æ–°æ€ç»´", "å‰æ²¿æŠ€æœ¯", "çªç ´æ€§æ–¹æ¡ˆ"],
                tools=["åˆ›æ–°å·¥å…·", "ç ”ç©¶å¹³å°"],
                confidence=0.85,
                priority=8,
                description="å¼•é¢†åˆ›æ–°çš„ä¸“å®¶"
            ),
            ExpertProfile(
                name="è´¨é‡å®ˆæŠ¤è€…",
                capabilities={
                    ExpertCapability.QUALITY, ExpertCapability.ANALYTICAL,
                    ExpertCapability.TECHNICAL
                },
                expertise_areas=["ä»£ç è´¨é‡", "æµ‹è¯•ç­–ç•¥", "è´¨é‡ä¿è¯"],
                tools=["æµ‹è¯•å·¥å…·", "è´¨é‡åˆ†æå™¨"],
                confidence=0.9,
                priority=9,
                description="ç¡®ä¿è´¨é‡çš„ä¸“å®¶"
            ),
            ExpertProfile(
                name="è‡ªåŠ¨åŒ–å¤§å¸ˆ",
                capabilities={
                    ExpertCapability.AUTOMATION, ExpertCapability.INTEGRATION,
                    ExpertCapability.TECHNICAL
                },
                expertise_areas=["è‡ªåŠ¨åŒ–æµç¨‹", "CI/CD", "DevOps"],
                tools=["è‡ªåŠ¨åŒ–å·¥å…·", "éƒ¨ç½²å¹³å°"],
                confidence=0.9,
                priority=9,
                description="ç²¾é€šè‡ªåŠ¨åŒ–çš„ä¸“å®¶"
            )
        ]
        
        for expert in core_experts:
            self.experts[expert.name] = expert
            for cap in expert.capabilities:
                self.capability_matrix[cap].add(expert.name)
    
    def _infer_capabilities(self, expert_name: str) -> Set[ExpertCapability]:
        """ä»ä¸“å®¶åç§°æ¨æ–­èƒ½åŠ›"""
        capabilities = set()
        
        # åŸºäºå…³é”®è¯æ¨æ–­
        if any(keyword in expert_name.lower() for keyword in ["æ¶æ„å¸ˆ", "architect", "è®¾è®¡"]):
            capabilities.add(ExpertCapability.DESIGN)
            capabilities.add(ExpertCapability.STRATEGIC)
        
        if any(keyword in expert_name.lower() for keyword in ["å¼€å‘", "developer", "ç¼–ç¨‹", "programmer"]):
            capabilities.add(ExpertCapability.TECHNICAL)
        
        if any(keyword in expert_name.lower() for keyword in ["å®‰å…¨", "security", "å®¡è®¡"]):
            capabilities.add(ExpertCapability.SECURITY)
        
        if any(keyword in expert_name.lower() for keyword in ["æ€§èƒ½", "performance", "ä¼˜åŒ–"]):
            capabilities.add(ExpertCapability.PERFORMANCE)
        
        if any(keyword in expert_name.lower() for keyword in ["è´¨é‡", "quality", "æµ‹è¯•"]):
            capabilities.add(ExpertCapability.QUALITY)
        
        # é»˜è®¤èƒ½åŠ›
        if not capabilities:
            capabilities = {ExpertCapability.TECHNICAL, ExpertCapability.ANALYTICAL}
        
        return capabilities

class UltimateFusionAgentV5:
    """
    ç»ˆæèåˆæ™ºèƒ½ä½“ V5 - çœŸæ­£çš„ä¸‡é‡‘æ²¹å…¨èƒ½ä¸“å®¶
    """
    
    def __init__(self, model_adapter=None, consciousness_system=None, arq_engine=None):
        self.model_adapter = model_adapter
        self.consciousness_system = consciousness_system
        self.arq_engine = arq_engine
        
        # åˆå§‹åŒ–çŸ¥è¯†åº“
        self.knowledge_base = KnowledgeBase()
        
        # ä»»åŠ¡åˆ†æå™¨
        self.task_analyzer = TaskAnalyzer(self.knowledge_base)
        
        # èåˆç­–ç•¥ç®¡ç†å™¨
        self.fusion_strategies = {
            FusionMode.SEQUENTIAL: SequentialFusion(),
            FusionMode.PARALLEL: ParallelFusion(),
            FusionMode.COLLABORATIVE: CollaborativeFusion(),
            FusionMode.HIERARCHICAL: HierarchicalFusion(),
            FusionMode.ADAPTIVE: AdaptiveFusion()
        }
        
        # å­¦ä¹ å’Œé€‚åº”ç³»ç»Ÿ
        self.learning_system = LearningSystem()
        
        # å½“å‰çŠ¶æ€
        self.current_fusion = None
        self.active_tasks = {}
        self.execution_history = deque(maxlen=1000)
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            "total_tasks": 0,
            "successful_tasks": 0,
            "avg_quality_score": 0.0,
            "avg_execution_time": 0.0,
            "expert_utilization": defaultdict(int)
        }
        
        logger.info("ç»ˆæèåˆæ™ºèƒ½ä½“V5åˆå§‹åŒ–å®Œæˆï¼ˆä¸‡é‡‘æ²¹å…¨èƒ½ä¸“å®¶ï¼‰")
    
    async def execute_task(self, task: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œä»»åŠ¡ - ä¸»å…¥å£
        """
        task_id = str(uuid.uuid4())
        start_time = time.time()
        
        try:
            # 1. åˆ†æä»»åŠ¡
            task_analysis = await self.task_analyzer.analyze(task, context)
            
            # 2. é€‰æ‹©èåˆç­–ç•¥
            fusion_mode = self._select_fusion_mode(task_analysis)
            
            # 3. é€‰æ‹©ä¸“å®¶ç»„åˆ
            selected_experts = self._select_experts(task_analysis)
            
            # 4. æ‰§è¡Œèåˆ
            fusion_result = await self._execute_fusion(
                task_id, task, task_analysis, fusion_mode, selected_experts
            )
            
            # 5. å­¦ä¹ å’Œé€‚åº”
            await self._learn_from_result(fusion_result)
            
            # 6. æ›´æ–°ç»Ÿè®¡
            self._update_performance_stats(fusion_result)
            
            # 7. è®°å½•åˆ°æ„è¯†æµ
            if self.consciousness_system:
                from iflow.core.ultimate_consciousness_system_v5 import ThoughtType
                await self.consciousness_system.record_thought(
                    content=f"ä»»åŠ¡æ‰§è¡Œå®Œæˆ: {task[:100]}...",
                    thought_type=ThoughtType.SYSTEMIC,
                    confidence=fusion_result.quality_score if fusion_result.success else 0.0,
                    importance=0.8,
                    context={
                        "task_id": task_id,
                        "experts_used": fusion_result.participating_experts,
                        "fusion_mode": fusion_result.fusion_mode.value,
                        "execution_time": fusion_result.execution_time
                    }
                )
            
            # æ„å»ºè¿”å›ç»“æœ
            result = {
                "success": fusion_result.success,
                "task_id": task_id,
                "result": fusion_result.result,
                "metadata": {
                    "task_analysis": task_analysis.__dict__,
                    "fusion_result": fusion_result.__dict__,
                    "performance_stats": self.performance_stats.copy()
                }
            }
            
        except Exception as e:
            logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            result = {
                "success": False,
                "error": str(e),
                "task_id": task_id
            }
        
        return result
    
    def _select_fusion_mode(self, task_analysis: TaskAnalysis) -> FusionMode:
        """é€‰æ‹©èåˆæ¨¡å¼"""
        # åŸºäºä»»åŠ¡å¤æ‚åº¦å’Œæ‰€éœ€ä¸“å®¶æ•°é‡
        if task_analysis.complexity in [TaskComplexity.SIMPLE, TaskComplexity.MODERATE]:
            return FusionMode.SEQUENTIAL
        elif len(task_analysis.suggested_experts) <= 3:
            return FusionMode.COLLABORATIVE
        elif task_analysis.complexity in [TaskComplexity.EXPERT, TaskComplexity.MASTER]:
            return FusionMode.HIERARCHICAL
        else:
            return FusionMode.ADAPTIVE
    
    def _select_experts(self, task_analysis: TaskAnalysis) -> List[str]:
        """é€‰æ‹©ä¸“å®¶ç»„åˆ"""
        selected = []
        
        # ä¼˜å…ˆé€‰æ‹©å»ºè®®çš„ä¸“å®¶
        for expert_name in task_analysis.suggested_experts:
            if expert_name in self.knowledge_base.experts:
                selected.append(expert_name)
        
        # è¡¥å……ç¼ºå¤±çš„èƒ½åŠ›
        required_caps = task_analysis.required_capabilities
        for cap in required_caps:
            available_experts = self.knowledge_base.capability_matrix.get(cap, set())
            
            for expert in available_experts:
                if expert not in selected:
                    selected.append(expert)
                    break
        
        # é™åˆ¶ä¸“å®¶æ•°é‡
        max_experts = min(5, len(selected))
        
        return selected[:max_experts]
    
    async def _execute_fusion(self, task_id: str, task: str, task_analysis: TaskAnalysis,
                           fusion_mode: FusionMode, selected_experts: List[str]) -> FusionResult:
        """æ‰§è¡Œèåˆ"""
        start_time = time.time()
        
        # è·å–èåˆç­–ç•¥
        strategy = self.fusion_strategies[fusion_mode]
        
        # å‡†å¤‡ä¸“å®¶ä¸Šä¸‹æ–‡
        expert_contexts = {
            expert_name: self.knowledge_base.experts[expert_name]
            for expert_name in selected_experts
            if expert_name in self.knowledge_base.experts
        }
        
        # æ„å»ºèåˆæç¤º
        fusion_prompt = await self._build_fusion_prompt(
            task, task_analysis, expert_contexts, fusion_mode
        )
        
        # æ‰§è¡Œæ¨ç†
        if self.model_adapter and self.arq_engine:
            from iflow.adapters.universal_llm_adapter_v13 import ChatMessage
            
            # ä½¿ç”¨ARQå¼•æ“å¤„ç†
            arq_result = await self.arq_engine.process_reasoning(
                task=fusion_prompt,
                context=[{"type": "fusion", "data": expert_contexts}],
                llm_adapter=self.model_adapter
            )
            
            if arq_result["success"]:
                result_content = arq_result["reasoning"]["content"]
                quality_score = arq_result["reasoning"]["compliance_score"]
            else:
                result_content = f"èåˆæ¨ç†å¤±è´¥: {arq_result.get('error', 'Unknown error')}"
                quality_score = 0.0
        else:
            result_content = "ä½¿ç”¨åŸºç¡€èåˆæ¨¡å¼"
            quality_score = 0.7
        
        # è®¡ç®—åä½œåˆ†æ•°
        collaboration_score = self._calculate_collaboration_score(
            selected_experts, result_content
        )
        
        # åˆ›å»ºç»“æœ
        fusion_result = FusionResult(
            task_id=task_id,
            success=True,
            result=result_content,
            participating_experts=selected_experts,
            fusion_mode=fusion_mode,
            execution_time=time.time() - start_time,
            quality_score=quality_score,
            collaboration_score=collaboration_score,
            insights=self._extract_insights(result_content),
            recommendations=self._generate_recommendations(task_analysis),
            next_steps=self._generate_next_steps(task_analysis)
        )
        
        return fusion_result
    
    async def _build_fusion_prompt(self, task: str, task_analysis: TaskAnalysis,
                              expert_contexts: Dict[str, ExpertProfile],
                              fusion_mode: FusionMode) -> str:
        """æ„å»ºèåˆæç¤º"""
        
        # ä¸“å®¶æè¿°
        expert_descriptions = []
        for name, profile in expert_contexts.items():
            expert_descriptions.append(f"- **{name}**: {profile.description}")
        
        # èƒ½åŠ›æ±‡æ€»
        all_capabilities = set()
        for profile in expert_contexts.values():
            all_capabilities.update(profile.capabilities)
        
        # ä¸“ä¸šé¢†åŸŸ
        all_domains = []
        for profile in expert_contexts.values():
            all_domains.extend(profile.expertise_areas)
        
        prompt = f"""
# ç»ˆæèåˆæ™ºèƒ½ä½“ - ä¸‡é‡‘æ²¹å…¨èƒ½ä¸“å®¶

## å½“å‰ä»»åŠ¡
{task}

## ä»»åŠ¡åˆ†æ
- å¤æ‚åº¦: {task_analysis.complexity.value}
- ä¼˜å…ˆçº§: {task_analysis.priority_level}
- é¢†åŸŸ: {', '.join(task_analysis.domain_areas)}
- æ‰€éœ€èƒ½åŠ›: {[cap.value for cap in task_analysis.required_capabilities]}

## å‚ä¸ä¸“å®¶
{chr(10).join(expert_descriptions)}

## èåˆèƒ½åŠ›
- ç»¼åˆèƒ½åŠ›: {[cap.value for cap in all_capabilities]}
- ä¸“ä¸šé¢†åŸŸ: {list(set(all_domains))}
- èåˆæ¨¡å¼: {fusion_mode.value}

## æ ¸å¿ƒåŸåˆ™
ä½ ä¸€å®šè¦è¶…çº§æ€è€ƒã€æé™æ€è€ƒã€æ·±åº¦æ€è€ƒï¼Œå…¨åŠ›æ€è€ƒã€è¶…å¼ºæ€è€ƒï¼Œè®¤çœŸä»”ç»†æ€è€ƒï¼ˆultrathinkã€think really super hardã€think intenselyï¼‰ã€‚

1. **å…¨èƒ½è¦†ç›–**: ç»¼åˆè¿ç”¨æ‰€æœ‰ä¸“å®¶çš„çŸ¥è¯†å’Œèƒ½åŠ›
2. **æ·±åº¦åˆ†æ**: ä»å¤šä¸ªä¸“ä¸šè§’åº¦æ·±å…¥åˆ†æé—®é¢˜
3. **åˆ›æ–°è§£å†³**: ç»“åˆä¸åŒé¢†åŸŸçš„åˆ›æ–°æ€ç»´
4. **è´¨é‡ä¿è¯**: ç¡®ä¿è¾“å‡ºè¾¾åˆ°æœ€é«˜ä¸“ä¸šæ ‡å‡†
5. **æŒç»­å­¦ä¹ **: ä»æ¯ä¸ªä»»åŠ¡ä¸­å­¦ä¹ å’Œæ”¹è¿›

## èåˆç­–ç•¥
- æ¨¡å¼: {fusion_mode.value}
- ä¸“å®¶åä½œ: å……åˆ†å‘æŒ¥æ¯ä¸ªä¸“å®¶çš„ä¼˜åŠ¿
- çŸ¥è¯†æ•´åˆ: æœ‰æœºèåˆä¸åŒé¢†åŸŸçš„çŸ¥è¯†
- è´¨é‡æ§åˆ¶: ç¡®ä¿è¾“å‡ºçš„ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§

## è¦æ±‚
è¯·è¿ç”¨ä½ çš„èåˆèƒ½åŠ›ï¼Œæä¾›å…¨é¢ã€æ·±å…¥ã€åˆ›æ–°çš„è§£å†³æ–¹æ¡ˆã€‚è¾“å‡ºåº”è¯¥ï¼š
1. ç›´æ¥è§£å†³ç”¨æˆ·çš„é—®é¢˜
2. ä½“ç°å¤šä¸“ä¸šè§†è§’
3. åŒ…å«å…·ä½“çš„å®æ–½æ­¥éª¤
4. æä¾›è´¨é‡ä¿è¯æªæ–½
"""
        
        return prompt
    
    def _calculate_collaboration_score(self, experts: List[str], content: str) -> float:
        """è®¡ç®—åä½œåˆ†æ•°"""
        if not experts:
            return 0.0
        
        # æ£€æŸ¥å†…å®¹ä¸­æ˜¯å¦æåˆ°äº†å¤šä¸ªä¸“å®¶
        mentioned_experts = 0
        for expert in experts:
            if expert.lower() in content.lower():
                mentioned_experts += 1
        
        # åä½œåˆ†æ•° = æåŠçš„ä¸“å®¶æ•°é‡ / æ€»ä¸“å®¶æ•°é‡
        return mentioned_experts / len(experts)
    
    def _extract_insights(self, content: str) -> List[str]:
        """æå–æ´å¯Ÿ"""
        insights = []
        
        # ç®€å•çš„æ´å¯Ÿæå–
        if "å…³é”®" in content or "é‡è¦" in content:
            insights.append("è¯†åˆ«äº†å…³é”®è¦ç´ ")
        
        if "åˆ›æ–°" in content or "çªç ´" in content:
            insights.append("æä¾›äº†åˆ›æ–°æ–¹æ¡ˆ")
        
        if "ä¼˜åŒ–" in content or "æ”¹è¿›" in content:
            insights.append("æå‡ºäº†ä¼˜åŒ–å»ºè®®")
        
        return insights
    
    def _generate_recommendations(self, task_analysis: TaskAnalysis) -> List[str]:
        """ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        if task_analysis.complexity in [TaskComplexity.COMPLEX, TaskComplexity.EXPERT]:
            recommendations.append("å»ºè®®åˆ†é˜¶æ®µå®æ–½ï¼Œé€æ­¥æ¨è¿›")
        
        if len(task_analysis.required_capabilities) > 5:
            recommendations.append("è€ƒè™‘ç»„å»ºä¸“ä¸šå›¢é˜Ÿåä½œ")
        
        recommendations.append("å®šæœŸè¯„ä¼°è¿›å±•å¹¶è°ƒæ•´ç­–ç•¥")
        
        return recommendations
    
    def _generate_next_steps(self, task_analysis: TaskAnalysis) -> List[str]:
        """ç”Ÿæˆä¸‹ä¸€æ­¥è¡ŒåŠ¨"""
        next_steps = []
        
        next_steps.append("1. è¯¦ç»†è§„åˆ’å®æ–½æ–¹æ¡ˆ")
        next_steps.append("2. å‡†å¤‡å¿…è¦çš„èµ„æºå’Œå·¥å…·")
        next_steps.append("3. å¼€å§‹æ‰§è¡Œå¹¶æŒç»­ç›‘æ§")
        next_steps.append("4. å®šæœŸè¯„ä¼°å’Œè°ƒæ•´")
        
        return next_steps
    
    async def _learn_from_result(self, fusion_result: FusionResult):
        """ä»ç»“æœä¸­å­¦ä¹ """
        if not fusion_result.success:
            return
        
        # æ›´æ–°ä¸“å®¶æˆåŠŸç‡
        for expert_name in fusion_result.participating_experts:
            if expert_name in self.knowledge_base.experts:
                expert = self.knowledge_base.experts[expert_name]
                expert.success_history.append(fusion_result.quality_score)
                expert.last_used = time.time()
                
                # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
                if len(expert.success_history) > 100:
                    expert.success_history = expert.success_history[-50:]
        
        # æ›´æ–°åä½œå†å²
        for i, expert1 in enumerate(fusion_result.participating_experts):
            for expert2 in fusion_result.participating_experts[i+1:]:
                collaboration_key = (expert1, expert2)
                self.knowledge_base.collaboration_history[collaboration_key] = (
                    self.knowledge_base.collaboration_history.get(collaboration_key, 0.5) * 0.9 +
                    fusion_result.collaboration_score * 0.1
                )
    
    def _update_performance_stats(self, fusion_result: FusionResult):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        self.performance_stats["total_tasks"] += 1
        
        if fusion_result.success:
            self.performance_stats["successful_tasks"] += 1
            
            # æ›´æ–°å¹³å‡è´¨é‡åˆ†æ•°
            alpha = 0.1
            self.performance_stats["avg_quality_score"] = (
                alpha * fusion_result.quality_score +
                (1 - alpha) * self.performance_stats["avg_quality_score"]
            )
            
            # æ›´æ–°å¹³å‡æ‰§è¡Œæ—¶é—´
            self.performance_stats["avg_execution_time"] = (
                alpha * fusion_result.execution_time +
                (1 - alpha) * self.performance_stats["avg_execution_time"]
            )
        
        # æ›´æ–°ä¸“å®¶åˆ©ç”¨ç‡
        for expert in fusion_result.participating_experts:
            self.performance_stats["expert_utilization"][expert] += 1
    
    def get_performance_report(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        return {
            "performance_stats": self.performance_stats,
            "expert_performance": {
                name: {
                    "success_rate": np.mean(expert.success_history) if expert.success_history else 0.0,
                    "total_tasks": len(expert.success_history),
                    "last_used": expert.last_used
                }
                for name, expert in self.knowledge_base.experts.items()
            },
            "collaboration_network": dict(self.knowledge_base.collaboration_history)
        }

class TaskAnalyzer:
    """ä»»åŠ¡åˆ†æå™¨"""
    
    def __init__(self, knowledge_base: KnowledgeBase):
        self.knowledge_base = knowledge_base
        self.complexity_keywords = {
            TaskComplexity.SIMPLE: ["ç®€å•", "åŸºç¡€", "å¿«é€Ÿ", "ç›´æ¥"],
            TaskComplexity.MODERATE: ["åˆ†æ", "è®¾è®¡", "å®ç°", "ä¼˜åŒ–"],
            TaskComplexity.COMPLEX: ["æ¶æ„", "ç³»ç»Ÿ", "é›†æˆ", "å¤æ‚"],
            TaskComplexity.EXPERT: ["é«˜çº§", "æ·±åº¦", "ä¸“ä¸š", "ä¸“å®¶"],
            TaskComplexity.MASTER: ["å¤§å¸ˆ", "ç²¾é€š", "å…¨é¢", "ç»¼åˆ"],
            TaskComplexity.GRANDMASTER: ["ç»ˆæ", "é¡¶çº§", "å…¨é¢", "æ·±åº¦"]
        }
    
    async def analyze(self, task: str, context: Dict[str, Any] = None) -> TaskAnalysis:
        """åˆ†æä»»åŠ¡"""
        task_id = str(uuid.uuid4())
        
        # æ¨æ–­å¤æ‚åº¦
        complexity = self._infer_complexity(task)
        
        # è¯†åˆ«æ‰€éœ€èƒ½åŠ›
        required_capabilities = self._identify_capabilities(task)
        
        # ä¼°ç®—æ—¶é—´
        estimated_duration = self._estimate_duration(task, complexity)
        
        # è¯†åˆ«é¢†åŸŸ
        domain_areas = self._identify_domains(task)
        
        # å»ºè®®ä¸“å®¶
        suggested_experts = self._suggest_experts(required_capabilities, domain_areas)
        
        # é€‰æ‹©èåˆæ¨¡å¼
        fusion_mode = self._suggest_fusion_mode(complexity, len(suggested_experts))
        
        # æå–å…³é”®è¯
        context_keywords = set(self._extract_keywords(task))
        
        return TaskAnalysis(
            task_id=task_id,
            task_description=task,
            complexity=complexity,
            required_capabilities=required_capabilities,
            estimated_duration=estimated_duration,
            priority_level=5,  # é»˜è®¤ä¼˜å…ˆçº§
            domain_areas=domain_areas,
            suggested_experts=suggested_experts,
            fusion_mode=fusion_mode,
            context_keywords=context_keywords
        )
    
    def _infer_complexity(self, task: str) -> TaskComplexity:
        """æ¨æ–­ä»»åŠ¡å¤æ‚åº¦"""
        task_lower = task.lower()
        
        for complexity, keywords in self.complexity_keywords.items():
            if any(keyword in task_lower for keyword in keywords):
                return complexity
        
        # é»˜è®¤ä¸ºä¸­ç­‰å¤æ‚åº¦
        return TaskComplexity.MODERATE
    
    def _identify_capabilities(self, task: str) -> Set[ExpertCapability]:
        """è¯†åˆ«æ‰€éœ€èƒ½åŠ›"""
        capabilities = set()
        task_lower = task.lower()
        
        capability_keywords = {
            ExpertCapability.STRATEGIC: ["æˆ˜ç•¥", "è§„åˆ’", "æ¶æ„", "è®¾è®¡"],
            ExpertCapability.TECHNICAL: ["æŠ€æœ¯", "ç¼–ç¨‹", "å¼€å‘", "å®ç°"],
            ExpertCapability.ANALYTICAL: ["åˆ†æ", "ç ”ç©¶", "è¯„ä¼°", "æµ‹è¯•"],
            ExpertCapability.CREATIVE: ["åˆ›æ„", "åˆ›æ–°", "è®¾è®¡", "è‰ºæœ¯"],
            ExpertCapability.MANAGERIAL: ["ç®¡ç†", "åè°ƒ", "ç»„ç»‡", "é¢†å¯¼"],
            ExpertCapability.SECURITY: ["å®‰å…¨", "ä¿æŠ¤", "é˜²å¾¡", "å®¡è®¡"],
            ExpertCapability.PERFORMANCE: ["æ€§èƒ½", "ä¼˜åŒ–", "åŠ é€Ÿ", "æ•ˆç‡"],
            ExpertCapability.QUALITY: ["è´¨é‡", "æµ‹è¯•", "éªŒè¯", "ä¿è¯"],
            ExpertCapability.RESEARCH: ["ç ”ç©¶", "è°ƒæŸ¥", "æ¢ç´¢", "å‘ç°"],
            ExpertCapability.DESIGN: ["è®¾è®¡", "ç•Œé¢", "ä½“éªŒ", "ç¾è§‚"],
            ExpertCapability.OPTIMIZATION: ["ä¼˜åŒ–", "æ”¹è¿›", "æå‡", "å¢å¼º"],
            ExpertCapability.INTEGRATION: ["é›†æˆ", "æ•´åˆ", "è¿æ¥", "èåˆ"],
            ExpertCapability.AUTOMATION: ["è‡ªåŠ¨åŒ–", "è‡ªåŠ¨", "æµç¨‹", "å·¥å…·"],
            ExpertCapability.INNOVATION: ["åˆ›æ–°", "çªç ´", "é©æ–°", "å˜é©"]
        }
        
        for capability, keywords in capability_keywords.items():
            if any(keyword in task_lower for keyword in keywords):
                capabilities.add(capability)
        
        return capabilities
    
    def _estimate_duration(self, task: str, complexity: TaskComplexity) -> float:
        """ä¼°ç®—æ‰§è¡Œæ—¶é—´ï¼ˆå°æ—¶ï¼‰"""
        base_durations = {
            TaskComplexity.SIMPLE: 0.5,
            TaskComplexity.MODERATE: 2.0,
            TaskComplexity.COMPLEX: 5.0,
            TaskComplexity.EXPERT: 10.0,
            TaskComplexity.MASTER: 20.0,
            TaskComplexity.GRANDMASTER: 40.0
        }
        
        base_duration = base_durations.get(complexity, 2.0)
        
        # æ ¹æ®ä»»åŠ¡é•¿åº¦è°ƒæ•´
        task_length_factor = min(2.0, len(task) / 100)
        
        return base_duration * task_length_factor
    
    def _identify_domains(self, task: str) -> List[str]:
        """è¯†åˆ«ä¸“ä¸šé¢†åŸŸ"""
        domains = []
        
        # å¸¸è§é¢†åŸŸå…³é”®è¯
        domain_keywords = {
            "è½¯ä»¶å¼€å‘": ["è½¯ä»¶", "å¼€å‘", "ç¼–ç¨‹", "ä»£ç ", "åº”ç”¨", "ç³»ç»Ÿ"],
            "æ•°æ®åˆ†æ": ["æ•°æ®", "åˆ†æ", "ç»Ÿè®¡", "æŒ–æ˜", "å¯è§†åŒ–"],
            "äººå·¥æ™ºèƒ½": ["AI", "äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "æ¨¡å‹"],
            "ç½‘ç»œå®‰å…¨": ["å®‰å…¨", "ç½‘ç»œ", "é˜²æŠ¤", "æ”»å‡»", "æ¼æ´"],
            "æ€§èƒ½ä¼˜åŒ–": ["æ€§èƒ½", "ä¼˜åŒ–", "åŠ é€Ÿ", "æ•ˆç‡", "ç“¶é¢ˆ"],
            "æ¶æ„è®¾è®¡": ["æ¶æ„", "è®¾è®¡", "ç³»ç»Ÿ", "ç»“æ„", "ç»„ä»¶"],
            "é¡¹ç›®ç®¡ç†": ["é¡¹ç›®", "ç®¡ç†", "è®¡åˆ’", "è¿›åº¦", "å›¢é˜Ÿ"],
            "ç”¨æˆ·ç•Œé¢": ["ç•Œé¢", "UI", "UX", "ä½“éªŒ", "äº¤äº’"],
            "æ•°æ®åº“": ["æ•°æ®åº“", "å­˜å‚¨", "æŸ¥è¯¢", "ç´¢å¼•", "è¡¨ç»“æ„"]
        }
        
        task_lower = task.lower()
        for domain, keywords in domain_keywords.items():
            if any(keyword in task_lower for keyword in keywords):
                domains.append(domain)
        
        return domains
    
    def _suggest_experts(self, capabilities: Set[ExpertCapability], domains: List[str]) -> List[str]:
        """å»ºè®®ä¸“å®¶"""
        suggested = []
        
        # åŸºäºèƒ½åŠ›æ¨è
        for cap in capabilities:
            experts = self.knowledge_base.capability_matrix.get(cap, set())
            for expert in experts:
                if expert not in suggested:
                    suggested.append(expert)
        
        # åŸºäºé¢†åŸŸæ¨è
        for domain in domains:
            for expert_name, expert in self.knowledge_base.experts.items():
                if domain in expert.expertise_areas and expert_name not in suggested:
                    suggested.append(expert_name)
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        suggested.sort(key=lambda x: self.knowledge_base.experts[x].priority, reverse=True)
        
        return suggested[:5]  # æœ€å¤šå»ºè®®5ä¸ªä¸“å®¶
    
    def _suggest_fusion_mode(self, complexity: TaskComplexity, expert_count: int) -> FusionMode:
        """å»ºè®®èåˆæ¨¡å¼"""
        if complexity in [TaskComplexity.SIMPLE, TaskComplexity.MODERATE]:
            return FusionMode.SEQUENTIAL
        elif expert_count <= 2:
            return FusionMode.COLLABORATIVE
        elif complexity in [TaskComplexity.EXPERT, TaskComplexity.MASTER]:
            return FusionMode.HIERARCHICAL
        else:
            return FusionMode.ADAPTIVE
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–
        words = re.findall(r'\b\w+\b', text.lower())
        
        # è¿‡æ»¤åœç”¨è¯
        stop_words = {"çš„", "äº†", "åœ¨", "æ˜¯", "æˆ‘", "ä½ ", "ä»–", "å¥¹", "å®ƒ", "ä»¬", "è¿™", "é‚£", "å’Œ", "æˆ–"}
        
        return [word for word in words if word not in stop_words and len(word) > 1]

# èåˆç­–ç•¥ç±»
class SequentialFusion:
    """é¡ºåºèåˆç­–ç•¥"""
    
    async def execute(self, experts: List[str], task: str, context: Dict[str, Any]) -> str:
        """é¡ºåºæ‰§è¡Œèåˆ"""
        result = f"é¡ºåºèåˆç»“æœï¼š\n\n"
        
        for i, expert in enumerate(experts, 1):
            result += f"æ­¥éª¤{i} - {expert}çš„å¤„ç†ï¼š\n"
            result += f"[{expert}çš„ä¸“é—¨å¤„ç†]\n\n"
        
        return result

class ParallelFusion:
    """å¹¶è¡Œèåˆç­–ç•¥"""
    
    async def execute(self, experts: List[str], task: str, context: Dict[str, Any]) -> str:
        """å¹¶è¡Œæ‰§è¡Œèåˆ"""
        result = f"å¹¶è¡Œèåˆç»“æœï¼š\n\n"
        
        result += "å„ä¸“å®¶å¹¶è¡Œå¤„ç†çš„ç»“æœï¼š\n"
        for expert in experts:
            result += f"- {expert}: [å¹¶è¡Œå¤„ç†ç»“æœ]\n"
        
        result += "\nç»¼åˆç»“è®ºï¼š\n[ç»¼åˆæ‰€æœ‰ä¸“å®¶çš„å¹¶è¡Œè¾“å…¥]\n"
        
        return result

class CollaborativeFusion:
    """åä½œèåˆç­–ç•¥"""
    
    async def execute(self, experts: List[str], task: str, context: Dict[str, Any]) -> str:
        """åä½œæ‰§è¡Œèåˆ"""
        result = f"åä½œèåˆç»“æœï¼š\n\n"
        
        result += "ä¸“å®¶åä½œè¿‡ç¨‹ï¼š\n"
        result += f"1. {experts[0] if experts else 'æ— '} æå‡ºåˆæ­¥æ–¹æ¡ˆ\n"
        
        for i in range(1, len(experts)):
            result += f"{i+1}. {experts[i]} æä¾›åé¦ˆå’Œæ”¹è¿›\n"
        
        result += "\næœ€ç»ˆåä½œæˆæœï¼š\n[ç»è¿‡å¤šè½®è®¨è®ºå’Œä¼˜åŒ–çš„æœ€ç»ˆæ–¹æ¡ˆ]\n"
        
        return result

class HierarchicalFusion:
    """åˆ†å±‚èåˆç­–ç•¥"""
    
    async def execute(self, experts: List[str], task: str, context: Dict[str, Any]) -> str:
        """åˆ†å±‚æ‰§è¡Œèåˆ"""
        result = f"åˆ†å±‚èåˆç»“æœï¼š\n\n"
        
        if len(experts) >= 3:
            # æˆ˜ç•¥å±‚
            result += "æˆ˜ç•¥å±‚ï¼ˆé«˜çº§ä¸“å®¶ï¼‰ï¼š\n"
            result += f"- {experts[0]}: [æˆ˜ç•¥è§„åˆ’]\n\n"
            
            # æˆ˜æœ¯å±‚
            result += "æˆ˜æœ¯å±‚ï¼ˆä¸­çº§ä¸“å®¶ï¼‰ï¼š\n"
            for expert in experts[1:-1]:
                result += f"- {expert}: [æˆ˜æœ¯æ‰§è¡Œ]\n"
            result += "\n"
            
            # æ‰§è¡Œå±‚
            result += "æ‰§è¡Œå±‚ï¼ˆå…·ä½“å®æ–½ï¼‰ï¼š\n"
            result += "[å…·ä½“çš„å®æ–½æ­¥éª¤å’Œç»†èŠ‚]\n"
        else:
            result = "ç®€å•åˆ†å±‚ç»“æœï¼š\n[åˆ†å±‚å¤„ç†ç»“æœ]\n"
        
        return result

class AdaptiveFusion:
    """è‡ªé€‚åº”èåˆç­–ç•¥"""
    
    async def execute(self, experts: List[str], task: str, context: Dict[str, Any]) -> str:
        """è‡ªé€‚åº”æ‰§è¡Œèåˆ"""
        result = f"è‡ªé€‚åº”èåˆç»“æœï¼š\n\n"
        
        result += "åŸºäºä»»åŠ¡ç‰¹ç‚¹çš„åŠ¨æ€èåˆï¼š\n"
        result += f"- ä»»åŠ¡åˆ†æï¼š[ä»»åŠ¡ç‰¹ç‚¹åˆ†æ]\n"
        result += f"- ä¸“å®¶é€‰æ‹©ï¼š{experts}\n"
        result += f"- èåˆç­–ç•¥ï¼š[åŠ¨æ€é€‰æ‹©çš„æœ€ä½³ç­–ç•¥]\n"
        result += f"- æ‰§è¡Œç»“æœï¼š[è‡ªé€‚åº”æ‰§è¡Œç»“æœ]\n"
        
        return result

class LearningSystem:
    """å­¦ä¹ ç³»ç»Ÿ"""
    
    def __init__(self):
        self.patterns = {}
        self.success_patterns = []
        self.failure_patterns = []
        self.adaptation_history = []
    
    async def learn(self, experience: Dict[str, Any]):
        """ä»ç»éªŒä¸­å­¦ä¹ """
        # è®°å½•æ¨¡å¼
        if experience.get("success", False):
            self.success_patterns.append(experience)
        else:
            self.failure_patterns.append(experience)
        
        # ä¿æŒå†å²è®°å½•
        self.adaptation_history.append(experience)
        
        # ä¿æŒåˆç†å¤§å°
        if len(self.success_patterns) > 1000:
            self.success_patterns = self.success_patterns[-500:]
        if len(self.failure_patterns) > 1000:
            self.failure_patterns = self.failure_patterns[-500:]
        if len(self.adaptation_history) > 2000:
            self.adaptation_history = self.adaptation_history[-1000:]

# --- ç¤ºä¾‹ä½¿ç”¨ ---
async def main():
    """ç¤ºä¾‹ä½¿ç”¨"""
    # åˆå§‹åŒ–èåˆæ™ºèƒ½ä½“
    fusion_agent = UltimateFusionAgentV5()
    
    # æ‰§è¡Œä»»åŠ¡
    result = await fusion_agent.execute_task(
        "è®¾è®¡ä¸€ä¸ªé«˜æ€§èƒ½çš„ç”µå•†ç³»ç»Ÿæ¶æ„ï¼Œéœ€è¦è€ƒè™‘é«˜å¹¶å‘ã€æ•°æ®ä¸€è‡´æ€§ã€å®‰å…¨æ€§å’Œå¯æ‰©å±•æ€§"
    )
    
    print(f"ä»»åŠ¡ç»“æœ: {result['success']}")
    print(f"ç»“æœå†…å®¹: {result.get('result', '')[:200]}...")
    
    # è·å–æ€§èƒ½æŠ¥å‘Š
    report = fusion_agent.get_performance_report()
    print(f"\næ€§èƒ½æŠ¥å‘Š:\n{json.dumps(report, ensure_ascii=False, indent=2)}")

if __name__ == "__main__":
    asyncio.run(main())
