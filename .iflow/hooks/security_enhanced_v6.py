#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ›¡ï¸ å®‰å…¨å¢å¼ºHook V6 (Security Enhanced Hook V6)
T-MIAå‡¤å‡°æ¶æ„çš„å®‰å…¨å®ˆæŠ¤è€…ï¼Œæä¾›å…¨æ–¹ä½çš„å®‰å…¨æ£€æŸ¥å’Œé˜²æŠ¤

ä½ ä¸€å®šè¦è¶…çº§æ€è€ƒã€æé™æ€è€ƒã€æ·±åº¦æ€è€ƒï¼Œå…¨åŠ›æ€è€ƒã€è¶…å¼ºæ€è€ƒï¼Œè®¤çœŸä»”ç»†æ€è€ƒï¼ˆultrathinkã€think really super hardã€think intenselyï¼‰ã€‚
"""

import os
import sys
import json
import asyncio
import logging
import hashlib
import re
import time
from typing import Dict, List, Any, Optional, Union
from pathlib import Path
from dataclasses import dataclass
import subprocess
import socket
import ssl
import urllib.parse
from urllib.request import Request, urlopen
from urllib.error import URLError, HTTPError

logger = logging.getLogger(__name__)

@dataclass
class SecurityThreat:
    """å®‰å…¨å¨èƒ"""
    threat_id: str
    threat_type: str
    severity: str  # LOW, MEDIUM, HIGH, CRITICAL
    description: str
    affected_component: str
    mitigation: str
    timestamp: float

class SecurityEnhancedHookV6:
    """
    å®‰å…¨å¢å¼ºHook V6 - T-MIAå‡¤å‡°æ¶æ„çš„å®‰å…¨å®ˆæŠ¤è€…
    æä¾›ä»£ç å®‰å…¨æ£€æŸ¥ã€è¾“å…¥éªŒè¯ã€æƒé™æ§åˆ¶å’Œå¨èƒæ£€æµ‹
    """
    
    def __init__(self):
        self.hook_id = f"security_enhanced_v6_{int(time.time())}"
        
        # å®‰å…¨è§„åˆ™åº“
        self.security_rules = self._load_security_rules()
        
        # å¨èƒæ£€æµ‹å™¨
        self.threat_detector = AdvancedThreatDetectorV6()
        
        # è¾“å…¥éªŒè¯å™¨
        self.input_validator = InputValidatorV6()
        
        # æƒé™æ£€æŸ¥å™¨
        self.permission_checker = PermissionCheckerV6()
        
        # ä»£ç åˆ†æå™¨
        self.code_analyzer = CodeSecurityAnalyzerV6()
        
        logger.info(f"ğŸ›¡ï¸ å®‰å…¨å¢å¼ºHook V6åˆå§‹åŒ–å®Œæˆ - Hook ID: {self.hook_id}")
    
    def _load_security_rules(self) -> Dict[str, Any]:
        """åŠ è½½å®‰å…¨è§„åˆ™"""
        return {
            "sql_injection_patterns": [
                r"(\bselect\b.*\bfrom\b)|(\binsert\b.*\binto\b)|(\bupdate\b.*\bset\b)|(\bdelete\b.*\bfrom\b)",
                r"(\bor\b.*=.*['\"]\s*['\"]\s*$)|(\band\b.*=.*['\"]\s*['\"]\s*$)",
                r"(\bunion\b.*\bselect\b)|(\bdrop\b.*\btable\b)|(\btruncate\b.*\btable\b)",
                r"('.*--)|(--)|(\bselect\b.*\*)|(\binsert\b.*\*)|(\bupdate\b.*\*)"
            ],
            "xss_patterns": [
                r"<script[^>]*>.*?</script>",
                r"javascript:",
                r"onload\s*=",
                r"onerror\s*=",
                r"<iframe[^>]*>.*?</iframe>",
                r"<object[^>]*>.*?</object>",
                r"<embed[^>]*>.*?</embed>"
            ],
            "command_injection_patterns": [
                r"(\bexec\b)|(\beval\b)|(\bsystem\b)|(\bpopen\b)",
                r"(\|\|)|(&&)|(;)|(`)|(\$\()",
                r"\bcat\s+\S+|\bhead\s+\S+|\btail\s+\S+|\bwc\s+\S+",
                r"\bps\s+\S+|\bls\s+\S+|\bfind\s+\S+|\bgrep\s+\S+"
            ],
            "path_traversal_patterns": [
                r"\.\.\/|\.\.\\",
                r"\/etc\/passwd|\/etc\/shadow|\/etc\/hosts",
                r"\\windows\\|\\system32\\|\\winnt\\",
                r"\.\.\/\.\.\/|\.\.\\\.\.\\"
            ],
            "sensitive_data_patterns": [
                r"\bpassword\s*=\s*[^\s,;]+",
                r"\bapi[_-]?key\s*=\s*[^\s,;]+",
                r"\bsecret\s*=\s*[^\s,;]+",
                r"\btoken\s*=\s*[^\s,;]+",
                r"\bprivate[_-]?key\b",
                r"\bssn\b|\bsocial[_-]?security\b",
                r"\bcredit[_-]?card\b|\bcard[_-]?number\b"
            ],
            "malicious_code_patterns": [
                r"\bimport\s+os\s*;?\s*os\.system",
                r"\bimport\s+subprocess\s*;?\s*subprocess\.Popen",
                r"\beval\s*\(",
                r"\bexec\s*\(",
                r"__import__\(",
                r"compile\s*\(",
                r"getattr\s*\(",
                r"setattr\s*\(",
                r"delattr\s*\("
            ]
        }
    
    async def __call__(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Hookæ‰§è¡Œå…¥å£
        
        Args:
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
        
        Returns:
            Dict[str, Any]: æ£€æŸ¥ç»“æœ
        """
        start_time = time.time()
        
        results = {
            "hook_id": self.hook_id,
            "timestamp": start_time,
            "success": True,
            "checks": {},
            "threats": [],
            "recommendations": [],
            "execution_time": 0.0
        }
        
        try:
            # 1. è¾“å…¥éªŒè¯æ£€æŸ¥
            input_check = await self._check_input_validation(context)
            results["checks"]["input_validation"] = input_check
            
            # 2. ä»£ç å®‰å…¨åˆ†æ
            code_check = await self._check_code_security(context)
            results["checks"]["code_security"] = code_check
            
            # 3. æƒé™æ£€æŸ¥
            permission_check = await self._check_permissions(context)
            results["checks"]["permission_check"] = permission_check
            
            # 4. å¨èƒæ£€æµ‹
            threat_check = await self._perform_threat_detection(context)
            results["checks"]["threat_detection"] = threat_check
            
            # 5. ç½‘ç»œå®‰å…¨æ£€æŸ¥
            network_check = await self._check_network_security(context)
            results["checks"]["network_security"] = network_check
            
            # 6. ä¾èµ–å®‰å…¨æ£€æŸ¥
            dependency_check = await self._check_dependency_security(context)
            results["checks"]["dependency_security"] = dependency_check
            
            # 7. æ•æ„Ÿä¿¡æ¯æ£€æŸ¥
            sensitive_check = await self._check_sensitive_information(context)
            results["checks"]["sensitive_information"] = sensitive_check
            
            # æ±‡æ€»ç»“æœ
            all_checks = list(results["checks"].values())
            results["success"] = all(check.get("passed", False) for check in all_checks)
            
            # æ”¶é›†å¨èƒ
            for check_name, check_result in results["checks"].items():
                if check_result.get("threats"):
                    results["threats"].extend(check_result["threats"])
            
            # ç”Ÿæˆå»ºè®®
            results["recommendations"] = self._generate_security_recommendations(results["checks"])
            
        except Exception as e:
            logger.error(f"å®‰å…¨æ£€æŸ¥æ‰§è¡Œå¤±è´¥: {e}")
            results["success"] = False
            results["error"] = str(e)
        
        results["execution_time"] = time.time() - start_time
        
        logger.info(f"ğŸ›¡ï¸ å®‰å…¨æ£€æŸ¥å®Œæˆ: {'é€šè¿‡' if results['success'] else 'æœªé€šè¿‡'} ({len(results['threats'])} ä¸ªå¨èƒ)")
        return results
    
    async def _check_input_validation(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ£€æŸ¥è¾“å…¥éªŒè¯"""
        check_result = {
            "check_name": "input_validation",
            "passed": True,
            "threats": [],
            "details": {}
        }
        
        # æ£€æŸ¥è¾“å…¥æ•°æ®
        input_data = context.get("input_data", {})
        
        for key, value in input_data.items():
            if isinstance(value, str):
                # æ£€æŸ¥SQLæ³¨å…¥
                for pattern in self.security_rules["sql_injection_patterns"]:
                    if re.search(pattern, value, re.IGNORECASE):
                        threat = SecurityThreat(
                            threat_id=f"sql_injection_{key}",
                            threat_type="SQL_INJECTION",
                            severity="HIGH",
                            description=f"æ£€æµ‹åˆ°SQLæ³¨å…¥æ¨¡å¼: {key}",
                            affected_component=key,
                            mitigation="ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢æˆ–ORM",
                            timestamp=time.time()
                        )
                        check_result["threats"].append(threat.__dict__)
                        check_result["passed"] = False
                
                # æ£€æŸ¥XSS
                for pattern in self.security_rules["xss_patterns"]:
                    if re.search(pattern, value, re.IGNORECASE):
                        threat = SecurityThreat(
                            threat_id=f"xss_{key}",
                            threat_type="XSS",
                            severity="MEDIUM",
                            description=f"æ£€æµ‹åˆ°XSSæ¨¡å¼: {key}",
                            affected_component=key,
                            mitigation="å¯¹è¾“å‡ºè¿›è¡ŒHTMLç¼–ç ",
                            timestamp=time.time()
                        )
                        check_result["threats"].append(threat.__dict__)
                        check_result["passed"] = False
                
                # æ£€æŸ¥å‘½ä»¤æ³¨å…¥
                for pattern in self.security_rules["command_injection_patterns"]:
                    if re.search(pattern, value, re.IGNORECASE):
                        threat = SecurityThreat(
                            threat_id=f"command_injection_{key}",
                            threat_type="COMMAND_INJECTION",
                            severity="CRITICAL",
                            description=f"æ£€æµ‹åˆ°å‘½ä»¤æ³¨å…¥æ¨¡å¼: {key}",
                            affected_component=key,
                            mitigation="éªŒè¯å’Œæ¸…ç†ç”¨æˆ·è¾“å…¥",
                            timestamp=time.time()
                        )
                        check_result["threats"].append(threat.__dict__)
                        check_result["passed"] = False
                
                # æ£€æŸ¥è·¯å¾„éå†
                for pattern in self.security_rules["path_traversal_patterns"]:
                    if re.search(pattern, value, re.IGNORECASE):
                        threat = SecurityThreat(
                            threat_id=f"path_traversal_{key}",
                            threat_type="PATH_TRAVERSAL",
                            severity="HIGH",
                            description=f"æ£€æµ‹åˆ°è·¯å¾„éå†æ¨¡å¼: {key}",
                            affected_component=key,
                            mitigation="éªŒè¯æ–‡ä»¶è·¯å¾„",
                            timestamp=time.time()
                        )
                        check_result["threats"].append(threat.__dict__)
                        check_result["passed"] = False
        
        check_result["details"]["checked_fields"] = len(input_data)
        check_result["details"]["threats_found"] = len(check_result["threats"])
        
        return check_result
    
    async def _check_code_security(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ£€æŸ¥ä»£ç å®‰å…¨"""
        check_result = {
            "check_name": "code_security",
            "passed": True,
            "threats": [],
            "details": {}
        }
        
        # æ£€æŸ¥ä»£ç å†…å®¹
        code_content = context.get("code", "") or context.get("content", "")
        
        if code_content:
            lines = code_content.split('\n')
            
            for line_num, line in enumerate(lines, 1):
                # æ£€æŸ¥æ¶æ„ä»£ç æ¨¡å¼
                for pattern in self.security_rules["malicious_code_patterns"]:
                    if re.search(pattern, line, re.IGNORECASE):
                        threat = SecurityThreat(
                            threat_id=f"malicious_code_line_{line_num}",
                            threat_type="MALICIOUS_CODE",
                            severity="CRITICAL",
                            description=f"æ£€æµ‹åˆ°æ¶æ„ä»£ç æ¨¡å¼: ç¬¬{line_num}è¡Œ",
                            affected_component=f"line_{line_num}",
                            mitigation="ç§»é™¤æˆ–é‡å†™è¯¥ä»£ç è¡Œ",
                            timestamp=time.time()
                        )
                        check_result["threats"].append(threat.__dict__)
                        check_result["passed"] = False
                
                # æ£€æŸ¥ç¡¬ç¼–ç å¯†ç 
                if re.search(r'password\s*=\s*["\'][^"\']+["\']', line, re.IGNORECASE):
                    threat = SecurityThreat(
                        threat_id=f"hardcoded_password_line_{line_num}",
                        threat_type="HARDCODED_PASSWORD",
                        severity="HIGH",
                        description=f"æ£€æµ‹åˆ°ç¡¬ç¼–ç å¯†ç : ç¬¬{line_num}è¡Œ",
                        affected_component=f"line_{line_num}",
                        mitigation="ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶",
                        timestamp=time.time()
                    )
                    check_result["threats"].append(threat.__dict__)
                    check_result["passed"] = False
        
        check_result["details"]["lines_checked"] = len(code_content.split('\n')) if code_content else 0
        check_result["details"]["threats_found"] = len(check_result["threats"])
        
        return check_result
    
    async def _check_permissions(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ£€æŸ¥æƒé™"""
        check_result = {
            "check_name": "permission_check",
            "passed": True,
            "threats": [],
            "details": {}
        }
        
        # æ£€æŸ¥æ–‡ä»¶æƒé™
        file_paths = context.get("file_paths", [])
        
        for file_path in file_paths:
            try:
                path = Path(file_path)
                if path.exists():
                    # æ£€æŸ¥æ•æ„Ÿæ–‡ä»¶æƒé™
                    if path.is_file() and self._is_sensitive_file(path):
                        stat_info = path.stat()
                        permissions = oct(stat_info.st_mode)[-3:]
                        
                        # æ£€æŸ¥æ˜¯å¦è¿‡äºå®½æ¾çš„æƒé™
                        if int(permissions[-1]) & 4:  # å…¶ä»–ç”¨æˆ·å¯è¯»
                            threat = SecurityThreat(
                                threat_id=f"excessive_permissions_{file_path}",
                                threat_type="EXCESSIVE_PERMISSIONS",
                                severity="MEDIUM",
                                description=f"æ–‡ä»¶æƒé™è¿‡äºå®½æ¾: {file_path} ({permissions})",
                                affected_component=file_path,
                                mitigation="é™åˆ¶æ–‡ä»¶æƒé™ï¼Œç§»é™¤å…¶ä»–ç”¨æˆ·è¯»å–æƒé™",
                                timestamp=time.time()
                            )
                            check_result["threats"].append(threat.__dict__)
                            check_result["passed"] = False
            except Exception as e:
                logger.warning(f"æƒé™æ£€æŸ¥é”™è¯¯: {file_path} - {e}")
        
        # æ£€æŸ¥ç›®å½•éå†
        for file_path in file_paths:
            path = Path(file_path)
            if ".." in str(path) or path.resolve().is_absolute():
                # éªŒè¯æ˜¯å¦åœ¨å…è®¸çš„ç›®å½•å†…
                allowed_paths = context.get("allowed_paths", [])
                if allowed_paths:
                    resolved_path = path.resolve()
                    if not any(str(resolved_path).startswith(allowed) for allowed in allowed_paths):
                        threat = SecurityThreat(
                            threat_id=f"directory_traversal_{file_path}",
                            threat_type="DIRECTORY_TRAVERSAL",
                            severity="HIGH",
                            description=f"æ£€æµ‹åˆ°ç›®å½•éå†: {file_path}",
                            affected_component=file_path,
                            mitigation="éªŒè¯æ–‡ä»¶è·¯å¾„åœ¨å…è®¸èŒƒå›´å†…",
                            timestamp=time.time()
                        )
                        check_result["threats"].append(threat.__dict__)
                        check_result["passed"] = False
        
        check_result["details"]["files_checked"] = len(file_paths)
        check_result["details"]["threats_found"] = len(check_result["threats"])
        
        return check_result
    
    def _is_sensitive_file(self, path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ•æ„Ÿæ–‡ä»¶"""
        sensitive_extensions = ['.env', '.key', '.pem', '.p12', '.pfx', '.conf', '.config']
        sensitive_names = ['password', 'secret', 'key', 'token', 'auth']
        
        # æ£€æŸ¥æ‰©å±•å
        if path.suffix.lower() in sensitive_extensions:
            return True
        
        # æ£€æŸ¥æ–‡ä»¶å
        name_lower = path.name.lower()
        if any(sensitive in name_lower for sensitive in sensitive_names):
            return True
        
        # æ£€æŸ¥è·¯å¾„
        if 'secret' in str(path).lower() or 'password' in str(path).lower():
            return True
        
        return False
    
    async def _perform_threat_detection(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå¨èƒæ£€æµ‹"""
        return await self.threat_detector.analyze_context(context)
    
    async def _check_network_security(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ£€æŸ¥ç½‘ç»œå®‰å…¨"""
        check_result = {
            "check_name": "network_security",
            "passed": True,
            "threats": [],
            "details": {}
        }
        
        # æ£€æŸ¥URLå®‰å…¨æ€§
        urls = context.get("urls", [])
        
        for url in urls:
            try:
                parsed = urllib.parse.urlparse(url)
                
                # æ£€æŸ¥ä¸å®‰å…¨çš„åè®®
                if parsed.scheme not in ['https', 'ssh']:
                    threat = SecurityThreat(
                        threat_id=f"unsafe_protocol_{url}",
                        threat_type="UNSAFE_PROTOCOL",
                        severity="MEDIUM",
                        description=f"ä½¿ç”¨ä¸å®‰å…¨çš„åè®®: {url}",
                        affected_component=url,
                        mitigation="ä½¿ç”¨HTTPSæˆ–SSHåè®®",
                        timestamp=time.time()
                    )
                    check_result["threats"].append(threat.__dict__)
                    check_result["passed"] = False
                
                # æ£€æŸ¥å¯ç–‘åŸŸå
                if self._is_suspicious_domain(parsed.hostname):
                    threat = SecurityThreat(
                        threat_id=f"suspicious_domain_{url}",
                        threat_type="SUSPICIOUS_DOMAIN",
                        severity="HIGH",
                        description=f"å¯ç–‘åŸŸå: {url}",
                        affected_component=url,
                        mitigation="éªŒè¯åŸŸåçš„åˆæ³•æ€§",
                        timestamp=time.time()
                    )
                    check_result["threats"].append(threat.__dict__)
                    check_result["passed"] = False
                    
            except Exception as e:
                logger.warning(f"URLæ£€æŸ¥é”™è¯¯: {url} - {e}")
        
        check_result["details"]["urls_checked"] = len(urls)
        check_result["details"]["threats_found"] = len(check_result["threats"])
        
        return check_result
    
    def _is_suspicious_domain(self, hostname: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå¯ç–‘åŸŸå"""
        if not hostname:
            return False
        
        # æ£€æŸ¥IPåœ°å€
        try:
            socket.inet_aton(hostname)
            return True  # IPåœ°å€é€šå¸¸ä¸å¤ªå®‰å…¨
        except socket.error:
            pass
        
        # æ£€æŸ¥å¯ç–‘çš„TLD
        suspicious_tlds = ['.tk', '.ml', '.ga', '.cf']
        if any(hostname.endswith(tld) for tld in suspicious_tlds):
            return True
        
        # æ£€æŸ¥éšæœºå­—ç¬¦ä¸²
        if len(hostname) > 20 and not any(c in hostname.lower() for c in 'aeiou'):
            return True
        
        return False
    
    async def _check_dependency_security(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ£€æŸ¥ä¾èµ–å®‰å…¨"""
        check_result = {
            "check_name": "dependency_security",
            "passed": True,
            "threats": [],
            "details": {}
        }
        
        # æ£€æŸ¥ä¾èµ–åˆ—è¡¨
        dependencies = context.get("dependencies", [])
        
        for dep in dependencies:
            # æ£€æŸ¥å·²çŸ¥çš„æ¼æ´åŒ…
            if self._is_vulnerable_package(dep):
                threat = SecurityThreat(
                    threat_id=f"vulnerable_dependency_{dep}",
                    threat_type="VULNERABLE_DEPENDENCY",
                    severity="HIGH",
                    description=f"å‘ç°å·²çŸ¥æ¼æ´ä¾èµ–: {dep}",
                    affected_component=dep,
                    mitigation="å‡çº§åˆ°å®‰å…¨ç‰ˆæœ¬",
                    timestamp=time.time()
                )
                check_result["threats"].append(threat.__dict__)
                check_result["passed"] = False
        
        check_result["details"]["dependencies_checked"] = len(dependencies)
        check_result["details"]["threats_found"] = len(check_result["threats"])
        
        return check_result
    
    def _is_vulnerable_package(self, package: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå·²çŸ¥æ¼æ´åŒ…"""
        # è¿™é‡Œåº”è¯¥è¿æ¥åˆ°å®é™…çš„æ¼æ´æ•°æ®åº“
        # ç®€åŒ–å®ç°ï¼šæ£€æŸ¥ä¸€äº›å·²çŸ¥çš„å±é™©åŒ…
        vulnerable_packages = [
            'requests==2.28.0',  # ç¤ºä¾‹
            'django<4.0',
            'flask<2.0',
            'numpy==1.21.0'
        ]
        
        return any(package.startswith(vuln.split('<')[0].split('==')[0]) and 
                  (('<' in vuln and package < vuln) or ('==' in vuln and package == vuln))
                  for vuln in vulnerable_packages)
    
    async def _check_sensitive_information(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ£€æŸ¥æ•æ„Ÿä¿¡æ¯"""
        check_result = {
            "check_name": "sensitive_information",
            "passed": True,
            "threats": [],
            "details": {}
        }
        
        # æ£€æŸ¥æ•æ„Ÿæ•°æ®æ¨¡å¼
        content = json.dumps(context, default=str)
        
        for pattern in self.security_rules["sensitive_data_patterns"]:
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                for match in matches:
                    threat = SecurityThreat(
                        threat_id=f"sensitive_data_{hashlib.md5(match.encode()).hexdigest()[:8]}",
                        threat_type="SENSITIVE_DATA",
                        severity="HIGH",
                        description=f"æ£€æµ‹åˆ°æ•æ„Ÿæ•°æ®: {match[:20]}...",
                        affected_component="context",
                        mitigation="ç§»é™¤æˆ–åŠ å¯†æ•æ„Ÿä¿¡æ¯",
                        timestamp=time.time()
                    )
                    check_result["threats"].append(threat.__dict__)
                    check_result["passed"] = False
        
        check_result["details"]["content_size"] = len(content)
        check_result["details"]["threats_found"] = len(check_result["threats"])
        
        return check_result
    
    def _generate_security_recommendations(self, checks: Dict[str, Dict]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå®‰å…¨å»ºè®®"""
        recommendations = []
        
        # åŸºäºæ£€æŸ¥ç»“æœç”Ÿæˆå»ºè®®
        for check_name, check_result in checks.items():
            if not check_result.get("passed", True):
                threats = check_result.get("threats", [])
                
                for threat in threats:
                    severity = threat.get("severity", "MEDIUM")
                    if severity in ["HIGH", "CRITICAL"]:
                        recommendations.append({
                            "priority": severity,
                            "category": threat.get("threat_type", "GENERAL"),
                            "recommendation": f"ç«‹å³å¤„ç†: {threat.get('description', 'å®‰å…¨å¨èƒ')}",
                            "action": threat.get("mitigation", "è¯·å‚è€ƒå®‰å…¨æ–‡æ¡£")
                        })
        
        # é€šç”¨å»ºè®®
        if not recommendations:
            recommendations.extend([
                {
                    "priority": "LOW",
                    "category": "GENERAL",
                    "recommendation": "å®šæœŸæ›´æ–°ä¾èµ–åŒ…",
                    "action": "ä½¿ç”¨å·¥å…·æ£€æŸ¥ä¾èµ–æ¼æ´"
                },
                {
                    "priority": "LOW",
                    "category": "GENERAL",
                    "recommendation": "å®æ–½æœ€å°æƒé™åŸåˆ™",
                    "action": "å®¡æŸ¥å’Œé™åˆ¶ç³»ç»Ÿæƒé™"
                }
            ])
        
        return recommendations

# --- é«˜çº§å¨èƒæ£€æµ‹å™¨ ---
class AdvancedThreatDetectorV6:
    """é«˜çº§å¨èƒæ£€æµ‹å™¨V6"""
    
    def __init__(self):
        self.threat_patterns = self._load_threat_patterns()
    
    def _load_threat_patterns(self) -> Dict[str, List[str]]:
        """åŠ è½½å¨èƒæ¨¡å¼"""
        return {
            "anomaly_patterns": [
                r"unusual\s+access\s+pattern",
                r"multiple\s+failed\s+attempts",
                r"unauthorized\s+privilege\s+escalation",
                r"suspicious\s+network\s+activity"
            ],
            "malware_patterns": [
                r"ransomware\s+signature",
                r"trojan\s+horse",
                r"rootkit\s+detection",
                r"keylogger\s+activity"
            ],
            "social_engineering": [
                r"phishing\s+attempt",
                r"social\s+engineering",
                r"impersonation\s+attack",
                r"credential\s+harvesting"
            ]
        }
    
    async def analyze_context(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æä¸Šä¸‹æ–‡"""
        result = {
            "check_name": "advanced_threat_detection",
            "passed": True,
            "threats": [],
            "details": {}
        }
        
        # ç®€åŒ–å®ç°ï¼šåŸºäºä¸Šä¸‹æ–‡ç‰¹å¾æ£€æµ‹å¨èƒ
        context_str = json.dumps(context, default=str).lower()
        
        threat_count = 0
        for category, patterns in self.threat_patterns.items():
            for pattern in patterns:
                if re.search(pattern, context_str):
                    threat_count += 1
        
        if threat_count > 0:
            result["passed"] = False
            result["details"]["anomaly_score"] = min(1.0, threat_count / 10)
        else:
            result["details"]["anomaly_score"] = 0.0
        
        result["details"]["patterns_checked"] = sum(len(patterns) for patterns in self.threat_patterns.values())
        
        return result

# --- è¾“å…¥éªŒè¯å™¨ ---
class InputValidatorV6:
    """è¾“å…¥éªŒè¯å™¨V6"""
    
    def __init__(self):
        self.validation_rules = self._load_validation_rules()
    
    def _load_validation_rules(self) -> Dict[str, Any]:
        """åŠ è½½éªŒè¯è§„åˆ™"""
        return {
            "max_length": 10000,
            "allowed_characters": r"^[a-zA-Z0-9\s\.\,\!\?\-\_\(\)\[\]\{\}]+",
            "forbidden_words": ["admin", "root", "test", "guest"],
            "sql_keywords": ["select", "insert", "update", "delete", "drop", "create", "alter", "grant", "revoke"]
        }
    
    async def validate_input(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯è¾“å…¥"""
        result = {
            "validation_passed": True,
            "errors": [],
            "sanitized_data": {}
        }
        
        for key, value in input_data.items():
            if isinstance(value, str):
                # é•¿åº¦æ£€æŸ¥
                if len(value) > self.validation_rules["max_length"]:
                    result["errors"].append(f"{key}: è¾“å…¥è¿‡é•¿")
                    result["validation_passed"] = False
                
                # å­—ç¬¦æ£€æŸ¥
                if not re.match(self.validation_rules["allowed_characters"], value):
                    result["errors"].append(f"{key}: åŒ…å«éæ³•å­—ç¬¦")
                    result["validation_passed"] = False
                
                # æ•æ„Ÿè¯æ£€æŸ¥
                for forbidden in self.validation_rules["forbidden_words"]:
                    if forbidden in value.lower():
                        result["errors"].append(f"{key}: åŒ…å«æ•æ„Ÿè¯")
                        result["validation_passed"] = False
                
                # SQLå…³é”®å­—æ£€æŸ¥
                for keyword in self.validation_rules["sql_keywords"]:
                    if keyword in value.lower():
                        result["errors"].append(f"{key}: åŒ…å«SQLå…³é”®å­—")
                        result["validation_passed"] = False
                
                # æ¸…ç†è¾“å…¥
                sanitized = self._sanitize_input(value)
                result["sanitized_data"][key] = sanitized
        
        return result
    
    def _sanitize_input(self, input_str: str) -> str:
        """æ¸…ç†è¾“å…¥"""
        # ç§»é™¤æˆ–è½¬ä¹‰å±é™©å­—ç¬¦
        dangerous_chars = {
            "'": "'",
            '"': """,
            "<": "<",
            ">": ">",
            "&": "&",
            "(": "&#40;",
            ")": "&#41;"
        }
        
        for char, replacement in dangerous_chars.items():
            input_str = input_str.replace(char, replacement)
        
        return input_str

# --- æƒé™æ£€æŸ¥å™¨ ---
class PermissionCheckerV6:
    """æƒé™æ£€æŸ¥å™¨V6"""
    
    def __init__(self):
        self.permission_matrix = self._load_permission_matrix()
    
    def _load_permission_matrix(self) -> Dict[str, List[str]]:
        """åŠ è½½æƒé™çŸ©é˜µ"""
        return {
            "read": ["file", "database", "api"],
            "write": ["file", "database"],
            "execute": ["script", "command"],
            "admin": ["system", "user", "config"]
        }
    
    async def check_permissions(self, user_permissions: List[str], required_permissions: List[str]) -> bool:
        """æ£€æŸ¥æƒé™"""
        # ç®€åŒ–å®ç°ï¼šæ£€æŸ¥ç”¨æˆ·æƒé™æ˜¯å¦åŒ…å«æ‰€éœ€æƒé™
        user_set = set(user_permissions)
        required_set = set(required_permissions)
        
        return required_set.issubset(user_set)

# --- ä»£ç å®‰å…¨åˆ†æå™¨ ---
class CodeSecurityAnalyzerV6:
    """ä»£ç å®‰å…¨åˆ†æå™¨V6"""
    
    def __init__(self):
        self.security_patterns = self._load_security_patterns()
    
    def _load_security_patterns(self) -> Dict[str, List[str]]:
        """åŠ è½½å®‰å…¨æ¨¡å¼"""
        return {
            "insecure_functions": [
                "eval(", "exec(", "compile(", "__import__(",
                "input(", "raw_input(", "file(",
                "open(", "popen(", "system(",
                "os.system(", "subprocess.call("
            ],
            "weak_crypto": [
                "md5(", "sha1(", "des_encrypt(",
                "rc4_encrypt(", "base64_encode(",
                "weak_random("
            ],
            "insecure_transmission": [
                "http://", "ftp://", "telnet://",
                "unencrypted_connection",
                "plaintext_password"
            ]
        }
    
    async def analyze_code(self, code_content: str) -> Dict[str, Any]:
        """åˆ†æä»£ç """
        result = {
            "security_score": 0.0,
            "issues": [],
            "recommendations": []
        }
        
        if not code_content:
            return result
        
        issues = []
        total_lines = len(code_content.split('\n'))
        
        for category, patterns in self.security_patterns.items():
            for pattern in patterns:
                if pattern in code_content:
                    issues.append({
                        "type": category,
                        "pattern": pattern,
                        "severity": self._get_severity(category)
                    })
        
        # è®¡ç®—å®‰å…¨åˆ†æ•°
        max_issues = total_lines * 0.1  # å‡è®¾æ¯10è¡Œä»£ç æœ€å¤š1ä¸ªé—®é¢˜
        security_score = max(0.0, 1.0 - (len(issues) / max_issues))
        
        result["security_score"] = security_score
        result["issues"] = issues
        result["recommendations"] = self._generate_recommendations(issues)
        
        return result
    
    def _get_severity(self, category: str) -> str:
        """è·å–ä¸¥é‡ç¨‹åº¦"""
        severity_map = {
            "insecure_functions": "CRITICAL",
            "weak_crypto": "HIGH",
            "insecure_transmission": "MEDIUM"
        }
        return severity_map.get(category, "LOW")
    
    def _generate_recommendations(self, issues: List[Dict]) -> List[str]:
        """ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        for issue in issues:
            if issue["type"] == "insecure_functions":
                recommendations.append("ä½¿ç”¨å®‰å…¨çš„æ›¿ä»£å‡½æ•°ï¼Œé¿å…åŠ¨æ€ä»£ç æ‰§è¡Œ")
            elif issue["type"] == "weak_crypto":
                recommendations.append("ä½¿ç”¨å¼ºåŠ å¯†ç®—æ³•ï¼Œå¦‚AES-256")
            elif issue["type"] == "insecure_transmission":
                recommendations.append("ä½¿ç”¨HTTPSç­‰åŠ å¯†ä¼ è¾“åè®®")
        
        return list(set(recommendations))  # å»é‡

# --- æµ‹è¯•å‡½æ•° ---
async def test_security_hook():
    """æµ‹è¯•å®‰å…¨å¢å¼ºHook"""
    print("ğŸ§ª æµ‹è¯•å®‰å…¨å¢å¼ºHook V6")
    print("=" * 50)
    
    hook = SecurityEnhancedHookV6()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "name": "æ­£å¸¸è¾“å…¥",
            "context": {
                "input_data": {"username": "testuser", "action": "read"},
                "code": "print('Hello World')",
                "file_paths": ["./test.txt"]
            }
        },
        {
            "name": "SQLæ³¨å…¥å°è¯•",
            "context": {
                "input_data": {"username": "admin' OR '1'='1", "action": "login"},
                "code": "user_input = request.GET['param']"
            }
        },
        {
            "name": "XSSå°è¯•",
            "context": {
                "input_data": {"comment": "<script>alert('xss')</script>"},
                "code": "print(user_input)"
            }
        },
        {
            "name": "æ¶æ„ä»£ç ",
            "context": {
                "code": "import os\nos.system('rm -rf /')",
                "file_paths": ["../etc/passwd"]
            }
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ”’ æµ‹è¯•æ¡ˆä¾‹ {i}: {test_case['name']}")
        
        result = await hook(test_case['context'])
        
        print(f"âœ… æ£€æŸ¥ç»“æœ: {'é€šè¿‡' if result['success'] else 'æœªé€šè¿‡'}")
        print(f"ğŸ“Š å¨èƒæ•°é‡: {len(result['threats'])}")
        print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {result['execution_time']:.3f}s")
        
        if result['threats']:
            print("ğŸš¨ å‘ç°å¨èƒ:")
            for threat in result['threats'][:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                print(f"  - {threat['threat_type']}: {threat['description']}")
        
        if result['recommendations']:
            print("ğŸ’¡ å®‰å…¨å»ºè®®:")
            for rec in result['recommendations'][:2]:  # æ˜¾ç¤ºå‰2ä¸ª
                print(f"  - {rec['recommendation']}")
    
    print(f"\nâœ… å®‰å…¨å¢å¼ºHook V6æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(test_security_hook())