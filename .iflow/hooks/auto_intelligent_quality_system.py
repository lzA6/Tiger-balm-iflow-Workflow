#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ›¡ï¸ è‡ªåŠ¨æ™ºèƒ½è´¨é‡ç³»ç»Ÿ V4 (Auto Intelligent Quality System V4)
å…¨è‡ªåŠ¨å®¡æŸ¥ã€æµ‹è¯•ã€ä¼˜åŒ–ã€ä¿®å¤çš„ä¸€ä½“åŒ–è´¨é‡ä¿éšœç³»ç»Ÿã€‚
ä½ ä¸€å®šè¦è¶…çº§æ€è€ƒã€æé™æ€è€ƒã€æ·±åº¦æ€è€ƒï¼Œå…¨åŠ›æ€è€ƒã€è¶…å¼ºæ€è€ƒï¼Œè®¤çœŸä»”ç»†æ€è€ƒï¼ˆultrathinkã€think really super hardã€think intenselyï¼‰ã€‚
"""

import os
import sys
import json
import asyncio
import logging
import subprocess
import time
import ast
import re
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime
import threading
import queue

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

logger = logging.getLogger(__name__)

class QualityIssueType(Enum):
    """è´¨é‡é—®é¢˜ç±»å‹"""
    SYNTAX_ERROR = "syntax_error"
    STYLE_VIOLATION = "style_violation"
    SECURITY_VULNERABILITY = "security_vulnerability"
    PERFORMANCE_ISSUE = "performance_issue"
    LOGIC_ERROR = "logic_error"
    DOCUMENTATION_MISSING = "documentation_missing"
    TEST_COVERAGE_LOW = "test_coverage_low"
    DEPENDENCY_ISSUE = "dependency_issue"
    CODE_COMPLEXITY = "code_complexity"
    BEST_PRACTICE_VIOLATION = "best_practice_violation"

class Severity(Enum):
    """ä¸¥é‡ç¨‹åº¦"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"

@dataclass
class QualityIssue:
    """è´¨é‡é—®é¢˜"""
    id: str
    type: QualityIssueType
    severity: Severity
    file_path: str
    line_number: Optional[int]
    description: str
    suggestion: str
    auto_fixable: bool = False
    fixed: bool = False
    fix_applied: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class QualityReport:
    """è´¨é‡æŠ¥å‘Š"""
    timestamp: datetime
    total_issues: int
    issues_by_type: Dict[str, int]
    issues_by_severity: Dict[str, int]
    issues: List[QualityIssue]
    auto_fixes_applied: int
    metrics: Dict[str, float]
    recommendations: List[str]

class AutoIntelligentQualitySystemV4:
    """
    è‡ªåŠ¨æ™ºèƒ½è´¨é‡ç³»ç»Ÿ V4
    """
    
    def __init__(self, project_root: str = "Aé¡¹ç›®/iflow"):
        self.project_root = Path(project_root)
        self.issues_queue = queue.Queue()
        self.running = False
        self.worker_thread = None
        
        # è´¨é‡æ£€æŸ¥å™¨
        self.checkers = {
            "syntax": self._check_syntax,
            "style": self._check_style,
            "security": self._check_security,
            "performance": self._check_performance,
            "documentation": self._check_documentation,
            "test_coverage": self._check_test_coverage,
            "dependencies": self._check_dependencies,
            "complexity": self._check_complexity,
            "best_practices": self._check_best_practices
        }
        
        # è‡ªåŠ¨ä¿®å¤å™¨
        self.fixers = {
            "syntax": self._fix_syntax,
            "style": self._fix_style,
            "documentation": self._fix_documentation,
            "simple_security": self._fix_simple_security,
            "performance": self._fix_performance
        }
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_checks": 0,
            "issues_found": 0,
            "auto_fixes_applied": 0,
            "critical_issues_resolved": 0
        }
        
        logger.info("è‡ªåŠ¨æ™ºèƒ½è´¨é‡ç³»ç»ŸV4åˆå§‹åŒ–å®Œæˆ")

    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        if self.running:
            return
        
        self.running = True
        self.worker_thread = threading.Thread(target=self._worker_loop, daemon=True)
        self.worker_thread.start()
        logger.info("è´¨é‡ç›‘æ§å·²å¯åŠ¨")

    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.running = False
        if self.worker_thread:
            self.worker_thread.join(timeout=5)
        logger.info("è´¨é‡ç›‘æ§å·²åœæ­¢")

    def _worker_loop(self):
        """å·¥ä½œå¾ªç¯"""
        while self.running:
            try:
                # è·å–å¾…æ£€æŸ¥æ–‡ä»¶
                files_to_check = self._get_files_to_check()
                
                for file_path in files_to_check:
                    if not self.running:
                        break
                    
                    # æ‰§è¡Œè´¨é‡æ£€æŸ¥
                    issues = self._check_file_quality(file_path)
                    
                    # è‡ªåŠ¨ä¿®å¤
                    auto_fixed = self._auto_fix_issues(issues)
                    
                    # æ›´æ–°ç»Ÿè®¡
                    self.stats["total_checks"] += 1
                    self.stats["issues_found"] += len(issues)
                    self.stats["auto_fixes_applied"] += auto_fixed
                    
                    # ä¼‘æ¯ä¸€ä¸‹é¿å…è¿‡åº¦å ç”¨èµ„æº
                    time.sleep(0.1)
                
            except Exception as e:
                logger.error(f"è´¨é‡æ£€æŸ¥å¾ªç¯é”™è¯¯: {e}")
                time.sleep(1)

    def _get_files_to_check(self) -> List[Path]:
        """è·å–éœ€è¦æ£€æŸ¥çš„æ–‡ä»¶"""
        files_to_check = []
        
        # æ£€æŸ¥Pythonæ–‡ä»¶
        for py_file in self.project_root.rglob("*.py"):
            if not self._should_ignore_file(py_file):
                files_to_check.append(py_file)
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶
        for config_file in self.project_root.rglob("*.yaml"):
            if not self._should_ignore_file(config_file):
                files_to_check.append(config_file)
        
        for config_file in self.project_root.rglob("*.json"):
            if not self._should_ignore_file(config_file):
                files_to_check.append(config_file)
        
        # æ£€æŸ¥æ–‡æ¡£æ–‡ä»¶
        for doc_file in self.project_root.rglob("*.md"):
            if not self._should_ignore_file(doc_file):
                files_to_check.append(doc_file)
        
        return files_to_check

    def _should_ignore_file(self, file_path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å¿½ç•¥æ–‡ä»¶"""
        ignore_patterns = [
            "__pycache__",
            ".git",
            "node_modules",
            ".pytest_cache",
            ".coverage",
            "build",
            "dist",
            ".venv",
            "venv",
            "env"
        ]
        
        for pattern in ignore_patterns:
            if pattern in str(file_path):
                return True
        
        return False

    async def check_file(self, file_path: str) -> QualityReport:
        """æ£€æŸ¥å•ä¸ªæ–‡ä»¶"""
        file_path = Path(file_path)
        issues = self._check_file_quality(file_path)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = QualityReport(
            timestamp=datetime.now(),
            total_issues=len(issues),
            issues_by_type={},
            issues_by_severity={},
            issues=issues,
            auto_fixes_applied=0,
            metrics=self._calculate_metrics(file_path, issues),
            recommendations=self._generate_recommendations(issues)
        )
        
        # ç»Ÿè®¡é—®é¢˜
        for issue in issues:
            report.issues_by_type[issue.type.value] = report.issues_by_type.get(issue.type.value, 0) + 1
            report.issues_by_severity[issue.severity.value] = report.issues_by_severity.get(issue.severity.value, 0) + 1
        
        return report

    def _check_file_quality(self, file_path: Path) -> List[QualityIssue]:
        """æ£€æŸ¥æ–‡ä»¶è´¨é‡"""
        issues = []
        
        try:
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ‰§è¡Œå„ç§æ£€æŸ¥
            for checker_name, checker_func in self.checkers.items():
                try:
                    checker_issues = checker_func(file_path, content)
                    issues.extend(checker_issues)
                except Exception as e:
                    logger.warning(f"æ£€æŸ¥å™¨ {checker_name} å¤±è´¥: {e}")
        
        except Exception as e:
            issues.append(QualityIssue(
                id=f"read_error_{int(time.time())}",
                type=QualityIssueType.SYNTAX_ERROR,
                severity=Severity.HIGH,
                file_path=str(file_path),
                line_number=None,
                description=f"æ— æ³•è¯»å–æ–‡ä»¶: {str(e)}",
                suggestion="æ£€æŸ¥æ–‡ä»¶æƒé™å’Œç¼–ç ",
                auto_fixable=False
            ))
        
        return issues

    def _check_syntax(self, file_path: Path, content: str) -> List[QualityIssue]:
        """æ£€æŸ¥è¯­æ³•é”™è¯¯"""
        issues = []
        
        if file_path.suffix == '.py':
            try:
                # ä½¿ç”¨astè§£ææ£€æŸ¥è¯­æ³•
                ast.parse(content)
            except SyntaxError as e:
                issues.append(QualityIssue(
                    id=f"syntax_{int(time.time())}",
                    type=QualityIssueType.SYNTAX_ERROR,
                    severity=Severity.CRITICAL,
                    file_path=str(file_path),
                    line_number=e.lineno,
                    description=f"è¯­æ³•é”™è¯¯: {e.msg}",
                    suggestion="ä¿®å¤è¯­æ³•é”™è¯¯",
                    auto_fixable=False
                ))
        
        return issues

    def _check_style(self, file_path: Path, content: str) -> List[QualityIssue]:
        """æ£€æŸ¥ä»£ç é£æ ¼"""
        issues = []
        
        if file_path.suffix == '.py':
            lines = content.split('\n')
            
            # æ£€æŸ¥è¡Œé•¿åº¦
            for i, line in enumerate(lines, 1):
                if len(line) > 120:
                    issues.append(QualityIssue(
                        id=f"line_length_{int(time.time())}_{i}",
                        type=QualityIssueType.STYLE_VIOLATION,
                        severity=Severity.MEDIUM,
                        file_path=str(file_path),
                        line_number=i,
                        description=f"è¡Œè¿‡é•¿ ({len(line)} å­—ç¬¦)",
                        suggestion="å°†é•¿è¡Œæ‹†åˆ†ä¸ºå¤šè¡Œ",
                        auto_fixable=True
                    ))
            
            # æ£€æŸ¥å°¾éšç©ºæ ¼
            for i, line in enumerate(lines, 1):
                if line.endswith(' '):
                    issues.append(QualityIssue(
                        id=f"trailing_space_{int(time.time())}_{i}",
                        type=QualityIssueType.STYLE_VIOLATION,
                        severity=Severity.LOW,
                        file_path=str(file_path),
                        line_number=i,
                        description="è¡Œå°¾æœ‰å¤šä½™ç©ºæ ¼",
                        suggestion="ç§»é™¤è¡Œå°¾ç©ºæ ¼",
                        auto_fixable=True
                    ))
        
        return issues

    def _check_security(self, file_path: Path, content: str) -> List[QualityIssue]:
        """æ£€æŸ¥å®‰å…¨é—®é¢˜"""
        issues = []
        
        # æ£€æŸ¥ç¡¬ç¼–ç å¯†é’¥
        sensitive_patterns = [
            r'(password|passwd|pwd|secret|token|key)\s*=\s*["\'][^"\']*["\']',
            r'(api_key|apikey)\s*=\s*["\'][^"\']*["\']',
            r'(private_key|privatekey)\s*=\s*["\'][^"\']*["\']'
        ]
        
        for pattern in sensitive_patterns:
            matches = list(re.finditer(pattern, content, re.IGNORECASE))
            for match in matches:
                line_num = content[:match.start()].count('\n') + 1
                issues.append(QualityIssue(
                    id=f"security_{int(time.time())}_{line_num}",
                    type=QualityIssueType.SECURITY_VULNERABILITY,
                    severity=Severity.CRITICAL,
                    file_path=str(file_path),
                    line_number=line_num,
                    description="å‘ç°ç¡¬ç¼–ç æ•æ„Ÿä¿¡æ¯",
                    suggestion="ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶",
                    auto_fixable=False
                ))
        
        return issues

    def _check_performance(self, file_path: Path, content: str) -> List[QualityIssue]:
        """æ£€æŸ¥æ€§èƒ½é—®é¢˜"""
        issues = []
        
        if file_path.suffix == '.py':
            # æ£€æŸ¥å¾ªç¯ä¸­çš„é‡å¤è®¡ç®—
            lines = content.split('\n')
            in_loop = False
            loop_vars = set()
            
            for i, line in enumerate(lines, 1):
                stripped = line.strip()
                
                # æ£€æµ‹å¾ªç¯å¼€å§‹
                if stripped.startswith(('for ', 'while ')):
                    in_loop = True
                    # æå–å¾ªç¯å˜é‡
                    match = re.search(r'(for|while)\s+(\w+)', stripped)
                    if match:
                        loop_vars.add(match.group(2))
                
                elif stripped in ('break', 'continue', 'pass'):
                    in_loop = False
                    loop_vars.clear()
                
                # æ£€æŸ¥å¾ªç¯å†…çš„é‡å¤å‡½æ•°è°ƒç”¨
                elif in_loop:
                    for var in loop_vars:
                        pattern = rf'{var}\.\w*\('
                        matches = re.findall(pattern, line)
                        if len(matches) > 3:
                            issues.append(QualityIssue(
                                id=f"performance_{int(time.time())}_{i}",
                                type=QualityIssueType.PERFORMANCE_ISSUE,
                                severity=Severity.MEDIUM,
                                file_path=str(file_path),
                                line_number=i,
                                description=f"å¾ªç¯ä¸­é‡å¤è°ƒç”¨ {var} æ–¹æ³•",
                                suggestion="å°†ç»“æœç¼“å­˜åˆ°å¾ªç¯å¤–",
                                auto_fixable=False
                            ))
        
        return issues

    def _check_documentation(self, file_path: Path, content: str) -> List[QualityIssue]:
        """æ£€æŸ¥æ–‡æ¡£"""
        issues = []
        
        # æ£€æŸ¥æ¨¡å—æ–‡æ¡£å­—ç¬¦ä¸²
        if file_path.suffix == '.py':
            if not content.startswith('"""') and not content.startswith("'''"):
                issues.append(QualityIssue(
                    id=f"docstring_{int(time.time())}",
                    type=QualityIssueType.DOCUMENTATION_MISSING,
                    severity=Severity.MEDIUM,
                    file_path=str(file_path),
                    line_number=1,
                    description="ç¼ºå°‘æ¨¡å—æ–‡æ¡£å­—ç¬¦ä¸²",
                    suggestion="æ·»åŠ æ¨¡å—æ–‡æ¡£å­—ç¬¦ä¸²",
                    auto_fixable=True
                ))
        
        return issues

    def _check_test_coverage(self, file_path: Path, content: str) -> List[QualityIssue]:
        """æ£€æŸ¥æµ‹è¯•è¦†ç›–ç‡"""
        issues = []
        
        # ç®€åŒ–çš„æµ‹è¯•è¦†ç›–ç‡æ£€æŸ¥
        if file_path.name.startswith('test_') or 'tests' in str(file_path):
            return issues
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„æµ‹è¯•æ–‡ä»¶
        test_file = file_path.parent / f"test_{file_path.name}"
        if not test_file.exists():
            issues.append(QualityIssue(
                id=f"test_coverage_{int(time.time())}",
                type=QualityIssueType.TEST_COVERAGE_LOW,
                severity=Severity.MEDIUM,
                file_path=str(file_path),
                line_number=None,
                description="ç¼ºå°‘å¯¹åº”çš„æµ‹è¯•æ–‡ä»¶",
                suggestion=f"åˆ›å»ºæµ‹è¯•æ–‡ä»¶ {test_file.name}",
                auto_fixable=False
            ))
        
        return issues

    def _check_dependencies(self, file_path: Path, content: str) -> List[QualityIssue]:
        """æ£€æŸ¥ä¾èµ–é—®é¢˜"""
        issues = []
        
        # æ£€æŸ¥è¿‡æ—¶çš„ä¾èµ–
        outdated_packages = [
            'urllib3',
            'requests==1.x',
            'numpy==1.x',
            'pandas==1.x'
        ]
        
        for package in outdated_packages:
            if package in content:
                issues.append(QualityIssue(
                    id=f"dependency_{int(time.time())}",
                    type=QualityIssueType.DEPENDENCY_ISSUE,
                    severity=Severity.MEDIUM,
                    file_path=str(file_path),
                    line_number=None,
                    description=f"ä½¿ç”¨è¿‡æ—¶çš„ä¾èµ–: {package}",
                    suggestion="æ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬",
                    auto_fixable=False
                ))
        
        return issues

    def _check_complexity(self, file_path: Path, content: str) -> List[QualityIssue]:
        """æ£€æŸ¥ä»£ç å¤æ‚åº¦"""
        issues = []
        
        if file_path.suffix == '.py':
            try:
                tree = ast.parse(content)
                
                # æ£€æŸ¥å‡½æ•°å¤æ‚åº¦
                for node in ast.walk(tree):
                    if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                        complexity = self._calculate_complexity(node)
                        if complexity > 10:
                            issues.append(QualityIssue(
                                id=f"complexity_{int(time.time())}",
                                type=QualityIssueType.CODE_COMPLEXITY,
                                severity=Severity.HIGH,
                                file_path=str(file_path),
                                line_number=node.lineno,
                                description=f"å‡½æ•° {node.name} å¤æ‚åº¦è¿‡é«˜ ({complexity})",
                                suggestion="é‡æ„å‡½æ•°ï¼Œé™ä½å¤æ‚åº¦",
                                auto_fixable=False
                            ))
            except Exception as e:
                logger.warning(f"å¤æ‚åº¦æ£€æŸ¥å¤±è´¥: {e}")
        
        return issues

    def _check_best_practices(self, file_path: Path, content: str) -> List[QualityIssue]:
        """æ£€æŸ¥æœ€ä½³å®è·µ"""
        issues = []
        
        if file_path.suffix == '.py':
            lines = content.split('\n')
            
            # æ£€æŸ¥è£¸éœ²çš„except
            for i, line in enumerate(lines, 1):
                if 'except:' in line and line.strip() == 'except:':
                    issues.append(QualityIssue(
                        id=f"best_practice_{int(time.time())}_{i}",
                        type=QualityIssueType.BEST_PRACTICE_VIOLATION,
                        severity=Severity.MEDIUM,
                        file_path=str(file_path),
                        line_number=i,
                        description="ä½¿ç”¨è£¸éœ²çš„exceptè¯­å¥",
                        suggestion="æŒ‡å®šå…·ä½“çš„å¼‚å¸¸ç±»å‹",
                        auto_fixable=False
                    ))
        
        return issues

    def _calculate_complexity(self, node: ast.AST) -> int:
        """è®¡ç®—åœˆå¤æ‚åº¦"""
        complexity = 1  # åŸºç¡€å¤æ‚åº¦
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                complexity += 1
            elif isinstance(child, ast.ExceptHandler):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
        
        return complexity

    async def _auto_fix_issues(self, issues: List[QualityIssue]) -> int:
        """è‡ªåŠ¨ä¿®å¤é—®é¢˜"""
        fixed_count = 0
        
        # æŒ‰æ–‡ä»¶åˆ†ç»„
        issues_by_file = {}
        for issue in issues:
            if issue.auto_fixable and not issue.fixed:
                if issue.file_path not in issues_by_file:
                    issues_by_file[issue.file_path] = []
                issues_by_file[issue.file_path].append(issue)
        
        # é€ä¸ªæ–‡ä»¶ä¿®å¤
        for file_path, file_issues in issues_by_file.items():
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # åº”ç”¨ä¿®å¤
                for issue in file_issues:
                    fixer = self.fixers.get(issue.type.value)
                    if fixer:
                        try:
                            content = fixer(file_path, content, issue)
                            issue.fixed = True
                            issue.fix_applied = "è‡ªåŠ¨ä¿®å¤æˆåŠŸ"
                            fixed_count += 1
                        except Exception as e:
                            logger.warning(f"ä¿®å¤å¤±è´¥ {issue.id}: {e}")
                
                # å†™å›æ–‡ä»¶
                if any(issue.fixed for issue in file_issues):
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(content)
                    
            except Exception as e:
                logger.error(f"ä¿®å¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        return fixed_count

    def _fix_syntax(self, file_path: Path, content: str, issue: QualityIssue) -> str:
        """ä¿®å¤è¯­æ³•é”™è¯¯ï¼ˆå ä½ç¬¦å®ç°ï¼‰"""
        # è¯­æ³•é”™è¯¯é€šå¸¸éœ€è¦æ‰‹åŠ¨ä¿®å¤
        return content

    def _fix_style(self, file_path: Path, content: str, issue: QualityIssue) -> str:
        """ä¿®å¤é£æ ¼é—®é¢˜"""
        lines = content.split('\n')
        
        if issue.line_number and issue.line_number <= len(lines):
            line_idx = issue.line_number - 1
            line = lines[line_idx]
            
            if "è¡Œå°¾æœ‰å¤šä½™ç©ºæ ¼" in issue.description:
                lines[line_idx] = line.rstrip()
            elif "è¡Œè¿‡é•¿" in issue.description:
                # ç®€å•çš„è¡Œæ‹†åˆ†
                words = line.split()
                new_lines = []
                current_line = ""
                for word in words:
                    if len(current_line + word) <= 100:
                        current_line += " " + word if current_line else word
                    else:
                        new_lines.append(current_line)
                        current_line = "    " + word
                
                if current_line:
                    new_lines.append(current_line)
                
                # æ›¿æ¢åŸè¡Œ
                lines[line_idx:line_idx+1] = new_lines
        
        return '\n'.join(lines)

    def _fix_documentation(self, file_path: Path, content: str, issue: QualityIssue) -> str:
        """ä¿®å¤æ–‡æ¡£é—®é¢˜"""
        if "ç¼ºå°‘æ¨¡å—æ–‡æ¡£å­—ç¬¦ä¸²" in issue.description:
            docstring = f'"""\n{file_path.stem} æ¨¡å—\n\nè‡ªåŠ¨ç”Ÿæˆçš„æ¨¡å—æ–‡æ¡£\n"""\n\n'
            return docstring + content
        
        return content

    def _fix_simple_security(self, file_path: Path, content: str, issue: QualityIssue) -> str:
        """ä¿®å¤ç®€å•å®‰å…¨é—®é¢˜ï¼ˆå ä½ç¬¦å®ç°ï¼‰"""
        # å®‰å…¨é—®é¢˜éœ€è¦æ‰‹åŠ¨ä¿®å¤
        return content

    def _fix_performance(self, file_path: Path, content: str, issue: QualityIssue) -> str:
        """ä¿®å¤æ€§èƒ½é—®é¢˜ï¼ˆå ä½ç¬¦å®ç°ï¼‰"""
        # æ€§èƒ½é—®é¢˜éœ€è¦æ‰‹åŠ¨ä¿®å¤
        return content

    def _calculate_metrics(self, file_path: Path, issues: List[QualityIssue]) -> Dict[str, float]:
        """è®¡ç®—è´¨é‡æŒ‡æ ‡"""
        total_issues = len(issues)
        
        metrics = {
            "quality_score": max(0, 100 - total_issues * 5),  # ç®€åŒ–çš„è´¨é‡è¯„åˆ†
            "critical_issues": sum(1 for i in issues if i.severity == Severity.CRITICAL),
            "high_issues": sum(1 for i in issues if i.severity == Severity.HIGH),
            "medium_issues": sum(1 for i in issues if i.severity == Severity.MEDIUM),
            "low_issues": sum(1 for i in issues if i.severity == Severity.LOW),
            "auto_fixable_ratio": sum(1 for i in issues if i.auto_fixable) / total_issues if total_issues > 0 else 0
        }
        
        return metrics

    def _generate_recommendations(self, issues: List[QualityIssue]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # ç»Ÿè®¡é—®é¢˜ç±»å‹
        type_counts = {}
        for issue in issues:
            type_counts[issue.type.value] = type_counts.get(issue.type.value, 0) + 1
        
        # ç”Ÿæˆå»ºè®®
        if type_counts.get("syntax_error", 0) > 0:
            recommendations.append("ä¼˜å…ˆä¿®å¤è¯­æ³•é”™è¯¯ï¼Œè¿™äº›é”™è¯¯ä¼šå¯¼è‡´ä»£ç æ— æ³•è¿è¡Œ")
        
        if type_counts.get("security_vulnerability", 0) > 0:
            recommendations.append("ç«‹å³å¤„ç†å®‰å…¨é—®é¢˜ï¼Œé¿å…æ½œåœ¨çš„å®‰å…¨é£é™©")
        
        if type_counts.get("performance_issue", 0) > 5:
            recommendations.append("ä¼˜åŒ–æ€§èƒ½é—®é¢˜ï¼Œæå‡ä»£ç æ‰§è¡Œæ•ˆç‡")
        
        if type_counts.get("documentation_missing", 0) > 3:
            recommendations.append("å®Œå–„æ–‡æ¡£ï¼Œæé«˜ä»£ç å¯ç»´æŠ¤æ€§")
        
        return recommendations

    async def generate_quality_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        all_issues = []
        
        # æ”¶é›†æ‰€æœ‰é—®é¢˜
        files_to_check = self._get_files_to_check()
        for file_path in files_to_check:
            file_issues = self._check_file_quality(file_path)
            all_issues.extend(file_issues.issues)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            "timestamp": datetime.now().isoformat(),
            "total_files_checked": len(files_to_check),
            "total_issues": len(all_issues),
            "issues_by_type": {},
            "issues_by_severity": {},
            "auto_fixes_applied": self.stats["auto_fixes_applied"],
            "critical_issues_resolved": self.stats["critical_issues_resolved"],
            "overall_score": 0,
            "recommendations": []
        }
        
        # ç»Ÿè®¡é—®é¢˜
        for issue in all_issues:
            report["issues_by_type"][issue.type.value] = report["issues_by_type"].get(issue.type.value, 0) + 1
            report["issues_by_severity"][issue.severity.value] = report["issues_by_severity"].get(issue.severity.value, 0) + 1
        
        # è®¡ç®—æ€»ä½“è¯„åˆ†
        if report["total_issues"] == 0:
            report["overall_score"] = 100
        else:
            critical_weight = report["issues_by_severity"].get("critical", 0) * 10
            high_weight = report["issues_by_severity"].get("high", 0) * 5
            medium_weight = report["issues_by_severity"].get("medium", 0) * 2
            low_weight = report["issues_by_severity"].get("low", 0) * 1
            
            max_penalty = report["total_files_checked"] * 10
            penalty = critical_weight + high_weight + medium_weight + low_weight
            report["overall_score"] = max(0, 100 - (penalty / max_penalty * 100))
        
        # ç”Ÿæˆå»ºè®®
        report["recommendations"] = self._generate_recommendations(all_issues)
        
        return report

    def get_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        return {
            "running": self.running,
            "stats": self.stats,
            "checkers_available": list(self.checkers.keys()),
            "fixers_available": list(self.fixers.keys())
        }