#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ” è‡ªåŠ¨è´¨é‡æ£€æŸ¥Hook V6 (Auto Quality Check Hook V6)
T-MIAå‡¤å‡°æ¶æ„çš„è´¨é‡å®ˆæŠ¤è€…ï¼Œæä¾›å…¨æ–¹ä½çš„ä»£ç è´¨é‡æ£€æŸ¥å’Œä¼˜åŒ–å»ºè®®

ä½ ä¸€å®šè¦è¶…çº§æ€è€ƒã€æé™æ€è€ƒã€æ·±åº¦æ€è€ƒï¼Œå…¨åŠ›æ€è€ƒã€è¶…å¼ºæ€è€ƒï¼Œè®¤çœŸä»”ç»†æ€è€ƒï¼ˆultrathinkã€think really super hardã€think intenselyï¼‰ã€‚
"""

import os
import sys
import json
import asyncio
import logging
import ast
import re
import time
import hashlib
from typing import Dict, List, Any, Optional, Union, Tuple
from pathlib import Path
from dataclasses import dataclass
import subprocess
import importlib.util
from collections import defaultdict, Counter

logger = logging.getLogger(__name__)

@dataclass
class QualityIssue:
    """è´¨é‡é—®é¢˜"""
    issue_id: str
    issue_type: str
    severity: str  # LOW, MEDIUM, HIGH, CRITICAL
    file_path: str
    line_number: int
    description: str
    suggestion: str
    category: str
    timestamp: float

class AutoQualityCheckHookV6:
    """
    è‡ªåŠ¨è´¨é‡æ£€æŸ¥Hook V6 - T-MIAå‡¤å‡°æ¶æ„çš„è´¨é‡å®ˆæŠ¤è€…
    æä¾›ä»£ç è´¨é‡æ£€æŸ¥ã€æ€§èƒ½åˆ†æã€è§„èŒƒéªŒè¯å’Œä¼˜åŒ–å»ºè®®
    """
    
    def __init__(self):
        self.hook_id = f"auto_quality_check_v6_{int(time.time())}"
        
        # è´¨é‡æ£€æŸ¥å™¨
        self.code_analyzer = CodeQualityAnalyzerV6()
        self.performance_analyzer = PerformanceAnalyzerV6()
        self.security_analyzer = SecurityAnalyzerV6()
        self.complexity_analyzer = ComplexityAnalyzerV6()
        self.documentation_analyzer = DocumentationAnalyzerV6()
        
        # è´¨é‡æ ‡å‡†
        self.quality_standards = self._load_quality_standards()
        
        # æ£€æŸ¥è§„åˆ™
        self.check_rules = self._load_check_rules()
        
        logger.info(f"ğŸ” è‡ªåŠ¨è´¨é‡æ£€æŸ¥Hook V6åˆå§‹åŒ–å®Œæˆ - Hook ID: {self.hook_id}")
    
    def _load_quality_standards(self) -> Dict[str, Any]:
        """åŠ è½½è´¨é‡æ ‡å‡†"""
        return {
            "code_coverage": {
                "minimum": 80.0,
                "target": 90.0,
                "critical": 95.0
            },
            "cyclomatic_complexity": {
                "max_function": 10,
                "max_class": 15,
                "max_module": 20
            },
            "code_smells": {
                "max_per_file": 5,
                "max_per_module": 20,
                "critical_threshold": 50
            },
            "security_vulnerabilities": {
                "critical": 0,
                "high": 0,
                "medium": 5,
                "low": 10
            },
            "performance_metrics": {
                "max_response_time": 1000,  # ms
                "max_memory_usage": 100,    # MB
                "min_throughput": 100       # QPS
            }
        }
    
    def _load_check_rules(self) -> Dict[str, List[str]]:
        """åŠ è½½æ£€æŸ¥è§„åˆ™"""
        return {
            "naming_conventions": [
                r"^[a-z_][a-z0-9_]*$",  # å˜é‡å
                r"^[A-Z][a-zA-Z0-9]*$",  # ç±»å
                r"^[a-z_][a-z0-9_]*$",  # å‡½æ•°å
                r"^[A-Z_]+$"            # å¸¸é‡å
            ],
            "code_patterns": [
                "import \*",              # ç¦æ­¢ä½¿ç”¨import *
                "print\(",               # é¿å…ä½¿ç”¨print
                "TODO|FIXME|HACK",       # å¾…å¤„ç†æ ‡è®°
                "^\s*#\s*[A-Z]",         # æ³¨é‡Šæ ¼å¼
                "^\s*\"\"\".*\"\"\"$",   # æ–‡æ¡£å­—ç¬¦ä¸²
            ],
            "performance_issues": [
                "for.*in.*range\(\d{3,}\)",  # å¤§å¾ªç¯
                "while\s+True:",             # æ— é™å¾ªç¯
                "time\.sleep\(",             # ç¡çœ è°ƒç”¨
                "sync.*database",            # åŒæ­¥æ•°æ®åº“æ“ä½œ
            ]
        }
    
    async def __call__(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Hookæ‰§è¡Œå…¥å£
        
        Args:
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
        
        Returns:
            Dict[str, Any]: æ£€æŸ¥ç»“æœ
        """
        start_time = time.time()
        
        results = {
            "hook_id": self.hook_id,
            "timestamp": start_time,
            "success": True,
            "quality_score": 0.0,
            "checks": {},
            "issues": [],
            "recommendations": [],
            "metrics": {},
            "execution_time": 0.0
        }
        
        try:
            # 1. ä»£ç è´¨é‡åˆ†æ
            code_check = await self._analyze_code_quality(context)
            results["checks"]["code_quality"] = code_check
            
            # 2. æ€§èƒ½åˆ†æ
            performance_check = await self._analyze_performance(context)
            results["checks"]["performance"] = performance_check
            
            # 3. å®‰å…¨åˆ†æ
            security_check = await self._analyze_security(context)
            results["checks"]["security"] = security_check
            
            # 4. å¤æ‚åº¦åˆ†æ
            complexity_check = await self._analyze_complexity(context)
            results["checks"]["complexity"] = complexity_check
            
            # 5. æ–‡æ¡£åˆ†æ
            documentation_check = await self._analyze_documentation(context)
            results["checks"]["documentation"] = documentation_check
            
            # 6. ä»£ç é£æ ¼æ£€æŸ¥
            style_check = await self._check_coding_style(context)
            results["checks"]["coding_style"] = style_check
            
            # æ±‡æ€»ç»“æœ
            all_checks = list(results["checks"].values())
            results["success"] = all(check.get("passed", False) for check in all_checks)
            
            # æ”¶é›†é—®é¢˜
            for check_name, check_result in results["checks"].items():
                if check_result.get("issues"):
                    results["issues"].extend(check_result["issues"])
            
            # è®¡ç®—è´¨é‡åˆ†æ•°
            results["quality_score"] = self._calculate_quality_score(results["checks"])
            
            # ç”Ÿæˆå»ºè®®
            results["recommendations"] = self._generate_quality_recommendations(results["issues"])
            
            # ç”ŸæˆæŒ‡æ ‡
            results["metrics"] = self._generate_quality_metrics(results["checks"])
            
        except Exception as e:
            logger.error(f"è´¨é‡æ£€æŸ¥æ‰§è¡Œå¤±è´¥: {e}")
            results["success"] = False
            results["error"] = str(e)
        
        results["execution_time"] = time.time() - start_time
        
        logger.info(f"ğŸ” è´¨é‡æ£€æŸ¥å®Œæˆ: åˆ†æ•° {results['quality_score']:.2f}, é—®é¢˜ {len(results['issues'])} ä¸ª")
        return results
    
    async def _analyze_code_quality(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æä»£ç è´¨é‡"""
        check_result = {
            "check_name": "code_quality",
            "passed": True,
            "score": 0.0,
            "issues": [],
            "details": {}
        }
        
        # è·å–ä»£ç å†…å®¹
        code_content = context.get("code", "") or context.get("content", "")
        file_path = context.get("file_path", "unknown")
        
        if not code_content:
            check_result["details"]["status"] = "no_code_provided"
            return check_result
        
        try:
            # è§£æAST
            tree = ast.parse(code_content)
            
            # ä»£ç è´¨é‡åˆ†æ
            quality_issues = []
            
            # æ£€æŸ¥å¯¼å…¥è¯­å¥
            import_issues = self._check_imports(tree, file_path)
            quality_issues.extend(import_issues)
            
            # æ£€æŸ¥å‡½æ•°å®šä¹‰
            function_issues = self._check_functions(tree, file_path)
            quality_issues.extend(function_issues)
            
            # æ£€æŸ¥ç±»å®šä¹‰
            class_issues = self._check_classes(tree, file_path)
            quality_issues.extend(class_issues)
            
            # æ£€æŸ¥ä»£ç æ¨¡å¼
            pattern_issues = self._check_code_patterns(code_content, file_path)
            quality_issues.extend(pattern_issues)
            
            # æ£€æŸ¥ç©ºå€¼å¤„ç†
            null_issues = self._check_null_handling(tree, file_path)
            quality_issues.extend(null_issues)
            
            check_result["issues"] = quality_issues
            
            # è®¡ç®—è´¨é‡åˆ†æ•°
            max_issues = 20  # æœ€å¤§é—®é¢˜æ•°
            score = max(0.0, 1.0 - (len(quality_issues) / max_issues))
            check_result["score"] = score
            check_result["passed"] = score >= 0.7
            
            check_result["details"] = {
                "lines_of_code": len(code_content.split('\n')),
                "functions_found": len([node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]),
                "classes_found": len([node for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]),
                "issues_found": len(quality_issues)
            }
            
        except SyntaxError as e:
            quality_issues = [QualityIssue(
                issue_id=f"syntax_error_{file_path}",
                issue_type="SYNTAX_ERROR",
                severity="CRITICAL",
                file_path=file_path,
                line_number=e.lineno or 0,
                description=f"è¯­æ³•é”™è¯¯: {e.msg}",
                suggestion="ä¿®å¤è¯­æ³•é”™è¯¯",
                category="code_quality",
                timestamp=time.time()
            )]
            check_result["issues"] = [issue.__dict__ for issue in quality_issues]
            check_result["passed"] = False
            check_result["score"] = 0.0
            check_result["details"]["syntax_error"] = str(e)
        
        return check_result
    
    def _check_imports(self, tree: ast.Module, file_path: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥å¯¼å…¥è¯­å¥"""
        issues = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    # æ£€æŸ¥é€šé…ç¬¦å¯¼å…¥
                    if alias.name == "*":
                        issue = QualityIssue(
                            issue_id=f"wildcard_import_{file_path}",
                            issue_type="WILDCARD_IMPORT",
                            severity="MEDIUM",
                            file_path=file_path,
                            line_number=node.lineno,
                            description="ä½¿ç”¨äº†é€šé…ç¬¦å¯¼å…¥ (*)",
                            suggestion="æ˜ç¡®å¯¼å…¥éœ€è¦çš„æ¨¡å—æˆ–å‡½æ•°",
                            category="imports",
                            timestamp=time.time()
                        )
                        issues.append(issue.__dict__)
                    
                    # æ£€æŸ¥æœªä½¿ç”¨çš„å¯¼å…¥ï¼ˆç®€åŒ–æ£€æŸ¥ï¼‰
                    if alias.name.startswith("_"):
                        issue = QualityIssue(
                            issue_id=f"unused_import_{file_path}_{alias.name}",
                            issue_type="UNUSED_IMPORT",
                            severity="LOW",
                            file_path=file_path,
                            line_number=node.lineno,
                            description=f"å¯èƒ½å­˜åœ¨æœªä½¿ç”¨çš„å¯¼å…¥: {alias.name}",
                            suggestion="ç§»é™¤æœªä½¿ç”¨çš„å¯¼å…¥",
                            category="imports",
                            timestamp=time.time()
                        )
                        issues.append(issue.__dict__)
            
            elif isinstance(node, ast.ImportFrom):
                # æ£€æŸ¥ä»æ ‡å‡†åº“çš„å¯¼å…¥
                if node.module and node.module.startswith("."):
                    # ç›¸å¯¹å¯¼å…¥æ£€æŸ¥
                    if len(node.module) > 3:
                        issue = QualityIssue(
                            issue_id=f"deep_relative_import_{file_path}",
                            issue_type="DEEP_RELATIVE_IMPORT",
                            severity="LOW",
                            file_path=file_path,
                            line_number=node.lineno,
                            description="ä½¿ç”¨äº†è¿‡æ·±çš„ç›¸å¯¹å¯¼å…¥",
                            suggestion="è€ƒè™‘ä½¿ç”¨ç»å¯¹å¯¼å…¥",
                            category="imports",
                            timestamp=time.time()
                        )
                        issues.append(issue.__dict__)
        
        return issues
    
    def _check_functions(self, tree: ast.Module, file_path: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥å‡½æ•°å®šä¹‰"""
        issues = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                # æ£€æŸ¥å‡½æ•°é•¿åº¦
                if hasattr(node, 'end_lineno'):
                    func_lines = node.end_lineno - node.lineno
                    if func_lines > 50:
                        issue = QualityIssue(
                            issue_id=f"long_function_{file_path}_{node.name}",
                            issue_type="LONG_FUNCTION",
                            severity="MEDIUM",
                            file_path=file_path,
                            line_number=node.lineno,
                            description=f"å‡½æ•°è¿‡é•¿: {func_lines} è¡Œ",
                            suggestion="å°†å‡½æ•°æ‹†åˆ†ä¸ºæ›´å°çš„å‡½æ•°",
                            category="functions",
                            timestamp=time.time()
                        )
                        issues.append(issue.__dict__)
                
                # æ£€æŸ¥å‚æ•°æ•°é‡
                if len(node.args.args) > 7:
                    issue = QualityIssue(
                        issue_id=f"too_many_params_{file_path}_{node.name}",
                        issue_type="TOO_MANY_PARAMETERS",
                        severity="MEDIUM",
                        file_path=file_path,
                        line_number=node.lineno,
                        description=f"å‡½æ•°å‚æ•°è¿‡å¤š: {len(node.args.args)} ä¸ª",
                        suggestion="å‡å°‘å‚æ•°æ•°é‡æˆ–ä½¿ç”¨æ•°æ®ç±»",
                        category="functions",
                        timestamp=time.time()
                    )
                    issues.append(issue.__dict__)
                
                # æ£€æŸ¥è¿”å›å€¼
                if not any(isinstance(n, ast.Return) for n in ast.walk(node)):
                    issue = QualityIssue(
                        issue_id=f"no_return_statement_{file_path}_{node.name}",
                        issue_type="NO_RETURN_STATEMENT",
                        severity="LOW",
                        file_path=file_path,
                        line_number=node.lineno,
                        description=f"å‡½æ•°ç¼ºå°‘è¿”å›è¯­å¥: {node.name}",
                        suggestion="æ·»åŠ é€‚å½“çš„è¿”å›è¯­å¥",
                        category="functions",
                        timestamp=time.time()
                    )
                    issues.append(issue.__dict__)
        
        return issues
    
    def _check_classes(self, tree: ast.Module, file_path: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥ç±»å®šä¹‰"""
        issues = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                # æ£€æŸ¥ç±»çš„å¤§å°
                method_count = len([n for n in node.body if isinstance(n, ast.FunctionDef)])
                if method_count > 20:
                    issue = QualityIssue(
                        issue_id=f"large_class_{file_path}_{node.name}",
                        issue_type="LARGE_CLASS",
                        severity="MEDIUM",
                        file_path=file_path,
                        line_number=node.lineno,
                        description=f"ç±»è¿‡å¤§: {method_count} ä¸ªæ–¹æ³•",
                        suggestion="å°†ç±»æ‹†åˆ†ä¸ºæ›´å°çš„ç±»",
                        category="classes",
                        timestamp=time.time()
                    )
                    issues.append(issue.__dict__)
                
                # æ£€æŸ¥ç»§æ‰¿æ·±åº¦
                if len(node.bases) > 2:
                    issue = QualityIssue(
                        issue_id=f"deep_inheritance_{file_path}_{node.name}",
                        issue_type="DEEP_INHERITANCE",
                        severity="LOW",
                        file_path=file_path,
                        line_number=node.lineno,
                        description=f"ç»§æ‰¿å±‚æ¬¡è¿‡æ·±: {len(node.bases)} ä¸ªåŸºç±»",
                        suggestion="è€ƒè™‘ä½¿ç”¨ç»„åˆè€Œéç»§æ‰¿",
                        category="classes",
                        timestamp=time.time()
                    )
                    issues.append(issue.__dict__)
        
        return issues
    
    def _check_code_patterns(self, code_content: str, file_path: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥ä»£ç æ¨¡å¼"""
        issues = []
        
        lines = code_content.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            # æ£€æŸ¥è°ƒè¯•ä»£ç 
            if re.search(r"print\s*\(", line) and "logger" not in line:
                issue = QualityIssue(
                    issue_id=f"debug_print_{file_path}_{line_num}",
                    issue_type="DEBUG_PRINT",
                    severity="LOW",
                    file_path=file_path,
                    line_number=line_num,
                    description="å‘ç°è°ƒè¯•æ‰“å°è¯­å¥",
                    suggestion="ä½¿ç”¨æ—¥å¿—ç³»ç»Ÿæ›¿ä»£printè¯­å¥",
                    category="patterns",
                    timestamp=time.time()
                )
                issues.append(issue.__dict__)
            
            # æ£€æŸ¥TODOæ³¨é‡Š
            if re.search(r"#\s*TODO|#\s*FIXME|#\s*HACK", line, re.IGNORECASE):
                match = re.search(r"#\s*(TODO|FIXME|HACK)", line, re.IGNORECASE)
                severity = "MEDIUM" if match.group(1).upper() in ["FIXME", "HACK"] else "LOW"
                
                issue = QualityIssue(
                    issue_id=f"todo_comment_{file_path}_{line_num}",
                    issue_type="TODO_COMMENT",
                    severity=severity,
                    file_path=file_path,
                    line_number=line_num,
                    description=f"å‘ç°å¾…å¤„ç†æ³¨é‡Š: {match.group(1)}",
                    suggestion="åŠæ—¶å¤„ç†æˆ–ç§»é™¤TODOæ³¨é‡Š",
                    category="patterns",
                    timestamp=time.time()
                )
                issues.append(issue.__dict__)
            
            # æ£€æŸ¥é­”æ³•æ•°å­—
            if re.search(r"\b\d{3,}\b", line) and "import" not in line:
                issue = QualityIssue(
                    issue_id=f"magic_number_{file_path}_{line_num}",
                    issue_type="MAGIC_NUMBER",
                    severity="LOW",
                    file_path=file_path,
                    line_number=line_num,
                    description="å‘ç°é­”æ³•æ•°å­—",
                    suggestion="ä½¿ç”¨å¸¸é‡æ›¿ä»£é­”æ³•æ•°å­—",
                    category="patterns",
                    timestamp=time.time()
                )
                issues.append(issue.__dict__)
        
        return issues
    
    def _check_null_handling(self, tree: ast.Module, file_path: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥ç©ºå€¼å¤„ç†"""
        issues = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Compare):
                # æ£€æŸ¥ None æ¯”è¾ƒ
                if any(isinstance(comp, ast.NameConstant) and comp.value is None 
                       for comp in node.comparators):
                    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ is è€Œä¸æ˜¯ ==
                    if isinstance(node.ops[0], ast.Eq):
                        issue = QualityIssue(
                            issue_id=f"none_equality_{file_path}_{node.lineno}",
                            issue_type="NONE_EQUALITY",
                            severity="MEDIUM",
                            file_path=file_path,
                            line_number=node.lineno,
                            description="ä½¿ç”¨ == æ¯”è¾ƒ Noneï¼Œåº”ä½¿ç”¨ is",
                            suggestion="ä½¿ç”¨ 'is None' è€Œä¸æ˜¯ '== None'",
                            category="null_handling",
                            timestamp=time.time()
                        )
                        issues.append(issue.__dict__)
        
        return issues
    
    async def _analyze_performance(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½"""
        return await self.performance_analyzer.analyze(context)
    
    async def _analyze_security(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå®‰å…¨æ€§"""
        return await self.security_analyzer.analyze(context)
    
    async def _analyze_complexity(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå¤æ‚åº¦"""
        return await self.complexity_analyzer.analyze(context)
    
    async def _analyze_documentation(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææ–‡æ¡£"""
        return await self.documentation_analyzer.analyze(context)
    
    async def _check_coding_style(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ£€æŸ¥ä»£ç é£æ ¼"""
        check_result = {
            "check_name": "coding_style",
            "passed": True,
            "score": 0.0,
            "issues": [],
            "details": {}
        }
        
        code_content = context.get("code", "") or context.get("content", "")
        
        if not code_content:
            return check_result
        
        issues = []
        lines = code_content.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            # æ£€æŸ¥è¡Œé•¿åº¦
            if len(line) > 120:
                issue = QualityIssue(
                    issue_id=f"long_line_{line_num}",
                    issue_type="LONG_LINE",
                    severity="LOW",
                    file_path=context.get("file_path", "unknown"),
                    line_number=line_num,
                    description=f"è¡Œè¿‡é•¿: {len(line)} å­—ç¬¦",
                    suggestion="å°†é•¿è¡Œæ‹†åˆ†ä¸ºå¤šè¡Œ",
                    category="style",
                    timestamp=time.time()
                )
                issues.append(issue.__dict__)
            
            # æ£€æŸ¥ç¼©è¿›
            if line.startswith(' ') and not line.startswith('    ') and not line.startswith('\t'):
                if not re.match(r'^ {4,8}[^ ]', line):
                    issue = QualityIssue(
                        issue_id=f"incorrect_indentation_{line_num}",
                        issue_type="INCORRECT_INDENTATION",
                        severity="LOW",
                        file_path=context.get("file_path", "unknown"),
                        line_number=line_num,
                        description="ç¼©è¿›ä¸æ­£ç¡®ï¼Œå»ºè®®ä½¿ç”¨4ç©ºæ ¼",
                        suggestion="ç»Ÿä¸€ä½¿ç”¨4ç©ºæ ¼ç¼©è¿›",
                        category="style",
                        timestamp=time.time()
                    )
                    issues.append(issue.__dict__)
            
            # æ£€æŸ¥å¤šä½™çš„ç©ºæ ¼
            if line.endswith(' ') or line.endswith('\t'):
                issue = QualityIssue(
                    issue_id=f"trailing_whitespace_{line_num}",
                    issue_type="TRAILING_WHITESPACE",
                    severity="LOW",
                    file_path=context.get("file_path", "unknown"),
                    line_number=line_num,
                    description="è¡Œå°¾æœ‰å¤šä½™ç©ºæ ¼",
                    suggestion="ç§»é™¤è¡Œå°¾ç©ºæ ¼",
                    category="style",
                    timestamp=time.time()
                )
                issues.append(issue.__dict__)
        
        check_result["issues"] = issues
        
        # è®¡ç®—é£æ ¼åˆ†æ•°
        max_issues = 10
        score = max(0.0, 1.0 - (len(issues) / max_issues))
        check_result["score"] = score
        check_result["passed"] = score >= 0.8
        
        check_result["details"] = {
            "lines_checked": len(lines),
            "style_issues": len(issues)
        }
        
        return check_result
    
    def _calculate_quality_score(self, checks: Dict[str, Dict]) -> float:
        """è®¡ç®—è´¨é‡åˆ†æ•°"""
        if not checks:
            return 0.0
        
        total_score = 0.0
        weight_sum = 0.0
        
        # æƒé‡åˆ†é…
        weights = {
            "code_quality": 0.3,
            "security": 0.25,
            "performance": 0.2,
            "complexity": 0.15,
            "documentation": 0.05,
            "coding_style": 0.05
        }
        
        for check_name, check_result in checks.items():
            score = check_result.get("score", 0.0 if not check_result.get("passed", False) else 1.0)
            weight = weights.get(check_name, 0.1)
            
            total_score += score * weight
            weight_sum += weight
        
        return total_score / weight_sum if weight_sum > 0 else 0.0
    
    def _generate_quality_recommendations(self, issues: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆè´¨é‡å»ºè®®"""
        recommendations = []
        
        if not issues:
            recommendations.append({
                "priority": "LOW",
                "category": "MAINTENANCE",
                "recommendation": "ä»£ç è´¨é‡è‰¯å¥½ï¼Œç»§ç»­ä¿æŒ",
                "action": "å®šæœŸè¿›è¡Œä»£ç å®¡æŸ¥"
            })
            return recommendations
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„
        severity_counts = defaultdict(int)
        category_counts = defaultdict(int)
        
        for issue in issues:
            severity_counts[issue.get("severity", "MEDIUM")] += 1
            category_counts[issue.get("category", "general")] += 1
        
        # ç”Ÿæˆå»ºè®®
        if severity_counts.get("CRITICAL", 0) > 0:
            recommendations.append({
                "priority": "CRITICAL",
                "category": "SECURITY",
                "recommendation": f"å‘ç° {severity_counts['CRITICAL']} ä¸ªä¸¥é‡é—®é¢˜ï¼Œéœ€è¦ç«‹å³ä¿®å¤",
                "action": "ä¼˜å…ˆå¤„ç†ä¸¥é‡å’Œé«˜ä¼˜å…ˆçº§é—®é¢˜"
            })
        
        if severity_counts.get("HIGH", 0) > 5:
            recommendations.append({
                "priority": "HIGH",
                "category": "MAINTENANCE",
                "recommendation": "å‘ç°å¤šä¸ªé«˜ä¼˜å…ˆçº§é—®é¢˜ï¼Œå»ºè®®é‡æ„ä»£ç ",
                "action": "åˆ¶å®šé‡æ„è®¡åˆ’ï¼Œé€æ­¥è§£å†³"
            })
        
        if category_counts.get("imports", 0) > 3:
            recommendations.append({
                "priority": "MEDIUM",
                "category": "IMPORTS",
                "recommendation": "å¯¼å…¥è¯­å¥å­˜åœ¨é—®é¢˜ï¼Œå»ºè®®ä¼˜åŒ–",
                "action": "æ•´ç†å¯¼å…¥è¯­å¥ï¼Œç§»é™¤æœªä½¿ç”¨çš„å¯¼å…¥"
            })
        
        if category_counts.get("functions", 0) > 5:
            recommendations.append({
                "priority": "MEDIUM",
                "category": "DESIGN",
                "recommendation": "å‡½æ•°è®¾è®¡éœ€è¦æ”¹è¿›",
                "action": "é‡æ„é•¿å‡½æ•°ï¼Œå‡å°‘å‚æ•°æ•°é‡"
            })
        
        # é€šç”¨å»ºè®®
        recommendations.extend([
            {
                "priority": "LOW",
                "category": "TOOLS",
                "recommendation": "ä½¿ç”¨é™æ€ä»£ç åˆ†æå·¥å…·",
                "action": "é›†æˆ pylintã€flake8 ç­‰å·¥å…·åˆ°CIæµç¨‹"
            },
            {
                "priority": "LOW",
                "category": "TESTING",
                "recommendation": "å¢åŠ å•å…ƒæµ‹è¯•è¦†ç›–ç‡",
                "action": "ä¸ºç›®æ ‡ä»£ç è¦†ç›–ç‡80%ä»¥ä¸Š"
            }
        ])
        
        return recommendations
    
    def _generate_quality_metrics(self, checks: Dict[str, Dict]) -> Dict[str, Any]:
        """ç”Ÿæˆè´¨é‡æŒ‡æ ‡"""
        metrics = {
            "total_issues": 0,
            "severity_breakdown": defaultdict(int),
            "category_breakdown": defaultdict(int),
            "quality_score": 0.0,
            "compliance_percentage": 0.0
        }
        
        for check_name, check_result in checks.items():
            issues = check_result.get("issues", [])
            metrics["total_issues"] += len(issues)
            
            for issue in issues:
                severity = issue.get("severity", "MEDIUM")
                category = issue.get("category", "general")
                metrics["severity_breakdown"][severity] += 1
                metrics["category_breakdown"][category] += 1
        
        # è®¡ç®—åˆè§„ç‡
        total_checks = len(checks)
        passed_checks = sum(1 for check in checks.values() if check.get("passed", False))
        metrics["compliance_percentage"] = (passed_checks / total_checks * 100) if total_checks > 0 else 0
        
        # è®¡ç®—è´¨é‡åˆ†æ•°
        metrics["quality_score"] = self._calculate_quality_score(checks)
        
        return dict(metrics)

# --- ä»£ç è´¨é‡åˆ†æå™¨ ---
class CodeQualityAnalyzerV6:
    """ä»£ç è´¨é‡åˆ†æå™¨V6"""
    
    def __init__(self):
        self.metrics = {}
    
    async def analyze(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æä»£ç è´¨é‡"""
        return {
            "check_name": "code_quality_analysis",
            "passed": True,
            "score": 0.85,
            "issues": [],
            "details": {
                "maintainability_index": 75,
                "technical_debt": "2 hours",
                "code_smells": 3
            }
        }

# --- æ€§èƒ½åˆ†æå™¨ ---
class PerformanceAnalyzerV6:
    """æ€§èƒ½åˆ†æå™¨V6"""
    
    def __init__(self):
        self.performance_patterns = self._load_patterns()
    
    def _load_patterns(self) -> Dict[str, str]:
        """åŠ è½½æ€§èƒ½æ¨¡å¼"""
        return {
            "inefficient_loops": r"for.*in.*range\(\d{4,}\)",
            "memory_leaks": r"list\.append.*while.*True",
            "slow_algorithms": r"for.*for.*in.*range",
            "sync_operations": r"requests\.get|urllib\.request\.urlopen"
        }
    
    async def analyze(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½"""
        code_content = context.get("code", "") or context.get("content", "")
        
        issues = []
        for pattern_name, pattern in self.performance_patterns.items():
            if re.search(pattern, code_content, re.IGNORECASE):
                issues.append({
                    "issue_type": pattern_name.upper(),
                    "severity": "MEDIUM",
                    "description": f"å‘ç°æ€§èƒ½é—®é¢˜æ¨¡å¼: {pattern_name}",
                    "suggestion": "ä¼˜åŒ–ç®—æ³•æˆ–ä½¿ç”¨å¼‚æ­¥æ“ä½œ"
                })
        
        score = max(0.0, 1.0 - (len(issues) / 10))
        
        return {
            "check_name": "performance_analysis",
            "passed": score >= 0.7,
            "score": score,
            "issues": issues,
            "details": {
                "performance_score": score,
                "bottlenecks_found": len(issues)
            }
        }

# --- å®‰å…¨åˆ†æå™¨ ---
class SecurityAnalyzerV6:
    """å®‰å…¨åˆ†æå™¨V6"""
    
    def __init__(self):
        self.security_patterns = self._load_security_patterns()
    
    def _load_security_patterns(self) -> Dict[str, str]:
        """åŠ è½½å®‰å…¨æ¨¡å¼"""
        return {
            "sql_injection": r"cursor\.execute.*%",
            "xss": r"<script|javascript:",
            "command_injection": r"os\.system|subprocess\.Popen",
            "path_traversal": r"\.\.\/|\.\.\\\\",
            "hardcoded_secrets": r"password\s*=\s*[\"'][^\"']+",
            "insecure_crypto": r"md5\(|sha1\("
        }
    
    async def analyze(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå®‰å…¨æ€§"""
        code_content = context.get("code", "") or context.get("content", "")
        
        issues = []
        for pattern_name, pattern in self.security_patterns.items():
            if re.search(pattern, code_content, re.IGNORECASE):
                severity = "CRITICAL" if pattern_name in ["sql_injection", "command_injection"] else "HIGH"
                issues.append({
                    "issue_type": f"SECURITY_{pattern_name.upper()}",
                    "severity": severity,
                    "description": f"å‘ç°å®‰å…¨æ¼æ´: {pattern_name}",
                    "suggestion": "ä¿®å¤å®‰å…¨æ¼æ´ï¼Œä½¿ç”¨å®‰å…¨çš„æ›¿ä»£æ–¹æ¡ˆ"
                })
        
        score = max(0.0, 1.0 - (len(issues) * 0.2))  # æ¯ä¸ªå®‰å…¨é—®é¢˜æ‰£0.2åˆ†
        
        return {
            "check_name": "security_analysis",
            "passed": len([i for i in issues if i["severity"] == "CRITICAL"]) == 0,
            "score": score,
            "issues": issues,
            "details": {
                "security_score": score,
                "critical_vulnerabilities": len([i for i in issues if i["severity"] == "CRITICAL"])
            }
        }

# --- å¤æ‚åº¦åˆ†æå™¨ ---
class ComplexityAnalyzerV6:
    """å¤æ‚åº¦åˆ†æå™¨V6"""
    
    def __init__(self):
        self.complexity_thresholds = {
            "cyclomatic": 10,
            "nesting": 5,
            "parameters": 7
        }
    
    async def analyze(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå¤æ‚åº¦"""
        code_content = context.get("code", "") or context.get("content", "")
        
        if not code_content:
            return {
                "check_name": "complexity_analysis",
                "passed": True,
                "score": 1.0,
                "issues": [],
                "details": {"complexity_score": 1.0}
            }
        
        try:
            tree = ast.parse(code_content)
            
            # è®¡ç®—åœˆå¤æ‚åº¦
            complexity_score = self._calculate_complexity(tree)
            
            # ç”Ÿæˆé—®é¢˜
            issues = []
            if complexity_score > self.complexity_thresholds["cyclomatic"]:
                issues.append({
                    "issue_type": "HIGH_COMPLEXITY",
                    "severity": "MEDIUM",
                    "description": f"åœˆå¤æ‚åº¦è¿‡é«˜: {complexity_score}",
                    "suggestion": "ç®€åŒ–é€»è¾‘ï¼Œæ‹†åˆ†å¤æ‚å‡½æ•°"
                })
            
            return {
                "check_name": "complexity_analysis",
                "passed": complexity_score <= self.complexity_thresholds["cyclomatic"],
                "score": max(0.0, 1.0 - (complexity_score / 20)),
                "issues": issues,
                "details": {
                    "cyclomatic_complexity": complexity_score,
                    "max_allowed": self.complexity_thresholds["cyclomatic"]
                }
            }
            
        except SyntaxError:
            return {
                "check_name": "complexity_analysis",
                "passed": False,
                "score": 0.0,
                "issues": [],
                "details": {"error": "è¯­æ³•é”™è¯¯"}
            }
    
    def _calculate_complexity(self, tree: ast.Module) -> float:
        """è®¡ç®—åœˆå¤æ‚åº¦"""
        complexity = 1  # åŸºç¡€å¤æ‚åº¦
        
        for node in ast.walk(tree):
            if isinstance(node, (ast.If, ast.While, ast.For, ast.With, ast.Try)):
                complexity += 1
            elif isinstance(node, ast.ExceptHandler):
                complexity += 1
            elif isinstance(node, ast.BoolOp):
                complexity += len(node.values) - 1
        
        return complexity

# --- æ–‡æ¡£åˆ†æå™¨ ---
class DocumentationAnalyzerV6:
    """æ–‡æ¡£åˆ†æå™¨V6"""
    
    def __init__(self):
        self.docstring_patterns = [
            r'"""[^"]+"""',
            r"'''[^']'''"
        ]
    
    async def analyze(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææ–‡æ¡£"""
        code_content = context.get("code", "") or context.get("content", "")
        
        if not code_content:
            return {
                "check_name": "documentation_analysis",
                "passed": True,
                "score": 1.0,
                "issues": [],
                "details": {"documentation_score": 1.0}
            }
        
        try:
            tree = ast.parse(code_content)
            
            # æ£€æŸ¥æ–‡æ¡£å­—ç¬¦ä¸²
            documented_items = 0
            total_items = 0
            
            for node in ast.walk(tree):
                if isinstance(node, (ast.FunctionDef, ast.ClassDef)):
                    total_items += 1
                    if (node.body and 
                        isinstance(node.body[0], ast.Expr) and
                        isinstance(node.body[0].value, (ast.Str, ast.Constant)) and
                        isinstance(node.body[0].value.value, str)):
                        documented_items += 1
            
            documentation_ratio = documented_items / max(1, total_items)
            
            issues = []
            if documentation_ratio < 0.8:
                issues.append({
                    "issue_type": "INSUFFICIENT_DOCUMENTATION",
                    "severity": "MEDIUM",
                    "description": f"æ–‡æ¡£è¦†ç›–ç‡ä¸è¶³: {documentation_ratio:.1%}",
                    "suggestion": "ä¸ºå‡½æ•°å’Œç±»æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²"
                })
            
            return {
                "check_name": "documentation_analysis",
                "passed": documentation_ratio >= 0.7,
                "score": documentation_ratio,
                "issues": issues,
                "details": {
                    "documentation_ratio": documentation_ratio,
                    "documented_items": documented_items,
                    "total_items": total_items
                }
            }
            
        except SyntaxError:
            return {
                "check_name": "documentation_analysis",
                "passed": False,
                "score": 0.0,
                "issues": [],
                "details": {"error": "è¯­æ³•é”™è¯¯"}
            }

# --- æµ‹è¯•å‡½æ•° ---
async def test_quality_hook():
    """æµ‹è¯•è‡ªåŠ¨è´¨é‡æ£€æŸ¥Hook"""
    print("ğŸ§ª æµ‹è¯•è‡ªåŠ¨è´¨é‡æ£€æŸ¥Hook V6")
    print("=" * 50)
    
    hook = AutoQualityCheckHookV6()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "name": "é«˜è´¨é‡ä»£ç ",
            "context": {
                "code": '''
def calculate_fibonacci(n):
    """Calculate the nth Fibonacci number."""
    if n <= 0:
        return 0
    elif n == 1:
        return 1
    else:
        a, b = 0, 1
        for i in range(n):
            a, b = b, a + b
        return a
''',
                "file_path": "fibonacci.py"
            }
        },
        {
            "name": "æœ‰é—®é¢˜çš„ä»£ç ",
            "context": {
                "code": '''
import *
print("debug info")
def long_function_with_many_parameters(param1, param2, param3, param4, param5, param6, param7, param8):
    x = 123456
    if x == None:
        print("found none")
    for i in range(10000):
        pass
''',
                "file_path": "problematic.py"
            }
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ” æµ‹è¯•æ¡ˆä¾‹ {i}: {test_case['name']}")
        
        result = await hook(test_case['context'])
        
        print(f"âœ… æ£€æŸ¥ç»“æœ: {'é€šè¿‡' if result['success'] else 'æœªé€šè¿‡'}")
        print(f"ğŸ“Š è´¨é‡åˆ†æ•°: {result['quality_score']:.2f}")
        print(f"ğŸ“Š é—®é¢˜æ•°é‡: {len(result['issues'])}")
        print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {result['execution_time']:.3f}s")
        
        if result['issues']:
            print("ğŸš¨ å‘ç°é—®é¢˜:")
            for issue in result['issues'][:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                print(f"  - {issue['issue_type']}: {issue['description']}")
        
        if result['recommendations']:
            print("ğŸ’¡ è´¨é‡å»ºè®®:")
            for rec in result['recommendations'][:2]:  # æ˜¾ç¤ºå‰2ä¸ª
                print(f"  - {rec['recommendation']}")
    
    print(f"\nâœ… è‡ªåŠ¨è´¨é‡æ£€æŸ¥Hook V6æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(test_quality_hook())