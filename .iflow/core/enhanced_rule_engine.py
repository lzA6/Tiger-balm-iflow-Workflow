#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ å¢å¼ºè§„åˆ™å¼•æ“ V2 (Enhanced Rule Engine V2)
åœ¨ç°æœ‰ARQè§„åˆ™ç³»ç»ŸåŸºç¡€ä¸Šï¼Œå¢åŠ åŠ¨æ€è§„åˆ™å­¦ä¹ ã€ä¼˜å…ˆçº§è‡ªé€‚åº”ã€å†²çªæ£€æµ‹å’Œé‡å­ä¼˜åŒ–æ”¯æŒã€‚
ä½ ä¸€å®šè¦è¶…çº§æ€è€ƒã€æé™æ€è€ƒã€æ·±åº¦æ€è€ƒï¼Œå…¨åŠ›æ€è€ƒã€è¶…å¼ºæ€è€ƒï¼Œè®¤çœŸä»”ç»†æ€è€ƒï¼ˆultrathinkã€think really super hardã€think intenselyï¼‰ã€‚
"""

import os
import sys
import json
import asyncio
import logging
import hashlib
import re
import numpy as np
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Set, Union, Callable
from dataclasses import dataclass, field, asdict, ast
from datetime import datetime, timedelta
from enum import Enum
from collections import defaultdict, deque
import sqlite3
import threading
import uuid
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

logger = logging.getLogger(__name__)

class RulePriority(Enum):
    """è§„åˆ™ä¼˜å…ˆçº§"""
    CRITICAL = 1    # è‡´å‘½çº§ï¼šå®‰å…¨ã€åˆè§„ç­‰
    HIGH = 2        # é«˜çº§ï¼šæ€§èƒ½ã€è´¨é‡ç­‰
    MEDIUM = 3      # ä¸­çº§ï¼šæ•ˆç‡ã€ç»´æŠ¤æ€§ç­‰
    LOW = 4         # ä½çº§ï¼šé£æ ¼ã€åå¥½ç­‰

class RuleConflictType(Enum):
    """è§„åˆ™å†²çªç±»å‹"""
    CONTRADICTION = "contradiction"      # ç›´æ¥çŸ›ç›¾
    PRIORITY_CONFLICT = "priority_conflict"  # ä¼˜å…ˆçº§å†²çª
    SCOPE_OVERLAP = "scope_overlap"      # ä½œç”¨åŸŸé‡å 
    RESOURCE_COMPETITION = "resource_competition"  # èµ„æºç«äº‰

class RuleStatus(Enum):
    """è§„åˆ™çŠ¶æ€"""
    ACTIVE = "active"
    INACTIVE = "inactive"
    DEPRECATED = "deprecated"
    TESTING = "testing"

@dataclass
class EnhancedRule:
    """å¢å¼ºè§„åˆ™å®šä¹‰"""
    rule_id: str
    rule_name: str
    rule_type: str
    description: str
    priority: RulePriority
    conditions: List[str]
    actions: List[str]
    exceptions: List[str] = field(default_factory=list)
    status: RuleStatus = RuleStatus.ACTIVE
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    # æ–°å¢å±æ€§
    confidence_score: float = 1.0          # è§„åˆ™ç½®ä¿¡åº¦
    usage_count: int = 0                   # ä½¿ç”¨æ¬¡æ•°
    success_rate: float = 1.0              # æˆåŠŸç‡
    last_updated: datetime = field(default_factory=datetime.now)
    conflict_rules: List[str] = field(default_factory=list)  # å†²çªè§„åˆ™IDåˆ—è¡¨
    quantum_optimization: Dict[str, Any] = field(default_factory=dict)  # é‡å­ä¼˜åŒ–é…ç½®
    adaptive_thresholds: Dict[str, float] = field(default_factory=dict)  # è‡ªé€‚åº”é˜ˆå€¼

@dataclass
class RuleConflict:
    """è§„åˆ™å†²çªå®šä¹‰"""
    conflict_id: str
    conflict_type: RuleConflictType
    rule_a: str
    rule_b: str
    context: Dict[str, Any]
    severity: float
    resolution_strategy: str
    resolved: bool = False
    created_at: datetime = field(default_factory=datetime.now)

@dataclass
class RuleEvaluation:
    """è§„åˆ™è¯„ä¼°ç»“æœ"""
    rule_id: str
    matched: bool
    confidence: float
    context_match: Dict[str, Any]
    suggested_actions: List[str]
    quantum_recommendations: List[Dict[str, Any]] = field(default_factory=list)

class EnhancedRuleEngine:
    """
    å¢å¼ºè§„åˆ™å¼•æ“ - åœ¨ç°æœ‰ARQè§„åˆ™ç³»ç»ŸåŸºç¡€ä¸Šçš„é‡å¤§å‡çº§
    """
    
    def __init__(self, db_path: str = "Aé¡¹ç›®/iflow/data/enhanced_rules.db"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        
        # æ•°æ®åº“è¿æ¥
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self.lock = threading.RLock()
        
        # è§„åˆ™å­˜å‚¨
        self.rules: Dict[str, EnhancedRule] = {}
        self.rule_index: Dict[str, List[str]] = defaultdict(list)  # ç±»å‹ç´¢å¼•
        self.priority_queue: List[Tuple[int, str]] = []  # ä¼˜å…ˆçº§é˜Ÿåˆ—
        
        # å†²çªæ£€æµ‹
        self.conflicts: Dict[str, RuleConflict] = {}
        self.conflict_graph = {}  # å†²çªå›¾
        
        # è‡ªé€‚åº”å­¦ä¹ 
        self.performance_history: deque = deque(maxlen=1000)
        self.adaptive_weights: Dict[str, float] = {}
        
        # é‡å­ä¼˜åŒ–
        self.quantum_optimizer = None
        
        # åˆå§‹åŒ–
        self._init_db()
        self._load_default_rules()
        self._initialize_quantum_optimizer()
        
        logger.info("å¢å¼ºè§„åˆ™å¼•æ“V2åˆå§‹åŒ–å®Œæˆ")
    
    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        with self.conn:
            # è§„åˆ™è¡¨
            self.conn.execute("""
                CREATE TABLE IF NOT EXISTS enhanced_rules (
                    rule_id TEXT PRIMARY KEY,
                    rule_name TEXT,
                    rule_type TEXT,
                    description TEXT,
                    priority INTEGER,
                    conditions_json TEXT,
                    actions_json TEXT,
                    exceptions_json TEXT,
                    status TEXT,
                    confidence_score REAL,
                    usage_count INTEGER,
                    success_rate REAL,
                    last_updated REAL,
                    metadata_json TEXT,
                    quantum_optimization_json TEXT,
                    adaptive_thresholds_json TEXT
                )
            """)
            
            # å†²çªè¡¨
            self.conn.execute("""
                CREATE TABLE IF NOT EXISTS rule_conflicts (
                    conflict_id TEXT PRIMARY KEY,
                    conflict_type TEXT,
                    rule_a TEXT,
                    rule_b TEXT,
                    context_json TEXT,
                    severity REAL,
                    resolution_strategy TEXT,
                    resolved BOOLEAN,
                    created_at REAL
                )
            """)
            
            # æ€§èƒ½å†å²è¡¨
            self.conn.execute("""
                CREATE TABLE IF NOT EXISTS performance_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    rule_id TEXT,
                    evaluation_time REAL,
                    success BOOLEAN,
                    context_complexity REAL,
                    execution_time REAL,
                    FOREIGN KEY (rule_id) REFERENCES enhanced_rules (rule_id)
                )
            """)
    
    def _load_default_rules(self):
        """åŠ è½½å¢å¼ºçš„é»˜è®¤è§„åˆ™"""
        default_rules = [
            EnhancedRule(
                rule_id="ENHANCED_001",
                rule_name="é‡å­å®‰å…¨é˜²æŠ¤",
                rule_type="security",
                description="é›†æˆé‡å­åŠ å¯†å’Œä¼ ç»Ÿå®‰å…¨æ£€æŸ¥çš„åŒé‡é˜²æŠ¤æœºåˆ¶",
                priority=RulePriority.CRITICAL,
                conditions=["*"],
                actions=["é‡å­å¯†é’¥åˆ†å‘", "ä¼ ç»ŸåŠ å¯†éªŒè¯", "æ¼æ´æ‰«æ"],
                metadata={
                    "quantum_compatible": True,
                    "zero_trust": True,
                    "real_time_monitoring": True
                },
                quantum_optimization={
                    "algorithm": "quantum_key_distribution",
                    "entanglement_threshold": 0.9,
                    "security_level": "quantum_safe"
                },
                adaptive_thresholds={
                    "false_positive_rate": 0.01,
                    "detection_latency": 100  # ms
                }
            ),
            EnhancedRule(
                rule_id="ENHANCED_002",
                rule_name="è‡ªé€‚åº”æ€§èƒ½ä¼˜åŒ–",
                rule_type="performance",
                description="åŸºäºå®æ—¶è´Ÿè½½å’Œå†å²æ•°æ®çš„åŠ¨æ€æ€§èƒ½è°ƒä¼˜",
                priority=RulePriority.HIGH,
                conditions=["performance_critical", "resource_constrained"],
                actions=["è´Ÿè½½å‡è¡¡", "ç¼“å­˜ä¼˜åŒ–", "ç®—æ³•é€‰æ‹©"],
                metadata={
                    "adaptive": True,
                    "real_time": True,
                    "predictive": True
                },
                quantum_optimization={
                    "algorithm": "quantum_annealing",
                    "optimization_target": "execution_time",
                    "improvement_threshold": 0.3
                },
                adaptive_thresholds={
                    "cpu_usage_threshold": 0.8,
                    "memory_usage_threshold": 0.7,
                    "response_time_threshold": 2000  # ms
                }
            ),
            EnhancedRule(
                rule_id="ENHANCED_003",
                rule_name="æ™ºèƒ½å†²çªè§£å†³",
                rule_type="conflict_resolution",
                description="è‡ªåŠ¨æ£€æµ‹å’Œè§£å†³è§„åˆ™é—´çš„å†²çªï¼Œæä¾›æœ€ä¼˜è§£å†³æ–¹æ¡ˆ",
                priority=RulePriority.MEDIUM,
                conditions=["rule_conflict"],
                actions=["å†²çªåˆ†æ", "ä¼˜å…ˆçº§è°ƒæ•´", "è§„åˆ™åˆå¹¶"],
                metadata={
                    "conflict_detection": True,
                    "auto_resolution": True,
                    "human_intervention_threshold": 0.8
                },
                adaptive_thresholds={
                    "conflict_tolerance": 0.1,
                    "resolution_confidence": 0.9
                }
            ),
            EnhancedRule(
                rule_id="ENHANCED_004",
                rule_name="æŒç»­å­¦ä¹ ä¸è¿›åŒ–",
                rule_type="learning",
                description="åŸºäºæ‰§è¡Œç»“æœæŒç»­ä¼˜åŒ–è§„åˆ™å‚æ•°å’Œé€»è¾‘",
                priority=RulePriority.MEDIUM,
                conditions=["evaluation_completed"],
                actions=["æ€§èƒ½åˆ†æ", "å‚æ•°è°ƒæ•´", "è§„åˆ™è¿›åŒ–"],
                metadata={
                    "machine_learning": True,
                    "feedback_loop": True,
                    "evolutionary_algorithm": True
                },
                adaptive_thresholds={
                    "learning_rate": 0.1,
                    "improvement_threshold": 0.05,
                    "stability_threshold": 0.95
                }
            ),
            EnhancedRule(
                rule_id="ENHANCED_005",
                rule_name="é¢„æµ‹æ€§ç»´æŠ¤",
                rule_type="maintenance",
                description="é¢„æµ‹æ½œåœ¨é—®é¢˜å¹¶æå‰è¿›è¡Œé¢„é˜²æ€§ç»´æŠ¤",
                priority=RulePriority.LOW,
                conditions=["maintenance_window", "predictive_trigger"],
                actions=["å¥åº·æ£€æŸ¥", "èµ„æºæ¸…ç†", "æ€§èƒ½è°ƒä¼˜"],
                metadata={
                    "predictive": True,
                    "proactive": True,
                    "automated_maintenance": True
                },
                quantum_optimization={
                    "algorithm": "quantum_machine_learning",
                    "prediction_accuracy": 0.9,
                    "maintenance_optimization": True
                },
                adaptive_thresholds={
                    "prediction_confidence": 0.8,
                    "maintenance_window_size": 3600  # seconds
                }
            )
        ]
        
        for rule in default_rules:
            self.add_rule(rule)
    
    def _initialize_quantum_optimizer(self):
        """åˆå§‹åŒ–é‡å­ä¼˜åŒ–å™¨"""
        try:
            from iflow.tools.external.utils.quantum_optimizer import QuantumOptimizer
            self.quantum_optimizer = QuantumOptimizer()
            logger.info("é‡å­ä¼˜åŒ–å™¨åˆå§‹åŒ–æˆåŠŸ")
        except ImportError:
            logger.warning("é‡å­ä¼˜åŒ–å™¨æ¨¡å—æœªæ‰¾åˆ°ï¼Œä½¿ç”¨ç»å…¸ä¼˜åŒ–")
            self.quantum_optimizer = None
    
    def add_rule(self, rule: EnhancedRule) -> bool:
        """æ·»åŠ æ–°è§„åˆ™"""
        with self.lock:
            try:
                # æ£€æŸ¥å†²çª
                conflicts = self._detect_rule_conflicts(rule)
                if conflicts:
                    logger.warning(f"æ£€æµ‹åˆ°è§„åˆ™å†²çª: {len(conflicts)} ä¸ª")
                    self._resolve_conflicts(conflicts)
                
                # æ·»åŠ åˆ°å†…å­˜
                self.rules[rule.rule_id] = rule
                self.rule_index[rule.rule_type].append(rule.rule_id)
                
                # æ›´æ–°ä¼˜å…ˆçº§é˜Ÿåˆ—
                self.priority_queue.append((rule.priority.value, rule.rule_id))
                self.priority_queue.sort(key=lambda x: x[0])
                
                # æŒä¹…åŒ–
                self._persist_rule(rule)
                
                logger.info(f"æˆåŠŸæ·»åŠ è§„åˆ™: {rule.rule_id} ({rule.rule_name})")
                return True
                
            except Exception as e:
                logger.error(f"æ·»åŠ è§„åˆ™å¤±è´¥: {e}")
                return False
    
    def _detect_rule_conflicts(self, new_rule: EnhancedRule) -> List[RuleConflict]:
        """æ£€æµ‹æ–°è§„åˆ™ä¸ç°æœ‰è§„åˆ™çš„å†²çª"""
        conflicts = []
        
        for existing_rule in self.rules.values():
            if existing_rule.rule_id == new_rule.rule_id:
                continue
            
            # æ£€æŸ¥æ¡ä»¶é‡å 
            if self._check_condition_overlap(new_rule, existing_rule):
                conflict = RuleConflict(
                    conflict_id=str(uuid.uuid4()),
                    conflict_type=RuleConflictType.SCOPE_OVERLAP,
                    rule_a=new_rule.rule_id,
                    rule_b=existing_rule.rule_id,
                    context={
                        "overlapping_conditions": self._find_overlapping_conditions(new_rule, existing_rule)
                    },
                    severity=self._calculate_conflict_severity(new_rule, existing_rule)
                )
                conflicts.append(conflict)
        
        return conflicts
    
    def _check_condition_overlap(self, rule_a: EnhancedRule, rule_b: EnhancedRule) -> bool:
        """æ£€æŸ¥ä¸¤ä¸ªè§„åˆ™çš„æ¡ä»¶æ˜¯å¦é‡å """
        # ç®€åŒ–å®ç°ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å…±åŒçš„æ¡ä»¶æ¨¡å¼
        for cond_a in rule_a.conditions:
            for cond_b in rule_b.conditions:
                if cond_a == "*" or cond_b == "*" or cond_a == cond_b:
                    return True
        return False
    
    def _find_overlapping_conditions(self, rule_a: EnhancedRule, rule_b: EnhancedRule) -> List[str]:
        """æ‰¾åˆ°é‡å çš„æ¡ä»¶"""
        overlaps = []
        for cond_a in rule_a.conditions:
            for cond_b in rule_b.conditions:
                if cond_a == "*" or cond_b == "*" or cond_a == cond_b:
                    overlaps.append(f"{cond_a} <-> {cond_b}")
        return overlaps
    
    def _calculate_conflict_severity(self, rule_a: EnhancedRule, rule_b: EnhancedRule) -> float:
        """è®¡ç®—å†²çªä¸¥é‡ç¨‹åº¦"""
        # åŸºäºä¼˜å…ˆçº§å·®å¼‚å’Œè§„åˆ™ç±»å‹
        priority_diff = abs(rule_a.priority.value - rule_b.priority.value)
        base_severity = priority_diff / 4.0  # å½’ä¸€åŒ–åˆ°0-1
        
        # å¦‚æœæ¶‰åŠå®‰å…¨è§„åˆ™ï¼Œä¸¥é‡æ€§æ›´é«˜
        if "security" in [rule_a.rule_type, rule_b.rule_type]:
            base_severity *= 1.5
        
        return min(base_severity, 1.0)
    
    def _resolve_conflicts(self, conflicts: List[RuleConflict]):
        """è‡ªåŠ¨è§£æå†²çª"""
        for conflict in conflicts:
            if conflict.conflict_type == RuleConflictType.SCOPE_OVERLAP:
                # ä¼˜å…ˆçº§é«˜çš„è§„åˆ™ä¼˜å…ˆ
                rule_a = self.rules[conflict.rule_a]
                rule_b = self.rules[conflict.rule_b]
                
                if rule_a.priority.value < rule_b.priority.value:  # æ•°å€¼è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜
                    conflict.resolution_strategy = f"ä¼˜å…ˆæ‰§è¡Œ {rule_a.rule_id}"
                    rule_b.conflict_rules.append(rule_a.rule_id)
                else:
                    conflict.resolution_strategy = f"ä¼˜å…ˆæ‰§è¡Œ {rule_b.rule_id}"
                    rule_a.conflict_rules.append(rule_b.rule_id)
            
            conflict.resolved = True
            self.conflicts[conflict.conflict_id] = conflict
            
            # æŒä¹…åŒ–å†²çªè®°å½•
            self._persist_conflict(conflict)
    
    def evaluate_rules(self, context: Dict[str, Any], task_description: str) -> List[RuleEvaluation]:
        """è¯„ä¼°é€‚ç”¨çš„è§„åˆ™"""
        with self.lock:
            evaluations = []
            
            for rule in self.rules.values():
                if rule.status != RuleStatus.ACTIVE:
                    continue
                
                evaluation = self._evaluate_single_rule(rule, context, task_description)
                if evaluation.matched:
                    evaluations.append(evaluation)
            
            # æŒ‰ç½®ä¿¡åº¦å’Œä¼˜å…ˆçº§æ’åº
            evaluations.sort(key=lambda x: (-x.confidence, self.rules[x.rule_id].priority.value))
            
            # è®°å½•æ€§èƒ½å†å²
            asyncio.create_task(self._record_performance(evaluations, context))
            
            return evaluations
    
    def _evaluate_single_rule(self, rule: EnhancedRule, context: Dict[str, Any], task_description: str) -> RuleEvaluation:
        """è¯„ä¼°å•ä¸ªè§„åˆ™"""
        # æ¡ä»¶åŒ¹é…
        confidence = self._calculate_match_confidence(rule, context, task_description)
        
        # ä¸Šä¸‹æ–‡åŒ¹é…
        context_match = self._extract_context_match(rule, context)
        
        # å»ºè®®åŠ¨ä½œ
        suggested_actions = self._generate_suggested_actions(rule, context_match)
        
        # é‡å­å»ºè®®
        quantum_recommendations = self._get_quantum_recommendations(rule, context)
        
        return RuleEvaluation(
            rule_id=rule.rule_id,
            matched=confidence > 0.5,
            confidence=confidence,
            context_match=context_match,
            suggested_actions=suggested_actions,
            quantum_recommendations=quantum_recommendations
        )
    
    def _calculate_match_confidence(self, rule: EnhancedRule, context: Dict[str, Any], task_description: str) -> float:
        """è®¡ç®—è§„åˆ™åŒ¹é…ç½®ä¿¡åº¦"""
        base_confidence = 0.5
        
        # æ¡ä»¶åŒ¹é…åº¦
        condition_matches = 0
        for condition in rule.conditions:
            if condition == "*":
                condition_matches += 1
            elif condition in task_description.lower():
                condition_matches += 1
            elif any(condition in str(value).lower() for value in context.values()):
                condition_matches += 1
        
        condition_confidence = condition_matches / len(rule.conditions)
        
        # å†å²æˆåŠŸç‡å½±å“
        historical_confidence = rule.success_rate
        
        # è‡ªé€‚åº”æƒé‡
        adaptive_weight = self.adaptive_weights.get(rule.rule_id, 1.0)
        
        # ç»¼åˆç½®ä¿¡åº¦
        final_confidence = (base_confidence + condition_confidence + historical_confidence) / 3 * adaptive_weight
        
        return min(max(final_confidence, 0.0), 1.0)
    
    def _extract_context_match(self, rule: EnhancedRule, context: Dict[str, Any]) -> Dict[str, Any]:
        """æå–ä¸Šä¸‹æ–‡åŒ¹é…ä¿¡æ¯"""
        match_info = {}
        
        for key, value in context.items():
            if any(key.lower() in str(condition).lower() for condition in rule.conditions):
                match_info[key] = value
        
        return match_info
    
    def _generate_suggested_actions(self, rule: EnhancedRule, context_match: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆå»ºè®®åŠ¨ä½œ"""
        suggested_actions = list(rule.actions)
        
        # åŸºäºä¸Šä¸‹æ–‡è°ƒæ•´åŠ¨ä½œ
        if "performance_critical" in context_match:
            if "ç¼“å­˜ä¼˜åŒ–" not in suggested_actions:
                suggested_actions.append("ç´§æ€¥ç¼“å­˜ä¼˜åŒ–")
        
        return suggested_actions
    
    def _get_quantum_recommendations(self, rule: EnhancedRule, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """è·å–é‡å­ä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        if rule.quantum_optimization and self.quantum_optimizer:
            quantum_config = rule.quantum_optimization
            
            # æ¨¡æ‹Ÿé‡å­ä¼˜åŒ–å»ºè®®
            recommendation = {
                "algorithm": quantum_config.get("algorithm", "quantum_annealing"),
                "optimization_target": quantum_config.get("optimization_target", "execution_time"),
                "expected_improvement": quantum_config.get("improvement_threshold", 0.3),
                "confidence": np.random.random() * 0.3 + 0.7,  # æ¨¡æ‹Ÿé‡å­ç½®ä¿¡åº¦
                "resource_requirements": {
                    "qubits": 50,
                    "coherence_time": "100ns",
                    "error_rate": "0.01"
                }
            }
            
            recommendations.append(recommendation)
        
        return recommendations
    
    async def _record_performance(self, evaluations: List[RuleEvaluation], context: Dict[str, Any]):
        """è®°å½•æ€§èƒ½å†å²"""
        timestamp = time.time()
        
        for evaluation in evaluations:
            rule = self.rules[evaluation.rule_id]
            
            # æ›´æ–°è§„åˆ™ç»Ÿè®¡
            rule.usage_count += 1
            
            # è®¡ç®—å¤æ‚åº¦
            context_complexity = len(context) * 0.1 + len(str(context)) / 1000.0
            
            # æ¨¡æ‹Ÿæ‰§è¡Œæ—¶é—´
            execution_time = np.random.exponential(100)  # ms
            
            # è®°å½•åˆ°æ•°æ®åº“
            with self.conn:
                self.conn.execute("""
                    INSERT INTO performance_history 
                    (rule_id, evaluation_time, success, context_complexity, execution_time)
                    VALUES (?, ?, ?, ?, ?)
                """, (rule.rule_id, timestamp, evaluation.matched, context_complexity, execution_time))
            
            # æ›´æ–°æˆåŠŸç‡ï¼ˆç®€åŒ–å®ç°ï¼‰
            if rule.usage_count > 10:  # æœ‰è¶³å¤Ÿçš„æ•°æ®åæ‰æ›´æ–°
                avg_success = self._calculate_rule_success_rate(rule.rule_id)
                rule.success_rate = avg_success
        
        # æ›´æ–°è‡ªé€‚åº”æƒé‡
        await self._update_adaptive_weights()
    
    def _calculate_rule_success_rate(self, rule_id: str) -> float:
        """è®¡ç®—è§„åˆ™æˆåŠŸç‡"""
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT AVG(success) FROM performance_history 
            WHERE rule_id = ? AND evaluation_time > ?
        """, (rule_id, time.time() - 86400))  # æœ€è¿‘24å°æ—¶
        
        result = cursor.fetchone()
        return result[0] if result[0] is not None else 1.0
    
    async def _update_adaptive_weights(self):
        """æ›´æ–°è‡ªé€‚åº”æƒé‡"""
        for rule_id, rule in self.rules.items():
            if rule.usage_count > 5:
                # åŸºäºæˆåŠŸç‡å’Œç½®ä¿¡åº¦è°ƒæ•´æƒé‡
                weight = (rule.success_rate * 0.7 + rule.confidence_score * 0.3)
                self.adaptive_weights[rule_id] = max(0.5, min(2.0, weight))
    
    def _persist_rule(self, rule: EnhancedRule):
        """æŒä¹…åŒ–è§„åˆ™"""
        try:
            with self.conn:
                self.conn.execute("""
                    INSERT OR REPLACE INTO enhanced_rules 
                    (rule_id, rule_name, rule_type, description, priority, conditions_json, 
                     actions_json, exceptions_json, status, confidence_score, usage_count, 
                     success_rate, last_updated, metadata_json, quantum_optimization_json, 
                     adaptive_thresholds_json)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    rule.rule_id, rule.rule_name, rule.rule_type, rule.description,
                    rule.priority.value, json.dumps(rule.conditions), json.dumps(rule.actions),
                    json.dumps(rule.exceptions), rule.status.value, rule.confidence_score,
                    rule.usage_count, rule.success_rate, rule.last_updated.timestamp(),
                    json.dumps(rule.metadata), json.dumps(rule.quantum_optimization),
                    json.dumps(rule.adaptive_thresholds)
                ))
        except Exception as e:
            logger.error(f"æŒä¹…åŒ–è§„åˆ™å¤±è´¥: {e}")
    
    def _persist_conflict(self, conflict: RuleConflict):
        """æŒä¹…åŒ–å†²çªè®°å½•"""
        try:
            with self.conn:
                self.conn.execute("""
                    INSERT OR REPLACE INTO rule_conflicts
                    (conflict_id, conflict_type, rule_a, rule_b, context_json, 
                     severity, resolution_strategy, resolved, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    conflict.conflict_id, conflict.conflict_type.value, conflict.rule_a,
                    conflict.rule_b, json.dumps(conflict.context), conflict.severity,
                    conflict.resolution_strategy, conflict.resolved, conflict.created_at.timestamp()
                ))
        except Exception as e:
            logger.error(f"æŒä¹…åŒ–å†²çªå¤±è´¥: {e}")
    
    def get_rule_statistics(self) -> Dict[str, Any]:
        """è·å–è§„åˆ™ç»Ÿè®¡ä¿¡æ¯"""
        with self.lock:
            total_rules = len(self.rules)
            active_rules = sum(1 for rule in self.rules.values() if rule.status == RuleStatus.ACTIVE)
            conflict_count = len(self.conflicts)
            
            # è®¡ç®—å¹³å‡æˆåŠŸç‡
            total_success = sum(rule.success_rate for rule in self.rules.values())
            avg_success_rate = total_success / total_rules if total_rules > 0 else 0
            
            return {
                "total_rules": total_rules,
                "active_rules": active_rules,
                "conflict_count": conflict_count,
                "average_success_rate": avg_success_rate,
                "quantum_enabled_rules": sum(1 for rule in self.rules.values() if rule.quantum_optimization),
                "adaptive_rules": sum(1 for rule in self.rules.values() if rule.adaptive_thresholds)
            }
    
    def close(self):
        """å…³é—­è§„åˆ™å¼•æ“"""
        self.conn.close()
        logger.info("å¢å¼ºè§„åˆ™å¼•æ“å·²å…³é—­")

async def main():
    """æµ‹è¯•å¢å¼ºè§„åˆ™å¼•æ“"""
    logger.info("ğŸš€ æµ‹è¯•å¢å¼ºè§„åˆ™å¼•æ“ V2...")
    
    engine = EnhancedRuleEngine()
    
    # æµ‹è¯•è§„åˆ™è¯„ä¼°
    test_context = {
        "task_type": "performance_optimization",
        "resource_usage": "high",
        "security_level": "critical"
    }
    
    test_task = "ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½ï¼ŒåŒæ—¶ç¡®ä¿æ•°æ®å®‰å…¨"
    
    print("\n" + "="*60)
    print("ğŸ” è§„åˆ™è¯„ä¼°æµ‹è¯•:")
    evaluations = engine.evaluate_rules(test_context, test_task)
    
    for eval in evaluations[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
        rule = engine.rules[eval.rule_id]
        print(f"  - {rule.rule_name} (ç½®ä¿¡åº¦: {eval.confidence:.2f})")
        print(f"    å»ºè®®åŠ¨ä½œ: {eval.suggested_actions}")
        if eval.quantum_recommendations:
            print(f"    é‡å­å»ºè®®: {eval.quantum_recommendations[0]['algorithm']}")
    
    print("\n" + "="*60)
    print("ğŸ“Š è§„åˆ™ç»Ÿè®¡:")
    stats = engine.get_rule_statistics()
    for key, value in stats.items():
        print(f"  - {key}: {value}")
    
    engine.close()

if __name__ == "__main__":
    asyncio.run(main())