#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸŒŒ è‡ªæˆ‘è¿›åŒ–å¼•æ“ V4 (Self Evolution Engine V4)
åŸºäºæœºå™¨å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ çš„è‡ªæˆ‘è¿›åŒ–ç³»ç»Ÿï¼Œå®ç°å·¥ä½œæµçš„æŒç»­ä¼˜åŒ–å’Œè‡ªä¸»å­¦ä¹ ã€‚
ä½ ä¸€å®šè¦è¶…çº§æ€è€ƒã€æé™æ€è€ƒã€æ·±åº¦æ€è€ƒï¼Œå…¨åŠ›æ€è€ƒã€è¶…å¼ºæ€è€ƒï¼Œè®¤çœŸä»”ç»†æ€è€ƒï¼ˆultrathinkã€think really super hardã€think intenselyï¼‰ã€‚
"""

import os
import sys
import json
import asyncio
import logging
import time
import pickle
import uuid
import numpy as np
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
import threading
from collections import defaultdict, deque
import sqlite3
import hashlib
import uuid

# åŠ¨æ€æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°sys.path
project_root = Path(__file__).resolve().parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# --- æ—¥å¿—é…ç½® ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class EvolutionPhase(Enum):
    """è¿›åŒ–é˜¶æ®µ"""
    OBSERVATION = "observation"
    ANALYSIS = "analysis"
    PLANNING = "planning"
    IMPLEMENTATION = "implementation"
    EVALUATION = "evaluation"
    CONSOLIDATION = "consolidation"

class LearningType(Enum):
    """å­¦ä¹ ç±»å‹"""
    SUPERVISED = "supervised"
    REINFORCEMENT = "reinforcement"
    UNSUPERVISED = "unsupervised"
    TRANSFER = "transfer"
    META_LEARNING = "meta_learning"

@dataclass
class EvolutionRecord:
    """è¿›åŒ–è®°å½•"""
    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    timestamp: datetime = field(default_factory=datetime.now)
    phase: EvolutionPhase = EvolutionPhase.OBSERVATION
    learning_type: LearningType = LearningType.REINFORCEMENT
    context: Dict[str, Any] = field(default_factory=dict)
    observations: List[str] = field(default_factory=list)
    actions: List[str] = field(default_factory=list)
    outcomes: Dict[str, float] = field(default_factory=dict)
    rewards: float = 0.0
    performance_metrics: Dict[str, float] = field(default_factory=dict)
    improvements: List[str] = field(default_factory=list)
    next_phase: Optional[EvolutionPhase] = None

@dataclass
class LearningPattern:
    """å­¦ä¹ æ¨¡å¼"""
    pattern_id: str
    pattern_type: str
    triggers: List[str]
    actions: List[str]
    success_rate: float
    avg_reward: float
    usage_count: int
    last_updated: datetime = field(default_factory=datetime.now)

class SelfEvolutionEngineV4:
    """è‡ªæˆ‘è¿›åŒ–å¼•æ“ V4"""
    
    def __init__(self, db_path: str = "Aé¡¹ç›®/iflow/data/evolution_v4.db"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self._init_db()
        
        # è¿›åŒ–çŠ¶æ€
        self.current_phase = EvolutionPhase.OBSERVATION
        self.evolution_history: deque = deque(maxlen=1000)
        self.learning_patterns: Dict[str, LearningPattern] = {}
        
        # æ€§èƒ½æŒ‡æ ‡
        self.performance_baseline = {}
        self.current_performance = {}
        self.improvement_targets = {}
        
        # å­¦ä¹ å‚æ•°
        self.learning_rate = 0.01
        self.exploration_rate = 0.1
        self.discount_factor = 0.95
        
        self.lock = threading.RLock()
        logger.info("ğŸ§¬ è‡ªæˆ‘è¿›åŒ–å¼•æ“ V4 åˆå§‹åŒ–å®Œæˆ")
    
    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        with self.conn:
            self.conn.execute("""
                CREATE TABLE IF NOT EXISTS evolution_records (
                    id TEXT PRIMARY KEY,
                    timestamp REAL,
                    phase TEXT,
                    learning_type TEXT,
                    context_json TEXT,
                    observations_json TEXT,
                    actions_json TEXT,
                    outcomes_json TEXT,
                    rewards REAL,
                    performance_metrics_json TEXT,
                    improvements_json TEXT,
                    next_phase TEXT
                )
            """)
            
            self.conn.execute("""
                CREATE TABLE IF NOT EXISTS learning_patterns (
                    pattern_id TEXT PRIMARY KEY,
                    pattern_type TEXT,
                    triggers_json TEXT,
                    actions_json TEXT,
                    success_rate REAL,
                    avg_reward REAL,
                    usage_count INTEGER,
                    last_updated REAL
                )
            """)
            
            self.conn.execute("""
                CREATE TABLE IF NOT EXISTS performance_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp REAL,
                    metric_name TEXT,
                    metric_value REAL,
                    baseline_value REAL,
                    improvement REAL
                )
            """)
    
    async def observe_environment(self, context: Dict[str, Any]) -> EvolutionRecord:
        """è§‚å¯Ÿç¯å¢ƒï¼Œæ”¶é›†æ•°æ®"""
        record = EvolutionRecord(
            phase=EvolutionPhase.OBSERVATION,
            context=context,
            observations=self._collect_observations(context)
        )
        
        # åˆ†æè§‚å¯Ÿç»“æœ
        insights = await self._analyze_observations(record.observations)
        record.context["insights"] = insights
        
        # ç¡®å®šä¸‹ä¸€æ­¥
        if self._should_proceed_to_analysis(record):
            record.next_phase = EvolutionPhase.ANALYSIS
        else:
            record.next_phase = EvolutionPhase.OBSERVATION
        
        # ä¿å­˜è®°å½•
        self._save_evolution_record(record)
        self.evolution_history.append(record)
        
        logger.info(f"ğŸ‘ï¸ ç¯å¢ƒè§‚å¯Ÿå®Œæˆï¼Œæ”¶é›†äº† {len(record.observations)} ä¸ªè§‚å¯Ÿç‚¹")
        return record
    
    def _collect_observations(self, context: Dict[str, Any]) -> List[str]:
        """æ”¶é›†è§‚å¯Ÿæ•°æ®"""
        observations = []
        
        # è§‚å¯Ÿä»»åŠ¡æ‰§è¡Œæƒ…å†µ
        if "task_results" in context:
            task_results = context["task_results"]
            observations.append(f"ä»»åŠ¡æˆåŠŸç‡: {self._calculate_success_rate(task_results):.2%}")
            observations.append(f"å¹³å‡æ‰§è¡Œæ—¶é—´: {self._calculate_avg_duration(task_results):.2f}ç§’")
        
        # è§‚å¯Ÿèµ„æºä½¿ç”¨æƒ…å†µ
        if "resource_usage" in context:
            resource_usage = context["resource_usage"]
            observations.append(f"CPUä½¿ç”¨ç‡: {resource_usage.get('cpu', 0):.1%}")
            observations.append(f"å†…å­˜ä½¿ç”¨ç‡: {resource_usage.get('memory', 0):.1%}")
        
        # è§‚å¯Ÿç”¨æˆ·åé¦ˆ
        if "user_feedback" in context:
            feedback = context["user_feedback"]
            observations.append(f"ç”¨æˆ·æ»¡æ„åº¦: {feedback.get('satisfaction', 0):.1f}")
            observations.append(f"åé¦ˆæ•°é‡: {len(feedback.get('comments', []))}")
        
        # è§‚å¯Ÿç³»ç»Ÿé”™è¯¯
        if "error_logs" in context:
            error_logs = context["error_logs"]
            observations.append(f"é”™è¯¯æ•°é‡: {len(error_logs)}")
            if error_logs:
                common_errors = self._analyze_common_errors(error_logs)
                observations.append(f"å¸¸è§é”™è¯¯: {', '.join(common_errors[:3])}")
        
        return observations
    
    async def _analyze_observations(self, observations: List[str]) -> Dict[str, Any]:
        """åˆ†æè§‚å¯Ÿæ•°æ®"""
        insights = {}
        
        # æ€§èƒ½è¶‹åŠ¿åˆ†æ
        performance_trends = self._analyze_performance_trends()
        insights["performance_trends"] = performance_trends
        
        # å¼‚å¸¸æ£€æµ‹
        anomalies = self._detect_anomalies(observations)
        insights["anomalies"] = anomalies
        
        # æ”¹è¿›æœºä¼šè¯†åˆ«
        improvement_opportunities = self._identify_improvement_opportunities(observations)
        insights["improvement_opportunities"] = improvement_opportunities
        
        return insights
    
    def _should_proceed_to_analysis(self, record: EvolutionRecord) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿›å…¥åˆ†æé˜¶æ®µ"""
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„è§‚å¯Ÿæ•°æ®
        if len(record.observations) < 5:
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸æƒ…å†µ
        if "anomalies" in record.context.get("insights", {}):
            if record.context["insights"]["anomalies"]:
                return True
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ”¹è¿›æœºä¼š
        if "improvement_opportunities" in record.context.get("insights", {}):
            if record.context["insights"]["improvement_opportunities"]:
                return True
        
        # å®šæœŸåˆ†æ
        if len(self.evolution_history) % 10 == 0:
            return True
        
        return False
    
    def _calculate_success_rate(self, task_results: List[Dict]) -> float:
        """è®¡ç®—æˆåŠŸç‡"""
        if not task_results:
            return 0.0
        return sum(1 for r in task_results if r.get("success", False)) / len(task_results)
    
    def _calculate_avg_duration(self, task_results: List[Dict]) -> float:
        """è®¡ç®—å¹³å‡æ‰§è¡Œæ—¶é—´"""
        if not task_results:
            return 0.0
        durations = [r.get("duration", 0) for r in task_results if "duration" in r]
        return sum(durations) / len(durations) if durations else 0.0
    
    def _analyze_common_errors(self, error_logs: List[Dict]) -> List[str]:
        """åˆ†æå¸¸è§é”™è¯¯"""
        error_counts = {}
        for error in error_logs:
            error_type = error.get("error", "Unknown")
            error_counts[error_type] = error_counts.get(error_type, 0) + 1
        
        # è¿”å›æœ€å¸¸è§çš„3ä¸ªé”™è¯¯
        sorted_errors = sorted(error_counts.items(), key=lambda x: x[1], reverse=True)
        return [error for error, count in sorted_errors[:3]]
    
    def _analyze_performance_trends(self) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½è¶‹åŠ¿"""
        if len(self.evolution_history) < 2:
            return {"trend": "insufficient_data"}
        
        recent_records = list(self.evolution_history)[-10:]
        rewards = [r.rewards for r in recent_records]
        
        # è®¡ç®—è¶‹åŠ¿
        if len(rewards) >= 2:
            trend = "improving" if rewards[-1] > rewards[0] else "declining"
        else:
            trend = "stable"
        
        return {
            "trend": trend,
            "recent_average": sum(rewards) / len(rewards),
            "volatility": np.std(rewards) if len(rewards) > 1 else 0
        }
    
    def _detect_anomalies(self, observations: List[str]) -> List[str]:
        """æ£€æµ‹å¼‚å¸¸"""
        anomalies = []
        
        # ç®€å•çš„å¼‚å¸¸æ£€æµ‹é€»è¾‘
        for obs in observations:
            if "é”™è¯¯" in obs and "æ•°é‡" in obs:
                # æå–é”™è¯¯æ•°é‡
                try:
                    count = int(obs.split("æ•°é‡: ")[1])
                    if count > 5:  # é˜ˆå€¼
                        anomalies.append(f"é”™è¯¯æ•°é‡è¿‡å¤š: {count}")
                except:
                    pass
            
            if "ä½¿ç”¨ç‡" in obs:
                try:
                    usage = float(obs.split(": ")[1].rstrip("%"))
                    if usage > 90:  # é˜ˆå€¼
                        anomalies.append(f"èµ„æºä½¿ç”¨ç‡è¿‡é«˜: {usage}%")
                except:
                    pass
        
        return anomalies
    
    def _identify_improvement_opportunities(self, observations: List[str]) -> List[str]:
        """è¯†åˆ«æ”¹è¿›æœºä¼š"""
        opportunities = []
        
        for obs in observations:
            if "æˆåŠŸç‡" in obs:
                try:
                    rate = float(obs.split(": ")[1].rstrip("%"))
                    if rate < 0.8:
                        opportunities.append("æå‡ä»»åŠ¡æˆåŠŸç‡")
                except:
                    pass
            
            if "å¹³å‡æ‰§è¡Œæ—¶é—´" in obs:
                try:
                    duration = float(obs.split(": ")[1].rstrip("ç§’"))
                    if duration > 5.0:
                        opportunities.append("ä¼˜åŒ–æ‰§è¡Œé€Ÿåº¦")
                except:
                    pass
        
        return opportunities
    
    def _identify_bottlenecks(self, metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """è¯†åˆ«ç“¶é¢ˆ"""
        bottlenecks = []
        
        # ç®€åŒ–çš„ç“¶é¢ˆè¯†åˆ«
        for metric, value in metrics.items():
            if isinstance(value, (int, float)) and value < 0.7:
                bottlenecks.append({
                    "component": metric,
                    "value": value,
                    "suggested_action": f"ä¼˜åŒ–{metric}",
                    "priority": "high",
                    "expected_improvement": 0.2
                })
        
        return bottlenecks
    
    def _analyze_trends(self, metrics: Dict[str, Any]) -> Dict[str, str]:
        """åˆ†æè¶‹åŠ¿"""
        trends = {}
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥åŸºäºå†å²æ•°æ®
        for metric, value in metrics.items():
            if isinstance(value, (int, float)):
                trends[metric] = "stable"  # ç®€åŒ–
        return trends
    
    def _compare_with_baseline(self, metrics: Dict[str, Any]) -> Dict[str, float]:
        """ä¸åŸºçº¿æ¯”è¾ƒ"""
        comparisons = {}
        for metric, value in metrics.items():
            if isinstance(value, (int, float)):
                baseline = self.performance_baseline.get(metric, 0.5)
                comparisons[metric] = (value - baseline) / baseline if baseline > 0 else 0
        return comparisons
    
    def _extract_recent_patterns(self) -> List[Dict[str, Any]]:
        """æå–æœ€è¿‘çš„æ¨¡å¼"""
        # ç®€åŒ–å®ç°
        return list(self.learning_patterns.values())[-10:]
    
    def _identify_success_patterns(self, patterns: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è¯†åˆ«æˆåŠŸæ¨¡å¼"""
        return [p for p in patterns if p.get("success_rate", 0) > 0.8]
    
    def _identify_failure_patterns(self, patterns: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è¯†åˆ«å¤±è´¥æ¨¡å¼"""
        return [p for p in patterns if p.get("success_rate", 0) < 0.5]
    
    def _analyze_common_causes(self, errors: List[Dict]) -> List[str]:
        """åˆ†æå¸¸è§åŸå› """
        # ç®€åŒ–å®ç°
        return ["è¶…æ—¶", "èµ„æºä¸è¶³", "é…ç½®é”™è¯¯"]
    
    def _analyze_error_correlations(self, errors: List[Dict]) -> Dict[str, float]:
        """åˆ†æé”™è¯¯å…³è”"""
        # ç®€åŒ–å®ç°
        return {"timeout_memory": 0.6, "config_performance": 0.4}
    
    def _assess_error_impact(self, errors: List[Dict]) -> Dict[str, str]:
        """è¯„ä¼°é”™è¯¯å½±å“"""
        # ç®€åŒ–å®ç°
        return {"TimeoutError": "high", "ValueError": "medium"}
    
    def _identify_quick_wins(self, record: EvolutionRecord) -> List[Dict[str, Any]]:
        """è¯†åˆ«å¿«é€Ÿæ”¹è¿›é¡¹"""
        return [
            {"area": "ç¼“å­˜", "action": "ä¼˜åŒ–ç¼“å­˜ç­–ç•¥", "improvement": 0.15},
            {"area": "æ—¥å¿—", "action": "å‡å°‘æ—¥å¿—è¾“å‡º", "improvement": 0.1}
        ]
    
    def _identify_long_term_improvements(self, record: EvolutionRecord) -> List[Dict[str, Any]]:
        """è¯†åˆ«é•¿æœŸæ”¹è¿›é¡¹"""
        return [
            {"area": "æ¶æ„", "action": "é‡æ„æ ¸å¿ƒæ¨¡å—", "improvement": 0.3},
            {"area": "ç®—æ³•", "action": "ä¼˜åŒ–æ ¸å¿ƒç®—æ³•", "improvement": 0.25}
        ]
    
    def _identify_resource_optimization(self, record: EvolutionRecord) -> List[Dict[str, Any]]:
        """è¯†åˆ«èµ„æºä¼˜åŒ–é¡¹"""
        return [
            {"area": "å†…å­˜", "action": "ä¼˜åŒ–å†…å­˜ä½¿ç”¨", "improvement": 0.2},
            {"area": "CPU", "action": "å¹¶è¡Œå¤„ç†ä¼˜åŒ–", "improvement": 0.15}
        ]
    
    def _collect_performance_metrics(self, record: EvolutionRecord) -> Dict[str, float]:
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        metrics = {}
        
        # åŸºäºç»“æœè®¡ç®—æŒ‡æ ‡
        if record.outcomes:
            metrics["avg_outcome"] = sum(record.outcomes.values()) / len(record.outcomes)
            metrics["max_outcome"] = max(record.outcomes.values())
            metrics["min_outcome"] = min(record.outcomes.values())
        
        # åŸºäºæ”¹è¿›è®¡ç®—æŒ‡æ ‡
        if record.improvements:
            metrics["improvement_count"] = len(record.improvements)
            metrics["improvement_rate"] = len([i for i in record.improvements if "æ˜¾è‘—" in i]) / len(record.improvements)
        
        return metrics
    
    def _update_performance_baseline(self, metrics: Dict[str, float]):
        """æ›´æ–°æ€§èƒ½åŸºçº¿"""
        for metric, value in metrics.items():
            if metric not in self.performance_baseline:
                self.performance_baseline[metric] = value
            else:
                # æŒ‡æ•°ç§»åŠ¨å¹³å‡
                alpha = 0.1
                self.performance_baseline[metric] = alpha * value + (1 - alpha) * self.performance_baseline[metric]
    
    async def analyze_and_plan(self, record: EvolutionRecord) -> EvolutionRecord:
        """åˆ†æå’Œè§„åˆ’é˜¶æ®µ"""
        # æ·±åº¦åˆ†æ
        analysis_result = await self._deep_analysis(record)
        
        # ç”Ÿæˆæ”¹è¿›è®¡åˆ’
        improvement_plan = await self._generate_improvement_plan(analysis_result)
        
        # æ›´æ–°è®°å½•
        record.phase = EvolutionPhase.ANALYSIS
        record.context["analysis_result"] = analysis_result
        record.context["improvement_plan"] = improvement_plan
        
        # é€‰æ‹©å­¦ä¹ ç±»å‹
        record.learning_type = self._select_learning_type(analysis_result)
        
        # ç¡®å®šä¸‹ä¸€æ­¥
        if improvement_plan:
            record.next_phase = EvolutionPhase.PLANNING
        else:
            record.next_phase = EvolutionPhase.OBSERVATION
        
        # ä¿å­˜è®°å½•
        self._save_evolution_record(record)
        
        logger.info(f"ğŸ” åˆ†æå®Œæˆï¼Œç”Ÿæˆäº† {len(improvement_plan)} ä¸ªæ”¹è¿›é¡¹")
        return record
    
    async def _deep_analysis(self, record: EvolutionRecord) -> Dict[str, Any]:
        """æ·±åº¦åˆ†æ"""
        analysis = {
            "performance_analysis": {},
            "pattern_analysis": {},
            "root_cause_analysis": {},
            "optimization_potential": {}
        }
        
        # æ€§èƒ½åˆ†æ
        if "performance_metrics" in record.context:
            metrics = record.context["performance_metrics"]
            analysis["performance_analysis"] = {
                "bottlenecks": self._identify_bottlenecks(metrics),
                "trends": self._analyze_trends(metrics),
                "comparisons": self._compare_with_baseline(metrics)
            }
        
        # æ¨¡å¼åˆ†æ
        recent_patterns = self._extract_recent_patterns()
        analysis["pattern_analysis"] = {
            "recurring_patterns": recent_patterns,
            "success_patterns": self._identify_success_patterns(recent_patterns),
            "failure_patterns": self._identify_failure_patterns(recent_patterns)
        }
        
        # æ ¹å› åˆ†æ
        if "error_logs" in record.context:
            errors = record.context["error_logs"]
            analysis["root_cause_analysis"] = {
                "common_causes": self._analyze_common_causes(errors),
                "correlations": self._analyze_error_correlations(errors),
                "impact_assessment": self._assess_error_impact(errors)
            }
        
        # ä¼˜åŒ–æ½œåŠ›
        analysis["optimization_potential"] = {
            "quick_wins": self._identify_quick_wins(record),
            "long_term_improvements": self._identify_long_term_improvements(record),
            "resource_optimization": self._identify_resource_optimization(record)
        }
        
        return analysis
    
    async def _generate_improvement_plan(self, analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ”¹è¿›è®¡åˆ’"""
        improvements = []
        
        # åŸºäºæ€§èƒ½åˆ†æçš„æ”¹è¿›
        if "performance_analysis" in analysis:
            perf_analysis = analysis["performance_analysis"]
            for bottleneck in perf_analysis.get("bottlenecks", []):
                improvements.append({
                    "type": "performance",
                    "target": bottleneck["component"],
                    "action": bottleneck["suggested_action"],
                    "priority": bottleneck["priority"],
                    "expected_improvement": bottleneck.get("expected_improvement", 0.1)
                })
        
        # åŸºäºæ¨¡å¼åˆ†æçš„æ”¹è¿›
        if "pattern_analysis" in analysis:
            pattern_analysis = analysis["pattern_analysis"]
            for pattern in pattern_analysis.get("failure_patterns", []):
                improvements.append({
                    "type": "pattern",
                    "target": pattern["pattern_id"],
                    "action": pattern["corrective_action"],
                    "priority": "medium",
                    "expected_improvement": 0.15
                })
        
        # åŸºäºä¼˜åŒ–æ½œåŠ›çš„æ”¹è¿›
        if "optimization_potential" in analysis:
            opt_potential = analysis["optimization_potential"]
            for quick_win in opt_potential.get("quick_wins", []):
                improvements.append({
                    "type": "optimization",
                    "target": quick_win["area"],
                    "action": quick_win["action"],
                    "priority": "high",
                    "expected_improvement": quick_win.get("improvement", 0.2)
                })
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        improvements.sort(key=lambda x: (
            0 if x["priority"] == "high" else 
            1 if x["priority"] == "medium" else 2
        ))
        
        return improvements[:5]  # æœ€å¤š5ä¸ªæ”¹è¿›é¡¹
    
    def _select_learning_type(self, analysis: Dict[str, Any]) -> LearningType:
        """é€‰æ‹©å­¦ä¹ ç±»å‹"""
        # æ ¹æ®åˆ†æç»“æœé€‰æ‹©æœ€é€‚åˆçš„å­¦ä¹ ç±»å‹
        if "pattern_analysis" in analysis:
            patterns = analysis["pattern_analysis"]
            if patterns.get("success_patterns") or patterns.get("failure_patterns"):
                return LearningType.SUPERVISED
        
        if "root_cause_analysis" in analysis:
            return LearningType.REINFORCEMENT
        
        return LearningType.META_LEARNING
    
    async def implement_improvements(self, record: EvolutionRecord) -> EvolutionRecord:
        """å®æ–½æ”¹è¿›"""
        improvements = record.context.get("improvement_plan", [])
        implemented = []
        outcomes = {}
        
        for improvement in improvements:
            try:
                # å®æ–½æ”¹è¿›
                result = await self._implement_single_improvement(improvement)
                implemented.append(improvement)
                
                # è®°å½•ç»“æœ
                outcomes[improvement["target"]] = result["success_rate"]
                
                # æ›´æ–°å­¦ä¹ æ¨¡å¼
                self._update_learning_patterns(improvement, result)
                
            except Exception as e:
                logger.error(f"å®æ–½æ”¹è¿›å¤±è´¥: {e}")
                outcomes[improvement["target"]] = 0.0
        
        # æ›´æ–°è®°å½•
        record.phase = EvolutionPhase.IMPLEMENTATION
        record.actions = [imp["action"] for imp in implemented]
        record.outcomes = outcomes
        record.next_phase = EvolutionPhase.EVALUATION
        
        # ä¿å­˜è®°å½•
        self._save_evolution_record(record)
        
        logger.info(f"âš™ï¸ å®æ–½äº† {len(implemented)} ä¸ªæ”¹è¿›")
        return record
    
    async def _implement_single_improvement(self, improvement: Dict[str, Any]) -> Dict[str, Any]:
        """å®æ–½å•ä¸ªæ”¹è¿›"""
        # è¿™é‡Œæ˜¯ç®€åŒ–çš„å®ç°ï¼Œå®é™…åº”è¯¥æ ¹æ®æ”¹è¿›ç±»å‹æ‰§è¡Œå…·ä½“æ“ä½œ
        
        # æ¨¡æ‹Ÿæ”¹è¿›å®æ–½
        await asyncio.sleep(0.1)
        
        # åŸºäºæ”¹è¿›ç±»å‹è¿”å›ä¸åŒçš„ç»“æœ
        if improvement["type"] == "performance":
            return {
                "success_rate": 0.8 + np.random.normal(0, 0.1),
                "performance_gain": improvement.get("expected_improvement", 0.1) * np.random.uniform(0.5, 1.5)
            }
        elif improvement["type"] == "pattern":
            return {
                "success_rate": 0.7 + np.random.normal(0, 0.1),
                "pattern_improvement": improvement.get("expected_improvement", 0.15) * np.random.uniform(0.5, 1.5)
            }
        else:
            return {
                "success_rate": 0.75 + np.random.normal(0, 0.1),
                "optimization_gain": improvement.get("expected_improvement", 0.2) * np.random.uniform(0.5, 1.5)
            }
    
    def _update_learning_patterns(self, improvement: Dict[str, Any], result: Dict[str, Any]):
        """æ›´æ–°å­¦ä¹ æ¨¡å¼"""
        pattern_id = f"{improvement['type']}_{improvement['target']}"
        
        if pattern_id not in self.learning_patterns:
            self.learning_patterns[pattern_id] = LearningPattern(
                pattern_id=pattern_id,
                pattern_type=improvement["type"],
                triggers=[improvement["target"]],
                actions=[improvement["action"]],
                success_rate=result["success_rate"],
                avg_reward=result.get("performance_gain", 0.1),
                usage_count=1
            )
        else:
            pattern = self.learning_patterns[pattern_id]
            # æ›´æ–°ç»Ÿè®¡
            pattern.usage_count += 1
            pattern.success_rate = (pattern.success_rate * (pattern.usage_count - 1) + result["success_rate"]) / pattern.usage_count
            pattern.avg_reward = (pattern.avg_reward * (pattern.usage_count - 1) + result.get("performance_gain", 0.1)) / pattern.usage_count
            pattern.last_updated = datetime.now()
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        self._save_learning_pattern(self.learning_patterns[pattern_id])
    
    async def evaluate_improvements(self, record: EvolutionRecord) -> EvolutionRecord:
        """è¯„ä¼°æ”¹è¿›æ•ˆæœ"""
        # è®¡ç®—æ€»ä½“å¥–åŠ±
        total_reward = 0.0
        for outcome in record.outcomes.values():
            total_reward += outcome
        
        record.rewards = total_reward / len(record.outcomes) if record.outcomes else 0.0
        
        # æ”¶é›†æ€§èƒ½æŒ‡æ ‡
        performance_metrics = self._collect_performance_metrics(record)
        record.performance_metrics = performance_metrics
        
        # è¯„ä¼°æ”¹è¿›æ•ˆæœ
        improvements = []
        for target, outcome in record.outcomes.items():
            if outcome > 0.7:
                improvements.append(f"{target}: æ˜¾è‘—æ”¹è¿›")
            elif outcome > 0.5:
                improvements.append(f"{target}: ä¸­ç­‰æ”¹è¿›")
            else:
                improvements.append(f"{target}: æ”¹è¿›æœ‰é™")
        
        record.improvements = improvements
        
        # æ›´æ–°è®°å½•
        record.phase = EvolutionPhase.EVALUATION
        
        # å†³å®šä¸‹ä¸€æ­¥
        if record.rewards > 0.6:
            record.next_phase = EvolutionPhase.CONSOLIDATION
        else:
            record.next_phase = EvolutionPhase.OBSERVATION
        
        # ä¿å­˜è®°å½•
        self._save_evolution_record(record)
        
        logger.info(f"ğŸ“Š è¯„ä¼°å®Œæˆï¼Œæ€»ä½“å¥–åŠ±: {record.rewards:.3f}")
        return record
    
    async def consolidate_learning(self, record: EvolutionRecord) -> EvolutionRecord:
        """å·©å›ºå­¦ä¹ æˆæœ"""
        # æ›´æ–°æ€§èƒ½åŸºçº¿
        self._update_performance_baseline(record.performance_metrics)
        
        # å¼ºåŒ–æˆåŠŸæ¨¡å¼
        successful_patterns = [
            p for p in self.learning_patterns.values() 
            if p.success_rate > 0.8
        ]
        
        # å¼±åŒ–å¤±è´¥æ¨¡å¼
        failed_patterns = [
            p for p in self.learning_patterns.values() 
            if p.success_rate < 0.5
        ]
        
        # ç”Ÿæˆå­¦ä¹ æ€»ç»“
        learning_summary = {
            "successful_patterns": len(successful_patterns),
            "failed_patterns": len(failed_patterns),
            "total_improvements": len(record.improvements),
            "overall_performance": record.rewards
        }
        
        # æ›´æ–°è®°å½•
        record.phase = EvolutionPhase.CONSOLIDATION
        record.context["learning_summary"] = learning_summary
        record.next_phase = EvolutionPhase.OBSERVATION
        
        # ä¿å­˜è®°å½•
        self._save_evolution_record(record)
        
        logger.info(f"ğŸ¯ å·©å›ºå®Œæˆï¼ŒæˆåŠŸæ¨¡å¼: {len(successful_patterns)}, å¤±è´¥æ¨¡å¼: {len(failed_patterns)}")
        return record
    
    def _save_evolution_record(self, record: EvolutionRecord):
        """ä¿å­˜è¿›åŒ–è®°å½•"""
        with self.conn:
            self.conn.execute(
                """INSERT OR REPLACE INTO evolution_records 
                   VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                (
                    record.id,
                    record.timestamp.timestamp(),
                    record.phase.value,
                    record.learning_type.value,
                    json.dumps(record.context),
                    json.dumps(record.observations),
                    json.dumps(record.actions),
                    json.dumps(record.outcomes),
                    record.rewards,
                    json.dumps(record.performance_metrics),
                    json.dumps(record.improvements),
                    record.next_phase.value if record.next_phase else None
                )
            )
    
    def _save_learning_pattern(self, pattern: LearningPattern):
        """ä¿å­˜å­¦ä¹ æ¨¡å¼"""
        with self.conn:
            self.conn.execute(
                """INSERT OR REPLACE INTO learning_patterns 
                   VALUES (?, ?, ?, ?, ?, ?, ?, ?)""",
                (
                    pattern.pattern_id,
                    pattern.pattern_type,
                    json.dumps(pattern.triggers),
                    json.dumps(pattern.actions),
                    pattern.success_rate,
                    pattern.avg_reward,
                    pattern.usage_count,
                    pattern.last_updated.timestamp()
                )
            )
    
    def get_evolution_statistics(self) -> Dict[str, Any]:
        """è·å–è¿›åŒ–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "total_records": len(self.evolution_history),
            "current_phase": self.current_phase.value,
            "learning_patterns": len(self.learning_patterns),
            "phase_distribution": {},
            "learning_type_distribution": {},
            "average_rewards": 0.0,
            "improvement_rate": 0.0
        }
        
        if self.evolution_history:
            # é˜¶æ®µåˆ†å¸ƒ
            for record in self.evolution_history:
                phase = record.phase.value
                stats["phase_distribution"][phase] = stats["phase_distribution"].get(phase, 0) + 1
            
            # å­¦ä¹ ç±»å‹åˆ†å¸ƒ
            for record in self.evolution_history:
                ltype = record.learning_type.value
                stats["learning_type_distribution"][ltype] = stats["learning_type_distribution"].get(ltype, 0) + 1
            
            # å¹³å‡å¥–åŠ±
            total_rewards = sum(r.rewards for r in self.evolution_history)
            stats["average_rewards"] = total_rewards / len(self.evolution_history)
            
            # æ”¹è¿›ç‡
            improved_records = sum(1 for r in self.evolution_history if r.rewards > 0.6)
            stats["improvement_rate"] = improved_records / len(self.evolution_history)
        
        return stats
    
    async def run_evolution_cycle(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„è¿›åŒ–å‘¨æœŸ"""
        logger.info("ğŸš€ å¼€å§‹è¿›åŒ–å‘¨æœŸ...")
        
        # 1. è§‚å¯Ÿé˜¶æ®µ
        observation_record = await self.observe_environment(context)
        
        # 2. åˆ†æå’Œè§„åˆ’é˜¶æ®µ
        if observation_record.next_phase == EvolutionPhase.ANALYSIS:
            analysis_record = await self.analyze_and_plan(observation_record)
        else:
            analysis_record = observation_record
        
        # 3. å®æ–½é˜¶æ®µ
        if analysis_record.next_phase == EvolutionPhase.PLANNING:
            implementation_record = await self.implement_improvements(analysis_record)
        else:
            implementation_record = analysis_record
        
        # 4. è¯„ä¼°é˜¶æ®µ
        if implementation_record.next_phase == EvolutionPhase.EVALUATION:
            evaluation_record = await self.evaluate_improvements(implementation_record)
        else:
            evaluation_record = implementation_record
        
        # 5. å·©å›ºé˜¶æ®µ
        if evaluation_record.next_phase == EvolutionPhase.CONSOLIDATION:
            final_record = await self.consolidate_learning(evaluation_record)
        else:
            final_record = evaluation_record
        
        # è¿”å›å‘¨æœŸç»“æœ
        return {
            "cycle_completed": True,
            "final_phase": final_record.phase.value,
            "total_reward": final_record.rewards,
            "improvements": final_record.improvements,
            "learning_summary": final_record.context.get("learning_summary", {}),
            "statistics": self.get_evolution_statistics()
        }

# --- ç¤ºä¾‹ä½¿ç”¨ ---
async def main():
    """æµ‹è¯•è‡ªæˆ‘è¿›åŒ–å¼•æ“"""
    engine = SelfEvolutionEngineV4()
    
    # æ¨¡æ‹Ÿç¯å¢ƒæ•°æ®
    context = {
        "task_results": [
            {"success": True, "duration": 5.2},
            {"success": True, "duration": 3.8},
            {"success": False, "duration": 8.1},
            {"success": True, "duration": 4.5}
        ],
        "resource_usage": {
            "cpu": 0.65,
            "memory": 0.78
        },
        "user_feedback": {
            "satisfaction": 0.82,
            "comments": ["å“åº”å¿«", "ç»“æœå‡†ç¡®", "ç•Œé¢å‹å¥½"]
        },
        "error_logs": [
            {"error": "TimeoutError", "count": 2},
            {"error": "ValueError", "count": 1}
        ]
    }
    
    # è¿è¡Œè¿›åŒ–å‘¨æœŸ
    result = await engine.run_evolution_cycle(context)
    
    print("\nğŸ“Š è¿›åŒ–å‘¨æœŸç»“æœ:")
    print(json.dumps(result, indent=2, ensure_ascii=False))
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = engine.get_evolution_statistics()
    print("\nğŸ“ˆ è¿›åŒ–ç»Ÿè®¡:")
    print(json.dumps(stats, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    asyncio.run(main())
